import java.io
import java.lang
import scala
import scala.collection
import scala.collection.concurrent
import scala.collection.generic
import scala.collection.immutable
import scala.collection.mutable
import scala.collection.parallel
import scala.collection.parallel.immutable
import scala.math
import scala.reflect
import scala.runtime
import typing



_ExposedArrayBuffer__T = typing.TypeVar('_ExposedArrayBuffer__T')  # <T>
class ExposedArrayBuffer(scala.collection.mutable.ArrayBuffer[_ExposedArrayBuffer__T], scala.collection.generic.Sizing, typing.Generic[_ExposedArrayBuffer__T]):
    def __init__(self): ...
    def internalArray(self) -> typing.List[typing.Any]: ...
    def setInternalSize(self, s: int) -> None: ...
    @typing.overload
    def sizeHint(self, coll: scala.collection.TraversableLike[typing.Any, typing.Any]) -> None: ...
    @typing.overload
    def sizeHint(self, coll: scala.collection.TraversableLike[typing.Any, typing.Any], delta: int) -> None: ...
    @typing.overload
    def sizeHint(self, len: int) -> None: ...

_ExposedArraySeq__T = typing.TypeVar('_ExposedArraySeq__T')  # <T>
class ExposedArraySeq(scala.collection.mutable.ArraySeq[_ExposedArraySeq__T], typing.Generic[_ExposedArraySeq__T]):
    def __init__(self, arr: typing.List[typing.Any], sz: int): ...
    def array(self) -> typing.List[typing.Any]: ...
    def length(self) -> int: ...
    def stringPrefix(self) -> str: ...

_LazyCombiner__Elem = typing.TypeVar('_LazyCombiner__Elem')  # <Elem>
_LazyCombiner__To = typing.TypeVar('_LazyCombiner__To')  # <To>
_LazyCombiner__Buff = typing.TypeVar('_LazyCombiner__Buff', bound=scala.collection.generic.Growable)  # <Buff>
class LazyCombiner(scala.collection.parallel.Combiner[_LazyCombiner__Elem, _LazyCombiner__To], typing.Generic[_LazyCombiner__Elem, _LazyCombiner__To, _LazyCombiner__Buff]):
    @staticmethod
    def $init$($this: 'LazyCombiner') -> None: ...
    @typing.overload
    def $plus$eq(self, elem: typing.Any) -> scala.collection.generic.Growable[typing.Any]: ...
    @typing.overload
    def $plus$eq(self, elem: _LazyCombiner__Elem) -> scala.collection.mutable.Builder[_LazyCombiner__Elem, _LazyCombiner__To]: ...
    @typing.overload
    def $plus$eq(self, elem1: typing.Any, elem2: typing.Any, elems: scala.collection.Seq[typing.Any]) -> scala.collection.generic.Growable[typing.Any]: ...
    @typing.overload
    def $plus$eq(self, elem: _LazyCombiner__Elem) -> 'LazyCombiner'[_LazyCombiner__Elem, _LazyCombiner__To, _LazyCombiner__Buff]: ...
    def allocateAndCopy(self) -> _LazyCombiner__To: ...
    def chain(self) -> scala.collection.mutable.ArrayBuffer[_LazyCombiner__Buff]: ...
    def clear(self) -> None: ...
    _combine__N = typing.TypeVar('_combine__N')  # <N>
    _combine__NewTo = typing.TypeVar('_combine__NewTo')  # <NewTo>
    def combine(self, other: scala.collection.parallel.Combiner[_combine__N, _combine__NewTo]) -> scala.collection.parallel.Combiner[_combine__N, _combine__NewTo]: ...
    def lastbuff(self) -> _LazyCombiner__Buff: ...
    def newLazyCombiner(self, buffchain: scala.collection.mutable.ArrayBuffer[_LazyCombiner__Buff]) -> 'LazyCombiner'[_LazyCombiner__Elem, _LazyCombiner__To, _LazyCombiner__Buff]: ...
    def result(self) -> _LazyCombiner__To: ...
    def scala$collection$parallel$mutable$LazyCombiner$_setter_$lastbuff_$eq(self, x$1: _LazyCombiner__Buff) -> None: ...
    def size(self) -> int: ...

_ParHashMapCombiner__K = typing.TypeVar('_ParHashMapCombiner__K')  # <K>
_ParHashMapCombiner__V = typing.TypeVar('_ParHashMapCombiner__V')  # <V>
class ParHashMapCombiner(scala.collection.parallel.BucketCombiner[scala.Tuple2[_ParHashMapCombiner__K, _ParHashMapCombiner__V], 'ParHashMap'[_ParHashMapCombiner__K, _ParHashMapCombiner__V], scala.collection.mutable.DefaultEntry[_ParHashMapCombiner__K, _ParHashMapCombiner__V], 'ParHashMapCombiner'[_ParHashMapCombiner__K, _ParHashMapCombiner__V]], scala.collection.mutable.HashTable.HashUtils[_ParHashMapCombiner__K], typing.Generic[_ParHashMapCombiner__K, _ParHashMapCombiner__V]):
    def __init__(self, tableLoadFactor: int): ...
    @typing.overload
    def $plus$eq(self, elem1: typing.Any, elem2: typing.Any, elems: scala.collection.Seq[typing.Any]) -> scala.collection.generic.Growable[typing.Any]: ...
    @typing.overload
    def $plus$eq(self, elem: scala.Tuple2[_ParHashMapCombiner__K, _ParHashMapCombiner__V]) -> 'ParHashMapCombiner'[_ParHashMapCombiner__K, _ParHashMapCombiner__V]: ...
    _apply__K = typing.TypeVar('_apply__K')  # <K>
    _apply__V = typing.TypeVar('_apply__V')  # <V>
    @staticmethod
    def apply() -> 'ParHashMapCombiner'[_apply__K, _apply__V]: ...
    def elemHashCode(self, key: _ParHashMapCombiner__K) -> int: ...
    def improve(self, hcode: int, seed: int) -> int: ...
    def result(self) -> 'ParHashMap'[_ParHashMapCombiner__K, _ParHashMapCombiner__V]: ...
    def sizeMapBucketBitSize(self) -> int: ...
    def sizeMapBucketSize(self) -> int: ...
    class AddingHashTable(scala.collection.mutable.HashTable[_ParHashMapCombiner__K, scala.collection.mutable.DefaultEntry[_ParHashMapCombiner__K, _ParHashMapCombiner__V]]):
        $outer: 'ParHashMapCombiner' = ...
        def __init__(self, $outer: 'ParHashMapCombiner', numelems: int, lf: int, _seedvalue: int): ...
        def _loadFactor(self) -> int: ...
        def _loadFactor_$eq(self, x$1: int) -> None: ...
        def addEntry(self, e: scala.collection.mutable.HashEntry) -> None: ...
        def alwaysInitSizeMap(self) -> bool: ...
        def calcSizeMapSize(self, tableLength: int) -> int: ...
        def clearTable(self) -> None: ...
        _createNewEntry__X = typing.TypeVar('_createNewEntry__X')  # <X>
        def createNewEntry(self, key: _ParHashMapCombiner__K, x: _createNewEntry__X) -> scala.runtime.Nothing.: ...
        def elemEquals(self, key1: _ParHashMapCombiner__K, key2: _ParHashMapCombiner__K) -> bool: ...
        def elemHashCode(self, key: _ParHashMapCombiner__K) -> int: ...
        def entriesIterator(self) -> scala.collection.Iterator[scala.collection.mutable.DefaultEntry[_ParHashMapCombiner__K, _ParHashMapCombiner__V]]: ...
        def findEntry(self, key: typing.Any) -> scala.collection.mutable.HashEntry: ...
        def findOrAddEntry(self, key: typing.Any, value: typing.Any) -> scala.collection.mutable.HashEntry: ...
        _foreachEntry__U = typing.TypeVar('_foreachEntry__U')  # <U>
        def foreachEntry(self, f: scala.Function1[scala.collection.mutable.DefaultEntry[_ParHashMapCombiner__K, _ParHashMapCombiner__V], _foreachEntry__U]) -> None: ...
        def hashTableContents(self) -> scala.collection.mutable.HashTable.Contents[_ParHashMapCombiner__K, scala.collection.mutable.DefaultEntry[_ParHashMapCombiner__K, _ParHashMapCombiner__V]]: ...
        def improve(self, hcode: int, seed: int) -> int: ...
        def index(self, hcode: int) -> int: ...
        def init(self, in_: java.io.ObjectInputStream, readEntry: scala.Function0[scala.collection.mutable.DefaultEntry[_ParHashMapCombiner__K, _ParHashMapCombiner__V]]) -> None: ...
        def initWithContents(self, c: scala.collection.mutable.HashTable.Contents[_ParHashMapCombiner__K, scala.collection.mutable.DefaultEntry[_ParHashMapCombiner__K, _ParHashMapCombiner__V]]) -> None: ...
        def initialSize(self) -> int: ...
        def insertEntry(self, e: scala.collection.mutable.DefaultEntry[_ParHashMapCombiner__K, _ParHashMapCombiner__V]) -> bool: ...
        def isSizeMapDefined(self) -> bool: ...
        def nnSizeMapAdd(self, h: int) -> None: ...
        def nnSizeMapRemove(self, h: int) -> None: ...
        def nnSizeMapReset(self, tableLength: int) -> None: ...
        def printSizeMap(self) -> None: ...
        def removeEntry(self, key: typing.Any) -> scala.collection.mutable.HashEntry: ...
        def seedvalue(self) -> int: ...
        def seedvalue_$eq(self, x$1: int) -> None: ...
        def serializeTo(self, out: java.io.ObjectOutputStream, writeEntry: scala.Function1[scala.collection.mutable.DefaultEntry[_ParHashMapCombiner__K, _ParHashMapCombiner__V], scala.runtime.BoxedUnit]) -> None: ...
        def setSize(self, sz: int) -> None: ...
        def sizeMapBucketBitSize(self) -> int: ...
        def sizeMapBucketSize(self) -> int: ...
        def sizeMapDisable(self) -> None: ...
        def sizeMapInit(self, tableLength: int) -> None: ...
        def sizeMapInitAndRebuild(self) -> None: ...
        def sizemap(self) -> typing.List[int]: ...
        def sizemap_$eq(self, x$1: typing.List[int]) -> None: ...
        def table(self) -> typing.List[scala.collection.mutable.HashEntry[_ParHashMapCombiner__K, scala.collection.mutable.DefaultEntry[_ParHashMapCombiner__K, _ParHashMapCombiner__V]]]: ...
        def tableSize(self) -> int: ...
        def tableSizeSeed(self) -> int: ...
        def tableSize_$eq(self, x$1: int) -> None: ...
        def table_$eq(self, x$1: typing.List[scala.collection.mutable.HashEntry[_ParHashMapCombiner__K, scala.collection.mutable.DefaultEntry[_ParHashMapCombiner__K, _ParHashMapCombiner__V]]]) -> None: ...
        def threshold(self) -> int: ...
        def threshold_$eq(self, x$1: int) -> None: ...
        def totalSizeMapBuckets(self) -> int: ...
    class FillBlocks(scala.collection.parallel.Task[typing.Any, 'ParHashMapCombiner.FillBlocks']):
        $outer: 'ParHashMapCombiner' = ...
        def __init__(self, $outer: 'ParHashMapCombiner', buckets: typing.List[scala.collection.mutable.UnrolledBuffer.Unrolled[scala.collection.mutable.DefaultEntry[_ParHashMapCombiner__K, _ParHashMapCombiner__V]]], table: 'ParHashMapCombiner.AddingHashTable', offset: int, howmany: int): ...
        def forwardThrowable(self) -> None: ...
        def leaf(self, prev: scala.Option[typing.Any]) -> None: ...
        def merge(self, that: 'ParHashMapCombiner.FillBlocks') -> None: ...
        def mergeThrowables(self, that: scala.collection.parallel.Task[typing.Any, typing.Any]) -> None: ...
        def repr(self) -> typing.Any: ...
        def result(self) -> int: ...
        def result_$eq(self, x$1: int) -> None: ...
        def shouldSplitFurther(self) -> bool: ...
        def signalAbort(self) -> None: ...
        def split(self) -> scala.collection.immutable.List['ParHashMapCombiner.FillBlocks']: ...
        def throwable(self) -> java.lang.Throwable: ...
        def throwable_$eq(self, x$1: java.lang.Throwable) -> None: ...
        def tryLeaf(self, lastres: scala.Option[typing.Any]) -> None: ...
        def tryMerge(self, t: typing.Any) -> None: ...

_ParHashSetCombiner__T = typing.TypeVar('_ParHashSetCombiner__T')  # <T>
class ParHashSetCombiner(scala.collection.parallel.BucketCombiner[_ParHashSetCombiner__T, 'ParHashSet'[_ParHashSetCombiner__T], typing.Any, 'ParHashSetCombiner'[_ParHashSetCombiner__T]], scala.collection.mutable.FlatHashTable.HashUtils[_ParHashSetCombiner__T], typing.Generic[_ParHashSetCombiner__T]):
    def __init__(self, tableLoadFactor: int): ...
    @typing.overload
    def $plus$eq(self, elem1: typing.Any, elem2: typing.Any, elems: scala.collection.Seq[typing.Any]) -> scala.collection.generic.Growable[typing.Any]: ...
    @typing.overload
    def $plus$eq(self, elem: _ParHashSetCombiner__T) -> 'ParHashSetCombiner'[_ParHashSetCombiner__T]: ...
    _apply__T = typing.TypeVar('_apply__T')  # <T>
    @staticmethod
    def apply() -> 'ParHashSetCombiner'[_apply__T]: ...
    def elemToEntry(self, elem: _ParHashSetCombiner__T) -> typing.Any: ...
    def entryToElem(self, entry: typing.Any) -> _ParHashSetCombiner__T: ...
    def improve(self, hcode: int, seed: int) -> int: ...
    def result(self) -> 'ParHashSet'[_ParHashSetCombiner__T]: ...
    def scala$collection$parallel$mutable$ParHashSetCombiner$$seedvalue(self) -> int: ...
    def sizeMapBucketBitSize(self) -> int: ...
    def sizeMapBucketSize(self) -> int: ...
    class AddingFlatHashTable(scala.collection.mutable.FlatHashTable[_ParHashSetCombiner__T]):
        $outer: 'ParHashSetCombiner' = ...
        def __init__(self, $outer: 'ParHashSetCombiner', numelems: int, lf: int, inseedvalue: int): ...
        def _loadFactor(self) -> int: ...
        def _loadFactor_$eq(self, x$1: int) -> None: ...
        def addElem(self, elem: _ParHashSetCombiner__T) -> bool: ...
        def addEntry(self, newEntry: typing.Any) -> bool: ...
        def alwaysInitSizeMap(self) -> bool: ...
        def calcSizeMapSize(self, tableLength: int) -> int: ...
        def capacity(self, expectedSize: int) -> int: ...
        def clearTable(self) -> None: ...
        def containsElem(self, elem: _ParHashSetCombiner__T) -> bool: ...
        def elemToEntry(self, elem: _ParHashSetCombiner__T) -> typing.Any: ...
        def entryToElem(self, entry: typing.Any) -> _ParHashSetCombiner__T: ...
        def findEntry(self, elem: _ParHashSetCombiner__T) -> scala.Option[_ParHashSetCombiner__T]: ...
        def hashTableContents(self) -> scala.collection.mutable.FlatHashTable.Contents[_ParHashSetCombiner__T]: ...
        def improve(self, hcode: int, seed: int) -> int: ...
        def index(self, hcode: int) -> int: ...
        def init(self, in_: java.io.ObjectInputStream, f: scala.Function1[_ParHashSetCombiner__T, scala.runtime.BoxedUnit]) -> None: ...
        def initWithContents(self, c: scala.collection.mutable.FlatHashTable.Contents[_ParHashSetCombiner__T]) -> None: ...
        def initialSize(self) -> int: ...
        def insertEntry(self, insertAt: int, comesBefore: int, newEntry: typing.Any) -> int: ...
        def isSizeMapDefined(self) -> bool: ...
        def iterator(self) -> scala.collection.Iterator[_ParHashSetCombiner__T]: ...
        def nnSizeMapAdd(self, h: int) -> None: ...
        def nnSizeMapRemove(self, h: int) -> None: ...
        def nnSizeMapReset(self, tableLength: int) -> None: ...
        def printContents(self) -> None: ...
        def printSizeMap(self) -> None: ...
        def randomSeed(self) -> int: ...
        def removeElem(self, elem: _ParHashSetCombiner__T) -> bool: ...
        def seedvalue(self) -> int: ...
        def seedvalue_$eq(self, x$1: int) -> None: ...
        def serializeTo(self, out: java.io.ObjectOutputStream) -> None: ...
        def setSize(self, sz: int) -> None: ...
        def sizeMapBucketBitSize(self) -> int: ...
        def sizeMapBucketSize(self) -> int: ...
        def sizeMapDisable(self) -> None: ...
        def sizeMapInit(self, tableLength: int) -> None: ...
        def sizeMapInitAndRebuild(self) -> None: ...
        def sizemap(self) -> typing.List[int]: ...
        def sizemap_$eq(self, x$1: typing.List[int]) -> None: ...
        def table(self) -> typing.List[typing.Any]: ...
        def tableLength(self) -> int: ...
        def tableSize(self) -> int: ...
        def tableSizeSeed(self) -> int: ...
        def tableSize_$eq(self, x$1: int) -> None: ...
        def table_$eq(self, x$1: typing.List[typing.Any]) -> None: ...
        def threshold(self) -> int: ...
        def threshold_$eq(self, x$1: int) -> None: ...
        def toString(self) -> str: ...
        def totalSizeMapBuckets(self) -> int: ...
    class FillBlocks(scala.collection.parallel.Task[scala.Tuple2[typing.Any, scala.collection.mutable.UnrolledBuffer[typing.Any]], 'ParHashSetCombiner.FillBlocks']):
        $outer: 'ParHashSetCombiner' = ...
        def __init__(self, $outer: 'ParHashSetCombiner', buckets: typing.List[scala.collection.mutable.UnrolledBuffer[typing.Any]], table: 'ParHashSetCombiner.AddingFlatHashTable', offset: int, howmany: int): ...
        def forwardThrowable(self) -> None: ...
        def howmany(self) -> int: ...
        def leaf(self, prev: scala.Option[scala.Tuple2[typing.Any, scala.collection.mutable.UnrolledBuffer[typing.Any]]]) -> None: ...
        def merge(self, that: 'ParHashSetCombiner.FillBlocks') -> None: ...
        def mergeThrowables(self, that: scala.collection.parallel.Task[typing.Any, typing.Any]) -> None: ...
        def offset(self) -> int: ...
        def repr(self) -> typing.Any: ...
        def result(self) -> scala.Tuple2[typing.Any, scala.collection.mutable.UnrolledBuffer[typing.Any]]: ...
        def result_$eq(self, x$1: scala.Tuple2[typing.Any, scala.collection.mutable.UnrolledBuffer[typing.Any]]) -> None: ...
        def shouldSplitFurther(self) -> bool: ...
        def signalAbort(self) -> None: ...
        def split(self) -> scala.collection.immutable.List['ParHashSetCombiner.FillBlocks']: ...
        def throwable(self) -> java.lang.Throwable: ...
        def throwable_$eq(self, x$1: java.lang.Throwable) -> None: ...
        def tryLeaf(self, lastres: scala.Option[scala.Tuple2[typing.Any, scala.collection.mutable.UnrolledBuffer[typing.Any]]]) -> None: ...
        def tryMerge(self, t: typing.Any) -> None: ...

_ParIterable__T = typing.TypeVar('_ParIterable__T')  # <T>
class ParIterable(scala.collection.parallel.ParIterable[_ParIterable__T], scala.Mutable, typing.Generic[_ParIterable__T]):
    @staticmethod
    def $init$($this: 'ParIterable') -> None: ...
    @staticmethod
    def ReusableCBF() -> scala.collection.generic.GenTraversableFactory.GenericCanBuildFrom[scala.runtime.Nothing.]: ...
    @staticmethod
    def apply(elems: scala.collection.Seq) -> scala.collection.GenTraversable: ...
    _canBuildFrom__T = typing.TypeVar('_canBuildFrom__T')  # <T>
    @staticmethod
    def canBuildFrom() -> scala.collection.generic.CanCombineFrom['ParIterable'[typing.Any], _canBuildFrom__T, 'ParIterable'[_canBuildFrom__T]]: ...
    def companion(self) -> scala.collection.generic.GenericCompanion['ParIterable']: ...
    @staticmethod
    def concat(xss: scala.collection.Seq) -> scala.collection.GenTraversable: ...
    @staticmethod
    def empty() -> scala.collection.GenTraversable: ...
    @typing.overload
    @staticmethod
    def fill(n1: int, n2: int, n3: int, n4: int, n5: int, elem: scala.Function0) -> scala.collection.GenTraversable: ...
    @typing.overload
    @staticmethod
    def fill(n1: int, n2: int, n3: int, n4: int, elem: scala.Function0) -> scala.collection.GenTraversable: ...
    @typing.overload
    @staticmethod
    def fill(n1: int, n2: int, n3: int, elem: scala.Function0) -> scala.collection.GenTraversable: ...
    @typing.overload
    @staticmethod
    def fill(n1: int, n2: int, elem: scala.Function0) -> scala.collection.GenTraversable: ...
    @typing.overload
    @staticmethod
    def fill(n: int, elem: scala.Function0) -> scala.collection.GenTraversable: ...
    @staticmethod
    def iterate(start: typing.Any, len: int, f: scala.Function1) -> scala.collection.GenTraversable: ...
    @typing.overload
    @staticmethod
    def range(start: typing.Any, end: typing.Any, step: typing.Any, evidence$2: scala.math.Integral) -> scala.collection.GenTraversable: ...
    @typing.overload
    @staticmethod
    def range(start: typing.Any, end: typing.Any, evidence$1: scala.math.Integral) -> scala.collection.GenTraversable: ...
    @typing.overload
    def seq(self) -> scala.collection.Iterable[typing.Any]: ...
    @typing.overload
    def seq(self) -> scala.collection.Iterable: ...
    @typing.overload
    def seq(self) -> scala.collection.Traversable[typing.Any]: ...
    @typing.overload
    def seq(self) -> scala.collection.TraversableOnce[typing.Any]: ...
    @typing.overload
    def seq(self) -> scala.collection.TraversableOnce[typing.Any]: ...
    @typing.overload
    def seq(self) -> scala.collection.mutable.Iterable[_ParIterable__T]: ...
    @typing.overload
    @staticmethod
    def tabulate(n1: int, n2: int, n3: int, n4: int, n5: int, f: scala.Function5) -> scala.collection.GenTraversable: ...
    @typing.overload
    @staticmethod
    def tabulate(n1: int, n2: int, n3: int, n4: int, f: scala.Function4) -> scala.collection.GenTraversable: ...
    @typing.overload
    @staticmethod
    def tabulate(n1: int, n2: int, n3: int, f: scala.Function3) -> scala.collection.GenTraversable: ...
    @typing.overload
    @staticmethod
    def tabulate(n1: int, n2: int, f: scala.Function2) -> scala.collection.GenTraversable: ...
    @typing.overload
    @staticmethod
    def tabulate(n: int, f: scala.Function1) -> scala.collection.GenTraversable: ...
    @typing.overload
    def toIterable(self) -> scala.collection.GenIterable[typing.Any]: ...
    @typing.overload
    def toIterable(self) -> scala.collection.parallel.ParIterable[_ParIterable__T]: ...
    @typing.overload
    def toIterable(self) -> 'ParIterable'[_ParIterable__T]: ...
    @typing.overload
    def toSeq(self) -> scala.collection.GenSeq[typing.Any]: ...
    @typing.overload
    def toSeq(self) -> scala.collection.parallel.ParSeq[_ParIterable__T]: ...
    @typing.overload
    def toSeq(self) -> 'ParSeq'[_ParIterable__T]: ...
    def toString(self) -> str: ...

_ParMapLike__K = typing.TypeVar('_ParMapLike__K')  # <K>
_ParMapLike__V = typing.TypeVar('_ParMapLike__V')  # <V>
_ParMapLike__Repr = typing.TypeVar('_ParMapLike__Repr', bound='ParMapLike')  # <Repr>
_ParMapLike__Sequential = typing.TypeVar('_ParMapLike__Sequential', bound=scala.collection.mutable.Map)  # <Sequential>
class ParMapLike(scala.collection.parallel.ParMapLike[_ParMapLike__K, _ParMapLike__V, _ParMapLike__Repr, _ParMapLike__Sequential], scala.collection.generic.Growable[scala.Tuple2[_ParMapLike__K, _ParMapLike__V]], scala.collection.generic.Shrinkable[_ParMapLike__K], scala.collection.mutable.Cloneable[_ParMapLike__Repr], typing.Generic[_ParMapLike__K, _ParMapLike__V, _ParMapLike__Repr, _ParMapLike__Sequential]):
    @staticmethod
    def $init$($this: 'ParMapLike') -> None: ...
    @typing.overload
    def $minus(self, key: _ParMapLike__K) -> _ParMapLike__Repr: ...
    @typing.overload
    def $minus(self, key: _ParMapLike__K) -> _ParMapLike__Repr: ...
    @typing.overload
    def $minus$eq(self, elem: typing.Any) -> scala.collection.generic.Shrinkable[typing.Any]: ...
    @typing.overload
    def $minus$eq(self, key: _ParMapLike__K) -> 'ParMapLike'[_ParMapLike__K, _ParMapLike__V, _ParMapLike__Repr, _ParMapLike__Sequential]: ...
    @typing.overload
    def $minus$eq(self, elem1: typing.Any, elem2: typing.Any, elems: scala.collection.Seq[typing.Any]) -> scala.collection.generic.Shrinkable[typing.Any]: ...
    _$plus_0__V1 = typing.TypeVar('_$plus_0__V1')  # <V1>
    _$plus_1__U = typing.TypeVar('_$plus_1__U')  # <U>
    @typing.overload
    def $plus(self, kv: scala.Tuple2[_ParMapLike__K, _.plus_0__V1]) -> scala.collection.GenMap[_ParMapLike__K, _.plus_0__V1]: ...
    @typing.overload
    def $plus(self, kv: scala.Tuple2[_ParMapLike__K, _.plus_1__U]) -> 'ParMap'[_ParMapLike__K, _.plus_1__U]: ...
    @typing.overload
    def $plus$eq(self, elem: typing.Any) -> scala.collection.generic.Growable[typing.Any]: ...
    @typing.overload
    def $plus$eq(self, kv: scala.Tuple2[_ParMapLike__K, _ParMapLike__V]) -> 'ParMapLike'[_ParMapLike__K, _ParMapLike__V, _ParMapLike__Repr, _ParMapLike__Sequential]: ...
    @typing.overload
    def $plus$eq(self, elem1: typing.Any, elem2: typing.Any, elems: scala.collection.Seq[typing.Any]) -> scala.collection.generic.Growable[typing.Any]: ...
    def clear(self) -> None: ...
    def equals(self, that: typing.Any) -> bool: ...
    def hashCode(self) -> int: ...
    def put(self, key: _ParMapLike__K, value: _ParMapLike__V) -> scala.Option[_ParMapLike__V]: ...
    def toString(self) -> str: ...

_ParSetLike__T = typing.TypeVar('_ParSetLike__T')  # <T>
_ParSetLike__Repr = typing.TypeVar('_ParSetLike__Repr', bound='ParSetLike')  # <Repr>
_ParSetLike__Sequential = typing.TypeVar('_ParSetLike__Sequential', bound=scala.collection.mutable.Set)  # <Sequential>
class ParSetLike(scala.collection.parallel.ParSetLike[_ParSetLike__T, _ParSetLike__Repr, _ParSetLike__Sequential], scala.collection.generic.Growable[_ParSetLike__T], scala.collection.generic.Shrinkable[_ParSetLike__T], scala.collection.mutable.Cloneable[_ParSetLike__Repr], typing.Generic[_ParSetLike__T, _ParSetLike__Repr, _ParSetLike__Sequential]):
    @staticmethod
    def $init$($this: 'ParSetLike') -> None: ...
    @typing.overload
    def $minus(self, elem: typing.Any) -> _ParSetLike__Repr: ...
    @typing.overload
    def $minus(self, elem: _ParSetLike__T) -> _ParSetLike__Repr: ...
    @typing.overload
    def $minus$eq(self, elem: typing.Any) -> scala.collection.generic.Shrinkable[typing.Any]: ...
    @typing.overload
    def $minus$eq(self, elem: _ParSetLike__T) -> 'ParSetLike'[_ParSetLike__T, _ParSetLike__Repr, _ParSetLike__Sequential]: ...
    @typing.overload
    def $minus$eq(self, elem1: typing.Any, elem2: typing.Any, elems: scala.collection.Seq[typing.Any]) -> scala.collection.generic.Shrinkable[typing.Any]: ...
    @typing.overload
    def $plus(self, elem: typing.Any) -> _ParSetLike__Repr: ...
    @typing.overload
    def $plus(self, elem: _ParSetLike__T) -> _ParSetLike__Repr: ...
    @typing.overload
    def $plus$eq(self, elem: typing.Any) -> scala.collection.generic.Growable[typing.Any]: ...
    @typing.overload
    def $plus$eq(self, elem: _ParSetLike__T) -> 'ParSetLike'[_ParSetLike__T, _ParSetLike__Repr, _ParSetLike__Sequential]: ...
    @typing.overload
    def $plus$eq(self, elem1: typing.Any, elem2: typing.Any, elems: scala.collection.Seq[typing.Any]) -> scala.collection.generic.Growable[typing.Any]: ...
    @typing.overload
    def empty(self) -> _ParSetLike__Repr: ...
    @typing.overload
    def empty(self) -> _ParSetLike__Repr: ...
    def equals(self, that: typing.Any) -> bool: ...
    def hashCode(self) -> int: ...
    @typing.overload
    def toString(self) -> str: ...
    @typing.overload
    def toString(self) -> str: ...

_ParTrieMapCombiner__K = typing.TypeVar('_ParTrieMapCombiner__K')  # <K>
_ParTrieMapCombiner__V = typing.TypeVar('_ParTrieMapCombiner__V')  # <V>
class ParTrieMapCombiner(scala.collection.parallel.Combiner[scala.Tuple2[_ParTrieMapCombiner__K, _ParTrieMapCombiner__V], 'ParTrieMap'[_ParTrieMapCombiner__K, _ParTrieMapCombiner__V]], typing.Generic[_ParTrieMapCombiner__K, _ParTrieMapCombiner__V]):
    @staticmethod
    def $init$($this: 'ParTrieMapCombiner') -> None: ...
    def canBeShared(self) -> bool: ...
    _combine__N = typing.TypeVar('_combine__N', bound=scala.Tuple2)  # <N>
    _combine__NewTo = typing.TypeVar('_combine__NewTo')  # <NewTo>
    def combine(self, other: scala.collection.parallel.Combiner[_combine__N, _combine__NewTo]) -> scala.collection.parallel.Combiner[_combine__N, _combine__NewTo]: ...

_ParTrieMapSplitter__K = typing.TypeVar('_ParTrieMapSplitter__K')  # <K>
_ParTrieMapSplitter__V = typing.TypeVar('_ParTrieMapSplitter__V')  # <V>
class ParTrieMapSplitter(scala.collection.concurrent.TrieMapIterator[_ParTrieMapSplitter__K, _ParTrieMapSplitter__V], scala.collection.parallel.IterableSplitter[scala.Tuple2[_ParTrieMapSplitter__K, _ParTrieMapSplitter__V]], typing.Generic[_ParTrieMapSplitter__K, _ParTrieMapSplitter__V]):
    def __init__(self, lev: int, ct: scala.collection.concurrent.TrieMap[_ParTrieMapSplitter__K, _ParTrieMapSplitter__V], mustInit: bool): ...
    def abort(self) -> None: ...
    _appendParIterable__U = typing.TypeVar('_appendParIterable__U')  # <U>
    _appendParIterable__PI = typing.TypeVar('_appendParIterable__PI', bound=scala.collection.parallel.IterableSplitter)  # <PI>
    def appendParIterable(self, that: _appendParIterable__PI) -> scala.collection.parallel.IterableSplitter.Appended[_appendParIterable__U, _appendParIterable__PI]: ...
    def buildString(self, closure: scala.Function1[scala.Function1[str, scala.runtime.BoxedUnit], scala.runtime.BoxedUnit]) -> str: ...
    _collect2combiner__S = typing.TypeVar('_collect2combiner__S')  # <S>
    _collect2combiner__That = typing.TypeVar('_collect2combiner__That')  # <That>
    def collect2combiner(self, pf: scala.PartialFunction[scala.Tuple2[_ParTrieMapSplitter__K, _ParTrieMapSplitter__V], _collect2combiner__S], cb: scala.collection.parallel.Combiner[_collect2combiner__S, _collect2combiner__That]) -> scala.collection.parallel.Combiner[_collect2combiner__S, _collect2combiner__That]: ...
    _copy2builder__U = typing.TypeVar('_copy2builder__U')  # <U>
    _copy2builder__Coll = typing.TypeVar('_copy2builder__Coll')  # <Coll>
    _copy2builder__Bld = typing.TypeVar('_copy2builder__Bld', bound=scala.collection.mutable.Builder)  # <Bld>
    def copy2builder(self, b: _copy2builder__Bld) -> _copy2builder__Bld: ...
    _copyToArray_0__B = typing.TypeVar('_copyToArray_0__B')  # <B>
    _copyToArray_1__B = typing.TypeVar('_copyToArray_1__B')  # <B>
    _copyToArray_2__U = typing.TypeVar('_copyToArray_2__U')  # <U>
    @typing.overload
    def copyToArray(self, xs: typing.Any) -> None: ...
    @typing.overload
    def copyToArray(self, xs: typing.Any, start: int) -> None: ...
    @typing.overload
    def copyToArray(self, array: typing.Any, from_: int, len: int) -> None: ...
    def count(self, p: scala.Function1[scala.Tuple2[_ParTrieMapSplitter__K, _ParTrieMapSplitter__V], typing.Any]) -> int: ...
    def debugInformation(self) -> str: ...
    def drop(self, n: int) -> scala.collection.parallel.IterableSplitter[scala.Tuple2[_ParTrieMapSplitter__K, _ParTrieMapSplitter__V]]: ...
    _drop2combiner__U = typing.TypeVar('_drop2combiner__U')  # <U>
    _drop2combiner__This = typing.TypeVar('_drop2combiner__This')  # <This>
    def drop2combiner(self, n: int, cb: scala.collection.parallel.Combiner[_drop2combiner__U, _drop2combiner__This]) -> scala.collection.parallel.Combiner[_drop2combiner__U, _drop2combiner__This]: ...
    def dup(self) -> 'ParTrieMapSplitter'[_ParTrieMapSplitter__K, _ParTrieMapSplitter__V]: ...
    _filter2combiner__U = typing.TypeVar('_filter2combiner__U')  # <U>
    _filter2combiner__This = typing.TypeVar('_filter2combiner__This')  # <This>
    def filter2combiner(self, pred: scala.Function1[scala.Tuple2[_ParTrieMapSplitter__K, _ParTrieMapSplitter__V], typing.Any], cb: scala.collection.parallel.Combiner[_filter2combiner__U, _filter2combiner__This]) -> scala.collection.parallel.Combiner[_filter2combiner__U, _filter2combiner__This]: ...
    _filterNot2combiner__U = typing.TypeVar('_filterNot2combiner__U')  # <U>
    _filterNot2combiner__This = typing.TypeVar('_filterNot2combiner__This')  # <This>
    def filterNot2combiner(self, pred: scala.Function1[scala.Tuple2[_ParTrieMapSplitter__K, _ParTrieMapSplitter__V], typing.Any], cb: scala.collection.parallel.Combiner[_filterNot2combiner__U, _filterNot2combiner__This]) -> scala.collection.parallel.Combiner[_filterNot2combiner__U, _filterNot2combiner__This]: ...
    _flatmap2combiner__S = typing.TypeVar('_flatmap2combiner__S')  # <S>
    _flatmap2combiner__That = typing.TypeVar('_flatmap2combiner__That')  # <That>
    def flatmap2combiner(self, f: scala.Function1[scala.Tuple2[_ParTrieMapSplitter__K, _ParTrieMapSplitter__V], scala.collection.GenTraversableOnce[_flatmap2combiner__S]], cb: scala.collection.parallel.Combiner[_flatmap2combiner__S, _flatmap2combiner__That]) -> scala.collection.parallel.Combiner[_flatmap2combiner__S, _flatmap2combiner__That]: ...
    _fold__U = typing.TypeVar('_fold__U')  # <U>
    def fold(self, z: _fold__U, op: scala.Function2[_fold__U, _fold__U, _fold__U]) -> _fold__U: ...
    def indexFlag(self) -> int: ...
    def isAborted(self) -> bool: ...
    def isRemainingCheap(self) -> bool: ...
    def iterated(self) -> int: ...
    def iterated_$eq(self, x$1: int) -> None: ...
    _map__S = typing.TypeVar('_map__S')  # <S>
    def map(self, f: scala.Function1[scala.Tuple2[_ParTrieMapSplitter__K, _ParTrieMapSplitter__V], _map__S]) -> scala.collection.parallel.IterableSplitter.Mapped[_map__S]: ...
    _map2combiner__S = typing.TypeVar('_map2combiner__S')  # <S>
    _map2combiner__That = typing.TypeVar('_map2combiner__That')  # <That>
    def map2combiner(self, f: scala.Function1[scala.Tuple2[_ParTrieMapSplitter__K, _ParTrieMapSplitter__V], _map2combiner__S], cb: scala.collection.parallel.Combiner[_map2combiner__S, _map2combiner__That]) -> scala.collection.parallel.Combiner[_map2combiner__S, _map2combiner__That]: ...
    def max(self, ord: scala.math.Ordering) -> typing.Any: ...
    def min(self, ord: scala.math.Ordering) -> typing.Any: ...
    def newIterator(self, _lev: int, _ct: scala.collection.concurrent.TrieMap[_ParTrieMapSplitter__K, _ParTrieMapSplitter__V], _mustInit: bool) -> 'ParTrieMapSplitter'[_ParTrieMapSplitter__K, _ParTrieMapSplitter__V]: ...
    _newSliceInternal__U = typing.TypeVar('_newSliceInternal__U', bound=scala.collection.parallel.IterableSplitter.Taken)  # <U>
    def newSliceInternal(self, it: _newSliceInternal__U, from1: int) -> _newSliceInternal__U: ...
    def newTaken(self, until: int) -> scala.collection.parallel.IterableSplitter.Taken: ...
    def next(self) -> scala.Tuple2[_ParTrieMapSplitter__K, _ParTrieMapSplitter__V]: ...
    _partition2combiners__U = typing.TypeVar('_partition2combiners__U')  # <U>
    _partition2combiners__This = typing.TypeVar('_partition2combiners__This')  # <This>
    def partition2combiners(self, pred: scala.Function1[scala.Tuple2[_ParTrieMapSplitter__K, _ParTrieMapSplitter__V], typing.Any], btrue: scala.collection.parallel.Combiner[_partition2combiners__U, _partition2combiners__This], bfalse: scala.collection.parallel.Combiner[_partition2combiners__U, _partition2combiners__This]) -> scala.Tuple2[scala.collection.parallel.Combiner[_partition2combiners__U, _partition2combiners__This], scala.collection.parallel.Combiner[_partition2combiners__U, _partition2combiners__This]]: ...
    _product__U = typing.TypeVar('_product__U')  # <U>
    def product(self, num: scala.math.Numeric[_product__U]) -> _product__U: ...
    _reduce__U = typing.TypeVar('_reduce__U')  # <U>
    def reduce(self, op: scala.Function2[_reduce__U, _reduce__U, _reduce__U]) -> _reduce__U: ...
    _reduceLeft_0__B = typing.TypeVar('_reduceLeft_0__B')  # <B>
    _reduceLeft_1__U = typing.TypeVar('_reduceLeft_1__U')  # <U>
    @typing.overload
    def reduceLeft(self, op: scala.Function2[_reduceLeft_0__B, scala.Tuple2[_ParTrieMapSplitter__K, _ParTrieMapSplitter__V], _reduceLeft_0__B]) -> _reduceLeft_0__B: ...
    @typing.overload
    def reduceLeft(self, howmany: int, op: scala.Function2[_reduceLeft_1__U, _reduceLeft_1__U, _reduceLeft_1__U]) -> _reduceLeft_1__U: ...
    def remaining(self) -> int: ...
    _scanToArray__U = typing.TypeVar('_scanToArray__U')  # <U>
    _scanToArray__A = typing.TypeVar('_scanToArray__A')  # <A>
    def scanToArray(self, z: _scanToArray__U, op: scala.Function2[_scanToArray__U, _scanToArray__U, _scanToArray__U], array: typing.Any, from_: int) -> None: ...
    _scanToCombiner_0__U = typing.TypeVar('_scanToCombiner_0__U')  # <U>
    _scanToCombiner_0__That = typing.TypeVar('_scanToCombiner_0__That')  # <That>
    _scanToCombiner_1__U = typing.TypeVar('_scanToCombiner_1__U')  # <U>
    _scanToCombiner_1__That = typing.TypeVar('_scanToCombiner_1__That')  # <That>
    @typing.overload
    def scanToCombiner(self, howmany: int, startValue: _scanToCombiner_0__U, op: scala.Function2[_scanToCombiner_0__U, _scanToCombiner_0__U, _scanToCombiner_0__U], cb: scala.collection.parallel.Combiner[_scanToCombiner_0__U, _scanToCombiner_0__That]) -> scala.collection.parallel.Combiner[_scanToCombiner_0__U, _scanToCombiner_0__That]: ...
    @typing.overload
    def scanToCombiner(self, startValue: _scanToCombiner_1__U, op: scala.Function2[_scanToCombiner_1__U, _scanToCombiner_1__U, _scanToCombiner_1__U], cb: scala.collection.parallel.Combiner[_scanToCombiner_1__U, _scanToCombiner_1__That]) -> scala.collection.parallel.Combiner[_scanToCombiner_1__U, _scanToCombiner_1__That]: ...
    def setIndexFlag(self, f: int) -> None: ...
    def setIndexFlagIfGreater(self, f: int) -> None: ...
    def setIndexFlagIfLesser(self, f: int) -> None: ...
    _shouldSplitFurther__S = typing.TypeVar('_shouldSplitFurther__S')  # <S>
    def shouldSplitFurther(self, coll: scala.collection.parallel.ParIterable[_shouldSplitFurther__S], parallelismLevel: int) -> bool: ...
    def signalDelegate(self) -> scala.collection.generic.Signalling: ...
    def signalDelegate_$eq(self, x$1: scala.collection.generic.Signalling) -> None: ...
    def slice(self, from1: int, until1: int) -> scala.collection.parallel.IterableSplitter[scala.Tuple2[_ParTrieMapSplitter__K, _ParTrieMapSplitter__V]]: ...
    _slice2combiner__U = typing.TypeVar('_slice2combiner__U')  # <U>
    _slice2combiner__This = typing.TypeVar('_slice2combiner__This')  # <This>
    def slice2combiner(self, from_: int, until: int, cb: scala.collection.parallel.Combiner[_slice2combiner__U, _slice2combiner__This]) -> scala.collection.parallel.Combiner[_slice2combiner__U, _slice2combiner__This]: ...
    _span2combiners__U = typing.TypeVar('_span2combiners__U')  # <U>
    _span2combiners__This = typing.TypeVar('_span2combiners__This')  # <This>
    def span2combiners(self, p: scala.Function1[scala.Tuple2[_ParTrieMapSplitter__K, _ParTrieMapSplitter__V], typing.Any], before: scala.collection.parallel.Combiner[_span2combiners__U, _span2combiners__This], after: scala.collection.parallel.Combiner[_span2combiners__U, _span2combiners__This]) -> scala.Tuple2[scala.collection.parallel.Combiner[_span2combiners__U, _span2combiners__This], scala.collection.parallel.Combiner[_span2combiners__U, _span2combiners__This]]: ...
    def split(self) -> scala.collection.Seq[scala.collection.parallel.IterableSplitter[scala.Tuple2[_ParTrieMapSplitter__K, _ParTrieMapSplitter__V]]]: ...
    _splitAt2combiners__U = typing.TypeVar('_splitAt2combiners__U')  # <U>
    _splitAt2combiners__This = typing.TypeVar('_splitAt2combiners__This')  # <This>
    def splitAt2combiners(self, at: int, before: scala.collection.parallel.Combiner[_splitAt2combiners__U, _splitAt2combiners__This], after: scala.collection.parallel.Combiner[_splitAt2combiners__U, _splitAt2combiners__This]) -> scala.Tuple2[scala.collection.parallel.Combiner[_splitAt2combiners__U, _splitAt2combiners__This], scala.collection.parallel.Combiner[_splitAt2combiners__U, _splitAt2combiners__This]]: ...
    def splitWithSignalling(self) -> scala.collection.Seq[scala.collection.parallel.IterableSplitter[scala.Tuple2[_ParTrieMapSplitter__K, _ParTrieMapSplitter__V]]]: ...
    _sum__U = typing.TypeVar('_sum__U')  # <U>
    def sum(self, num: scala.math.Numeric[_sum__U]) -> _sum__U: ...
    def tag(self) -> int: ...
    def take(self, n: int) -> scala.collection.parallel.IterableSplitter[scala.Tuple2[_ParTrieMapSplitter__K, _ParTrieMapSplitter__V]]: ...
    _take2combiner__U = typing.TypeVar('_take2combiner__U')  # <U>
    _take2combiner__This = typing.TypeVar('_take2combiner__This')  # <This>
    def take2combiner(self, n: int, cb: scala.collection.parallel.Combiner[_take2combiner__U, _take2combiner__This]) -> scala.collection.parallel.Combiner[_take2combiner__U, _take2combiner__This]: ...
    _takeWhile2combiner__U = typing.TypeVar('_takeWhile2combiner__U')  # <U>
    _takeWhile2combiner__This = typing.TypeVar('_takeWhile2combiner__This')  # <This>
    def takeWhile2combiner(self, p: scala.Function1[scala.Tuple2[_ParTrieMapSplitter__K, _ParTrieMapSplitter__V], typing.Any], cb: scala.collection.parallel.Combiner[_takeWhile2combiner__U, _takeWhile2combiner__This]) -> scala.Tuple2[scala.collection.parallel.Combiner[_takeWhile2combiner__U, _takeWhile2combiner__This], typing.Any]: ...
    def totalsize(self) -> int: ...
    _zip2combiner__U = typing.TypeVar('_zip2combiner__U')  # <U>
    _zip2combiner__S = typing.TypeVar('_zip2combiner__S')  # <S>
    _zip2combiner__That = typing.TypeVar('_zip2combiner__That')  # <That>
    def zip2combiner(self, otherpit: scala.collection.parallel.RemainsIterator[_zip2combiner__S], cb: scala.collection.parallel.Combiner[scala.Tuple2[_zip2combiner__U, _zip2combiner__S], _zip2combiner__That]) -> scala.collection.parallel.Combiner[scala.Tuple2[_zip2combiner__U, _zip2combiner__S], _zip2combiner__That]: ...
    _zipAll2combiner__U = typing.TypeVar('_zipAll2combiner__U')  # <U>
    _zipAll2combiner__S = typing.TypeVar('_zipAll2combiner__S')  # <S>
    _zipAll2combiner__That = typing.TypeVar('_zipAll2combiner__That')  # <That>
    def zipAll2combiner(self, that: scala.collection.parallel.RemainsIterator[_zipAll2combiner__S], thiselem: _zipAll2combiner__U, thatelem: _zipAll2combiner__S, cb: scala.collection.parallel.Combiner[scala.Tuple2[_zipAll2combiner__U, _zipAll2combiner__S], _zipAll2combiner__That]) -> scala.collection.parallel.Combiner[scala.Tuple2[_zipAll2combiner__U, _zipAll2combiner__S], _zipAll2combiner__That]: ...
    _zipAllParSeq__S = typing.TypeVar('_zipAllParSeq__S')  # <S>
    _zipAllParSeq__U = typing.TypeVar('_zipAllParSeq__U')  # <U>
    _zipAllParSeq__R = typing.TypeVar('_zipAllParSeq__R')  # <R>
    def zipAllParSeq(self, that: scala.collection.parallel.SeqSplitter[_zipAllParSeq__S], thisElem: _zipAllParSeq__U, thatElem: _zipAllParSeq__R) -> scala.collection.parallel.IterableSplitter.ZippedAll[_zipAllParSeq__U, _zipAllParSeq__R]: ...
    _zipParSeq__S = typing.TypeVar('_zipParSeq__S')  # <S>
    def zipParSeq(self, that: scala.collection.parallel.SeqSplitter[_zipParSeq__S]) -> scala.collection.parallel.IterableSplitter.Zipped[_zipParSeq__S]: ...

class SizeMapUtils:
    @staticmethod
    def $init$($this: 'SizeMapUtils') -> None: ...
    def calcNumElems(self, from_: int, until: int, tableLength: int, sizeMapBucketSize: int) -> int: ...
    def countBucketSizes(self, fromBucket: int, untilBucket: int) -> int: ...
    def countElems(self, from_: int, until: int) -> int: ...

_UnrolledParArrayCombiner__T = typing.TypeVar('_UnrolledParArrayCombiner__T')  # <T>
class UnrolledParArrayCombiner(scala.collection.parallel.Combiner[_UnrolledParArrayCombiner__T, 'ParArray'[_UnrolledParArrayCombiner__T]], typing.Generic[_UnrolledParArrayCombiner__T]):
    @staticmethod
    def $init$($this: 'UnrolledParArrayCombiner') -> None: ...
    @typing.overload
    def $plus$eq(self, elem: typing.Any) -> scala.collection.generic.Growable[typing.Any]: ...
    @typing.overload
    def $plus$eq(self, elem: typing.Any) -> scala.collection.mutable.Builder[typing.Any, typing.Any]: ...
    @typing.overload
    def $plus$eq(self, elem1: typing.Any, elem2: typing.Any, elems: scala.collection.Seq[typing.Any]) -> scala.collection.generic.Growable[typing.Any]: ...
    @typing.overload
    def $plus$eq(self, elem: _UnrolledParArrayCombiner__T) -> 'UnrolledParArrayCombiner'[_UnrolledParArrayCombiner__T]: ...
    _apply__T = typing.TypeVar('_apply__T')  # <T>
    @staticmethod
    def apply() -> 'UnrolledParArrayCombiner'[_apply__T]: ...
    def buff(self) -> scala.collection.mutable.DoublingUnrolledBuffer[typing.Any]: ...
    def clear(self) -> None: ...
    _combine__N = typing.TypeVar('_combine__N')  # <N>
    _combine__NewTo = typing.TypeVar('_combine__NewTo')  # <NewTo>
    def combine(self, other: scala.collection.parallel.Combiner[_combine__N, _combine__NewTo]) -> scala.collection.parallel.Combiner[_combine__N, _combine__NewTo]: ...
    @typing.overload
    def result(self) -> typing.Any: ...
    @typing.overload
    def result(self) -> 'ParArray'[_UnrolledParArrayCombiner__T]: ...
    def scala$collection$parallel$mutable$UnrolledParArrayCombiner$_setter_$buff_$eq(self, x$1: scala.collection.mutable.DoublingUnrolledBuffer[typing.Any]) -> None: ...
    def size(self) -> int: ...
    @typing.overload
    def sizeHint(self, coll: scala.collection.TraversableLike[typing.Any, typing.Any]) -> None: ...
    @typing.overload
    def sizeHint(self, coll: scala.collection.TraversableLike[typing.Any, typing.Any], delta: int) -> None: ...
    @typing.overload
    def sizeHint(self, sz: int) -> None: ...
    class CopyUnrolledToArray(scala.collection.parallel.Task[scala.runtime.BoxedUnit, 'UnrolledParArrayCombiner.CopyUnrolledToArray']):
        $outer: 'UnrolledParArrayCombiner' = ...
        def __init__(self, $outer: 'UnrolledParArrayCombiner', array: typing.List[typing.Any], offset: int, howmany: int): ...
        def forwardThrowable(self) -> None: ...
        def leaf(self, prev: scala.Option[scala.runtime.BoxedUnit]) -> None: ...
        def merge(self, that: typing.Any) -> None: ...
        def mergeThrowables(self, that: scala.collection.parallel.Task[typing.Any, typing.Any]) -> None: ...
        def repr(self) -> typing.Any: ...
        def result(self) -> None: ...
        def result_$eq(self, x$1: scala.runtime.BoxedUnit) -> None: ...
        def shouldSplitFurther(self) -> bool: ...
        def signalAbort(self) -> None: ...
        def split(self) -> scala.collection.immutable.List['UnrolledParArrayCombiner.CopyUnrolledToArray']: ...
        def throwable(self) -> java.lang.Throwable: ...
        def throwable_$eq(self, x$1: java.lang.Throwable) -> None: ...
        def toString(self) -> str: ...
        def tryLeaf(self, lastres: scala.Option[scala.runtime.BoxedUnit]) -> None: ...
        def tryMerge(self, t: typing.Any) -> None: ...

class package:
    @staticmethod
    def ParArrayCombiner() -> 'ResizableParArrayCombiner.': ...

_ParFlatHashTable__T = typing.TypeVar('_ParFlatHashTable__T')  # <T>
class ParFlatHashTable(scala.collection.mutable.FlatHashTable[_ParFlatHashTable__T], typing.Generic[_ParFlatHashTable__T]):
    @staticmethod
    def $init$($this: 'ParFlatHashTable') -> None: ...
    def alwaysInitSizeMap(self) -> bool: ...
    class ParFlatHashTableIterator(scala.collection.parallel.IterableSplitter[_ParFlatHashTable__T], SizeMapUtils):
        $outer: 'ParFlatHashTable' = ...
        def __init__(self, $outer: 'ParFlatHashTable', idx: int, until: int, totalsize: int): ...
        _$colon$bslash__B = typing.TypeVar('_$colon$bslash__B')  # <B>
        def $colon$bslash(self, z: _.colon.bslash__B, op: scala.Function2[_ParFlatHashTable__T, _.colon.bslash__B, _.colon.bslash__B]) -> _.colon.bslash__B: ...
        _$div$colon__B = typing.TypeVar('_$div$colon__B')  # <B>
        def $div$colon(self, z: _.div.colon__B, op: scala.Function2[_.div.colon__B, _ParFlatHashTable__T, _.div.colon__B]) -> _.div.colon__B: ...
        _$plus$plus__B = typing.TypeVar('_$plus$plus__B')  # <B>
        def $plus$plus(self, that: scala.Function0[scala.collection.GenTraversableOnce[_.plus.plus__B]]) -> scala.collection.Iterator[_.plus.plus__B]: ...
        def abort(self) -> None: ...
        @typing.overload
        def addString(self, b: scala.collection.mutable.StringBuilder) -> scala.collection.mutable.StringBuilder: ...
        @typing.overload
        def addString(self, b: scala.collection.mutable.StringBuilder, sep: str) -> scala.collection.mutable.StringBuilder: ...
        @typing.overload
        def addString(self, b: scala.collection.mutable.StringBuilder, start: str, sep: str, end: str) -> scala.collection.mutable.StringBuilder: ...
        _aggregate__B = typing.TypeVar('_aggregate__B')  # <B>
        def aggregate(self, z: scala.Function0[_aggregate__B], seqop: scala.Function2[_aggregate__B, _ParFlatHashTable__T, _aggregate__B], combop: scala.Function2[_aggregate__B, _aggregate__B, _aggregate__B]) -> _aggregate__B: ...
        _appendParIterable__U = typing.TypeVar('_appendParIterable__U')  # <U>
        _appendParIterable__PI = typing.TypeVar('_appendParIterable__PI', bound=scala.collection.parallel.IterableSplitter)  # <PI>
        def appendParIterable(self, that: _appendParIterable__PI) -> scala.collection.parallel.IterableSplitter.Appended[_appendParIterable__U, _appendParIterable__PI]: ...
        def buffered(self) -> scala.collection.BufferedIterator[_ParFlatHashTable__T]: ...
        def buildString(self, closure: scala.Function1[scala.Function1[str, scala.runtime.BoxedUnit], scala.runtime.BoxedUnit]) -> str: ...
        def calcNumElems(self, from_: int, until: int, tableLength: int, sizeMapBucketSize: int) -> int: ...
        _collect__B = typing.TypeVar('_collect__B')  # <B>
        def collect(self, pf: scala.PartialFunction[_ParFlatHashTable__T, _collect__B]) -> scala.collection.Iterator[_collect__B]: ...
        _collect2combiner__S = typing.TypeVar('_collect2combiner__S')  # <S>
        _collect2combiner__That = typing.TypeVar('_collect2combiner__That')  # <That>
        def collect2combiner(self, pf: scala.PartialFunction[_ParFlatHashTable__T, _collect2combiner__S], cb: scala.collection.parallel.Combiner[_collect2combiner__S, _collect2combiner__That]) -> scala.collection.parallel.Combiner[_collect2combiner__S, _collect2combiner__That]: ...
        _collectFirst__B = typing.TypeVar('_collectFirst__B')  # <B>
        def collectFirst(self, pf: scala.PartialFunction[_ParFlatHashTable__T, _collectFirst__B]) -> scala.Option[_collectFirst__B]: ...
        def contains(self, elem: typing.Any) -> bool: ...
        _copy2builder__U = typing.TypeVar('_copy2builder__U')  # <U>
        _copy2builder__Coll = typing.TypeVar('_copy2builder__Coll')  # <Coll>
        _copy2builder__Bld = typing.TypeVar('_copy2builder__Bld', bound=scala.collection.mutable.Builder)  # <Bld>
        def copy2builder(self, b: _copy2builder__Bld) -> _copy2builder__Bld: ...
        _copyToArray_0__B = typing.TypeVar('_copyToArray_0__B')  # <B>
        _copyToArray_1__B = typing.TypeVar('_copyToArray_1__B')  # <B>
        _copyToArray_2__U = typing.TypeVar('_copyToArray_2__U')  # <U>
        @typing.overload
        def copyToArray(self, xs: typing.Any) -> None: ...
        @typing.overload
        def copyToArray(self, xs: typing.Any, start: int) -> None: ...
        @typing.overload
        def copyToArray(self, array: typing.Any, from_: int, len: int) -> None: ...
        _copyToBuffer__B = typing.TypeVar('_copyToBuffer__B')  # <B>
        def copyToBuffer(self, dest: scala.collection.mutable.Buffer[_copyToBuffer__B]) -> None: ...
        _corresponds__B = typing.TypeVar('_corresponds__B')  # <B>
        def corresponds(self, that: scala.collection.GenTraversableOnce[_corresponds__B], p: scala.Function2[_ParFlatHashTable__T, _corresponds__B, typing.Any]) -> bool: ...
        def count(self, p: scala.Function1[_ParFlatHashTable__T, typing.Any]) -> int: ...
        def countBucketSizes(self, frombucket: int, untilbucket: int) -> int: ...
        def countElems(self, from_: int, until: int) -> int: ...
        def debugInformation(self) -> str: ...
        def drop(self, n: int) -> scala.collection.parallel.IterableSplitter[_ParFlatHashTable__T]: ...
        _drop2combiner__U = typing.TypeVar('_drop2combiner__U')  # <U>
        _drop2combiner__This = typing.TypeVar('_drop2combiner__This')  # <This>
        def drop2combiner(self, n: int, cb: scala.collection.parallel.Combiner[_drop2combiner__U, _drop2combiner__This]) -> scala.collection.parallel.Combiner[_drop2combiner__U, _drop2combiner__This]: ...
        def dropWhile(self, p: scala.Function1[_ParFlatHashTable__T, typing.Any]) -> scala.collection.Iterator[_ParFlatHashTable__T]: ...
        def dup(self) -> scala.collection.parallel.IterableSplitter[_ParFlatHashTable__T]: ...
        def duplicate(self) -> scala.Tuple2[scala.collection.Iterator[_ParFlatHashTable__T], scala.collection.Iterator[_ParFlatHashTable__T]]: ...
        def exists(self, p: scala.Function1[_ParFlatHashTable__T, typing.Any]) -> bool: ...
        def filter(self, p: scala.Function1[_ParFlatHashTable__T, typing.Any]) -> scala.collection.Iterator[_ParFlatHashTable__T]: ...
        _filter2combiner__U = typing.TypeVar('_filter2combiner__U')  # <U>
        _filter2combiner__This = typing.TypeVar('_filter2combiner__This')  # <This>
        def filter2combiner(self, pred: scala.Function1[_ParFlatHashTable__T, typing.Any], cb: scala.collection.parallel.Combiner[_filter2combiner__U, _filter2combiner__This]) -> scala.collection.parallel.Combiner[_filter2combiner__U, _filter2combiner__This]: ...
        def filterNot(self, p: scala.Function1[_ParFlatHashTable__T, typing.Any]) -> scala.collection.Iterator[_ParFlatHashTable__T]: ...
        _filterNot2combiner__U = typing.TypeVar('_filterNot2combiner__U')  # <U>
        _filterNot2combiner__This = typing.TypeVar('_filterNot2combiner__This')  # <This>
        def filterNot2combiner(self, pred: scala.Function1[_ParFlatHashTable__T, typing.Any], cb: scala.collection.parallel.Combiner[_filterNot2combiner__U, _filterNot2combiner__This]) -> scala.collection.parallel.Combiner[_filterNot2combiner__U, _filterNot2combiner__This]: ...
        def find(self, p: scala.Function1[_ParFlatHashTable__T, typing.Any]) -> scala.Option[_ParFlatHashTable__T]: ...
        _flatMap__B = typing.TypeVar('_flatMap__B')  # <B>
        def flatMap(self, f: scala.Function1[_ParFlatHashTable__T, scala.collection.GenTraversableOnce[_flatMap__B]]) -> scala.collection.Iterator[_flatMap__B]: ...
        _flatmap2combiner__S = typing.TypeVar('_flatmap2combiner__S')  # <S>
        _flatmap2combiner__That = typing.TypeVar('_flatmap2combiner__That')  # <That>
        def flatmap2combiner(self, f: scala.Function1[_ParFlatHashTable__T, scala.collection.GenTraversableOnce[_flatmap2combiner__S]], cb: scala.collection.parallel.Combiner[_flatmap2combiner__S, _flatmap2combiner__That]) -> scala.collection.parallel.Combiner[_flatmap2combiner__S, _flatmap2combiner__That]: ...
        _fold__U = typing.TypeVar('_fold__U')  # <U>
        def fold(self, z: _fold__U, op: scala.Function2[_fold__U, _fold__U, _fold__U]) -> _fold__U: ...
        _foldLeft__B = typing.TypeVar('_foldLeft__B')  # <B>
        def foldLeft(self, z: _foldLeft__B, op: scala.Function2[_foldLeft__B, _ParFlatHashTable__T, _foldLeft__B]) -> _foldLeft__B: ...
        _foldRight__B = typing.TypeVar('_foldRight__B')  # <B>
        def foldRight(self, z: _foldRight__B, op: scala.Function2[_ParFlatHashTable__T, _foldRight__B, _foldRight__B]) -> _foldRight__B: ...
        def forall(self, p: scala.Function1[_ParFlatHashTable__T, typing.Any]) -> bool: ...
        _foreach__U = typing.TypeVar('_foreach__U')  # <U>
        def foreach(self, f: scala.Function1[_ParFlatHashTable__T, _foreach__U]) -> None: ...
        _grouped__B = typing.TypeVar('_grouped__B')  # <B>
        def grouped(self, size: int) -> scala.collection.Iterator.GroupedIterator[_grouped__B]: ...
        def hasDefiniteSize(self) -> bool: ...
        def hasNext(self) -> bool: ...
        def idx(self) -> int: ...
        def idx_$eq(self, x$1: int) -> None: ...
        def indexFlag(self) -> int: ...
        _indexOf_0__B = typing.TypeVar('_indexOf_0__B')  # <B>
        _indexOf_1__B = typing.TypeVar('_indexOf_1__B')  # <B>
        @typing.overload
        def indexOf(self, elem: _indexOf_0__B) -> int: ...
        @typing.overload
        def indexOf(self, elem: _indexOf_1__B, from_: int) -> int: ...
        @typing.overload
        def indexWhere(self, p: scala.Function1[_ParFlatHashTable__T, typing.Any]) -> int: ...
        @typing.overload
        def indexWhere(self, p: scala.Function1[_ParFlatHashTable__T, typing.Any], from_: int) -> int: ...
        def isAborted(self) -> bool: ...
        def isEmpty(self) -> bool: ...
        def isRemainingCheap(self) -> bool: ...
        def isTraversableAgain(self) -> bool: ...
        def length(self) -> int: ...
        _map__S = typing.TypeVar('_map__S')  # <S>
        def map(self, f: scala.Function1[_ParFlatHashTable__T, _map__S]) -> scala.collection.parallel.IterableSplitter.Mapped[_map__S]: ...
        _map2combiner__S = typing.TypeVar('_map2combiner__S')  # <S>
        _map2combiner__That = typing.TypeVar('_map2combiner__That')  # <That>
        def map2combiner(self, f: scala.Function1[_ParFlatHashTable__T, _map2combiner__S], cb: scala.collection.parallel.Combiner[_map2combiner__S, _map2combiner__That]) -> scala.collection.parallel.Combiner[_map2combiner__S, _map2combiner__That]: ...
        _max__U = typing.TypeVar('_max__U')  # <U>
        def max(self, ord: scala.math.Ordering[_max__U]) -> _ParFlatHashTable__T: ...
        _maxBy__B = typing.TypeVar('_maxBy__B')  # <B>
        def maxBy(self, f: scala.Function1[_ParFlatHashTable__T, _maxBy__B], cmp: scala.math.Ordering[_maxBy__B]) -> _ParFlatHashTable__T: ...
        _min__U = typing.TypeVar('_min__U')  # <U>
        def min(self, ord: scala.math.Ordering[_min__U]) -> _ParFlatHashTable__T: ...
        _minBy__B = typing.TypeVar('_minBy__B')  # <B>
        def minBy(self, f: scala.Function1[_ParFlatHashTable__T, _minBy__B], cmp: scala.math.Ordering[_minBy__B]) -> _ParFlatHashTable__T: ...
        @typing.overload
        def mkString(self) -> str: ...
        @typing.overload
        def mkString(self, sep: str) -> str: ...
        @typing.overload
        def mkString(self, start: str, sep: str, end: str) -> str: ...
        def newIterator(self, index: int, until: int, totalsize: int) -> scala.collection.parallel.IterableSplitter[_ParFlatHashTable__T]: ...
        _newSliceInternal__U = typing.TypeVar('_newSliceInternal__U', bound=scala.collection.parallel.IterableSplitter.Taken)  # <U>
        def newSliceInternal(self, it: _newSliceInternal__U, from1: int) -> _newSliceInternal__U: ...
        def newTaken(self, until: int) -> scala.collection.parallel.IterableSplitter.Taken: ...
        def next(self) -> _ParFlatHashTable__T: ...
        def nonEmpty(self) -> bool: ...
        _padTo__A1 = typing.TypeVar('_padTo__A1')  # <A1>
        def padTo(self, len: int, elem: _padTo__A1) -> scala.collection.Iterator[_padTo__A1]: ...
        def partition(self, p: scala.Function1[_ParFlatHashTable__T, typing.Any]) -> scala.Tuple2[scala.collection.Iterator[_ParFlatHashTable__T], scala.collection.Iterator[_ParFlatHashTable__T]]: ...
        _partition2combiners__U = typing.TypeVar('_partition2combiners__U')  # <U>
        _partition2combiners__This = typing.TypeVar('_partition2combiners__This')  # <This>
        def partition2combiners(self, pred: scala.Function1[_ParFlatHashTable__T, typing.Any], btrue: scala.collection.parallel.Combiner[_partition2combiners__U, _partition2combiners__This], bfalse: scala.collection.parallel.Combiner[_partition2combiners__U, _partition2combiners__This]) -> scala.Tuple2[scala.collection.parallel.Combiner[_partition2combiners__U, _partition2combiners__This], scala.collection.parallel.Combiner[_partition2combiners__U, _partition2combiners__This]]: ...
        _patch__B = typing.TypeVar('_patch__B')  # <B>
        def patch(self, from_: int, patchElems: scala.collection.Iterator[_patch__B], replaced: int) -> scala.collection.Iterator[_patch__B]: ...
        _product__U = typing.TypeVar('_product__U')  # <U>
        def product(self, num: scala.math.Numeric[_product__U]) -> _product__U: ...
        _reduce__U = typing.TypeVar('_reduce__U')  # <U>
        def reduce(self, op: scala.Function2[_reduce__U, _reduce__U, _reduce__U]) -> _reduce__U: ...
        _reduceLeft_0__U = typing.TypeVar('_reduceLeft_0__U')  # <U>
        _reduceLeft_1__B = typing.TypeVar('_reduceLeft_1__B')  # <B>
        @typing.overload
        def reduceLeft(self, howmany: int, op: scala.Function2[_reduceLeft_0__U, _reduceLeft_0__U, _reduceLeft_0__U]) -> _reduceLeft_0__U: ...
        @typing.overload
        def reduceLeft(self, op: scala.Function2[_reduceLeft_1__B, _ParFlatHashTable__T, _reduceLeft_1__B]) -> _reduceLeft_1__B: ...
        _reduceLeftOption__B = typing.TypeVar('_reduceLeftOption__B')  # <B>
        def reduceLeftOption(self, op: scala.Function2[_reduceLeftOption__B, _ParFlatHashTable__T, _reduceLeftOption__B]) -> scala.Option[_reduceLeftOption__B]: ...
        _reduceOption__A1 = typing.TypeVar('_reduceOption__A1')  # <A1>
        def reduceOption(self, op: scala.Function2[_reduceOption__A1, _reduceOption__A1, _reduceOption__A1]) -> scala.Option[_reduceOption__A1]: ...
        _reduceRight__B = typing.TypeVar('_reduceRight__B')  # <B>
        def reduceRight(self, op: scala.Function2[_ParFlatHashTable__T, _reduceRight__B, _reduceRight__B]) -> _reduceRight__B: ...
        _reduceRightOption__B = typing.TypeVar('_reduceRightOption__B')  # <B>
        def reduceRightOption(self, op: scala.Function2[_ParFlatHashTable__T, _reduceRightOption__B, _reduceRightOption__B]) -> scala.Option[_reduceRightOption__B]: ...
        def remaining(self) -> int: ...
        def reversed(self) -> scala.collection.immutable.List[_ParFlatHashTable__T]: ...
        def sameElements(self, that: scala.collection.Iterator[typing.Any]) -> bool: ...
        _scanLeft__B = typing.TypeVar('_scanLeft__B')  # <B>
        def scanLeft(self, z: _scanLeft__B, op: scala.Function2[_scanLeft__B, _ParFlatHashTable__T, _scanLeft__B]) -> scala.collection.Iterator[_scanLeft__B]: ...
        _scanRight__B = typing.TypeVar('_scanRight__B')  # <B>
        def scanRight(self, z: _scanRight__B, op: scala.Function2[_ParFlatHashTable__T, _scanRight__B, _scanRight__B]) -> scala.collection.Iterator[_scanRight__B]: ...
        _scanToArray__U = typing.TypeVar('_scanToArray__U')  # <U>
        _scanToArray__A = typing.TypeVar('_scanToArray__A')  # <A>
        def scanToArray(self, z: _scanToArray__U, op: scala.Function2[_scanToArray__U, _scanToArray__U, _scanToArray__U], array: typing.Any, from_: int) -> None: ...
        _scanToCombiner_0__U = typing.TypeVar('_scanToCombiner_0__U')  # <U>
        _scanToCombiner_0__That = typing.TypeVar('_scanToCombiner_0__That')  # <That>
        _scanToCombiner_1__U = typing.TypeVar('_scanToCombiner_1__U')  # <U>
        _scanToCombiner_1__That = typing.TypeVar('_scanToCombiner_1__That')  # <That>
        @typing.overload
        def scanToCombiner(self, howmany: int, startValue: _scanToCombiner_0__U, op: scala.Function2[_scanToCombiner_0__U, _scanToCombiner_0__U, _scanToCombiner_0__U], cb: scala.collection.parallel.Combiner[_scanToCombiner_0__U, _scanToCombiner_0__That]) -> scala.collection.parallel.Combiner[_scanToCombiner_0__U, _scanToCombiner_0__That]: ...
        @typing.overload
        def scanToCombiner(self, startValue: _scanToCombiner_1__U, op: scala.Function2[_scanToCombiner_1__U, _scanToCombiner_1__U, _scanToCombiner_1__U], cb: scala.collection.parallel.Combiner[_scanToCombiner_1__U, _scanToCombiner_1__That]) -> scala.collection.parallel.Combiner[_scanToCombiner_1__U, _scanToCombiner_1__That]: ...
        def seq(self) -> scala.collection.Iterator[_ParFlatHashTable__T]: ...
        def setIndexFlag(self, f: int) -> None: ...
        def setIndexFlagIfGreater(self, f: int) -> None: ...
        def setIndexFlagIfLesser(self, f: int) -> None: ...
        _shouldSplitFurther__S = typing.TypeVar('_shouldSplitFurther__S')  # <S>
        def shouldSplitFurther(self, coll: scala.collection.parallel.ParIterable[_shouldSplitFurther__S], parallelismLevel: int) -> bool: ...
        def signalDelegate(self) -> scala.collection.generic.Signalling: ...
        def signalDelegate_$eq(self, x$1: scala.collection.generic.Signalling) -> None: ...
        def size(self) -> int: ...
        def sizeHintIfCheap(self) -> int: ...
        def slice(self, from1: int, until1: int) -> scala.collection.parallel.IterableSplitter[_ParFlatHashTable__T]: ...
        _slice2combiner__U = typing.TypeVar('_slice2combiner__U')  # <U>
        _slice2combiner__This = typing.TypeVar('_slice2combiner__This')  # <This>
        def slice2combiner(self, from_: int, until: int, cb: scala.collection.parallel.Combiner[_slice2combiner__U, _slice2combiner__This]) -> scala.collection.parallel.Combiner[_slice2combiner__U, _slice2combiner__This]: ...
        def sliceIterator(self, from_: int, until: int) -> scala.collection.Iterator[_ParFlatHashTable__T]: ...
        _sliding__B = typing.TypeVar('_sliding__B')  # <B>
        def sliding(self, size: int, step: int) -> scala.collection.Iterator.GroupedIterator[_sliding__B]: ...
        _sliding$default$2__B = typing.TypeVar('_sliding$default$2__B')  # <B>
        def sliding$default$2(self) -> int: ...
        def span(self, p: scala.Function1[_ParFlatHashTable__T, typing.Any]) -> scala.Tuple2[scala.collection.Iterator[_ParFlatHashTable__T], scala.collection.Iterator[_ParFlatHashTable__T]]: ...
        _span2combiners__U = typing.TypeVar('_span2combiners__U')  # <U>
        _span2combiners__This = typing.TypeVar('_span2combiners__This')  # <This>
        def span2combiners(self, p: scala.Function1[_ParFlatHashTable__T, typing.Any], before: scala.collection.parallel.Combiner[_span2combiners__U, _span2combiners__This], after: scala.collection.parallel.Combiner[_span2combiners__U, _span2combiners__This]) -> scala.Tuple2[scala.collection.parallel.Combiner[_span2combiners__U, _span2combiners__This], scala.collection.parallel.Combiner[_span2combiners__U, _span2combiners__This]]: ...
        def split(self) -> scala.collection.Seq[scala.collection.parallel.IterableSplitter[_ParFlatHashTable__T]]: ...
        _splitAt2combiners__U = typing.TypeVar('_splitAt2combiners__U')  # <U>
        _splitAt2combiners__This = typing.TypeVar('_splitAt2combiners__This')  # <This>
        def splitAt2combiners(self, at: int, before: scala.collection.parallel.Combiner[_splitAt2combiners__U, _splitAt2combiners__This], after: scala.collection.parallel.Combiner[_splitAt2combiners__U, _splitAt2combiners__This]) -> scala.Tuple2[scala.collection.parallel.Combiner[_splitAt2combiners__U, _splitAt2combiners__This], scala.collection.parallel.Combiner[_splitAt2combiners__U, _splitAt2combiners__This]]: ...
        def splitWithSignalling(self) -> scala.collection.Seq[scala.collection.parallel.IterableSplitter[_ParFlatHashTable__T]]: ...
        _sum__U = typing.TypeVar('_sum__U')  # <U>
        def sum(self, num: scala.math.Numeric[_sum__U]) -> _sum__U: ...
        def tag(self) -> int: ...
        def take(self, n: int) -> scala.collection.parallel.IterableSplitter[_ParFlatHashTable__T]: ...
        _take2combiner__U = typing.TypeVar('_take2combiner__U')  # <U>
        _take2combiner__This = typing.TypeVar('_take2combiner__This')  # <This>
        def take2combiner(self, n: int, cb: scala.collection.parallel.Combiner[_take2combiner__U, _take2combiner__This]) -> scala.collection.parallel.Combiner[_take2combiner__U, _take2combiner__This]: ...
        def takeWhile(self, p: scala.Function1[_ParFlatHashTable__T, typing.Any]) -> scala.collection.Iterator[_ParFlatHashTable__T]: ...
        _takeWhile2combiner__U = typing.TypeVar('_takeWhile2combiner__U')  # <U>
        _takeWhile2combiner__This = typing.TypeVar('_takeWhile2combiner__This')  # <This>
        def takeWhile2combiner(self, p: scala.Function1[_ParFlatHashTable__T, typing.Any], cb: scala.collection.parallel.Combiner[_takeWhile2combiner__U, _takeWhile2combiner__This]) -> scala.Tuple2[scala.collection.parallel.Combiner[_takeWhile2combiner__U, _takeWhile2combiner__This], typing.Any]: ...
        _to__Col = typing.TypeVar('_to__Col')  # <Col>
        def to(self, cbf: scala.collection.generic.CanBuildFrom[scala.runtime.Nothing., _ParFlatHashTable__T, _to__Col]) -> _to__Col: ...
        _toArray__B = typing.TypeVar('_toArray__B')  # <B>
        def toArray(self, evidence$1: scala.reflect.ClassTag[_toArray__B]) -> typing.Any: ...
        _toBuffer__B = typing.TypeVar('_toBuffer__B')  # <B>
        def toBuffer(self) -> scala.collection.mutable.Buffer[_toBuffer__B]: ...
        def toIndexedSeq(self) -> scala.collection.immutable.IndexedSeq[_ParFlatHashTable__T]: ...
        def toIterable(self) -> scala.collection.Iterable[_ParFlatHashTable__T]: ...
        def toIterator(self) -> scala.collection.Iterator[_ParFlatHashTable__T]: ...
        def toList(self) -> scala.collection.immutable.List[_ParFlatHashTable__T]: ...
        _toMap__T = typing.TypeVar('_toMap__T')  # <T>
        _toMap__U = typing.TypeVar('_toMap__U')  # <U>
        def toMap(self, ev: scala.Predef..less.colon.less[typing.Any, scala.Tuple2[typing.Any, _toMap__U]]) -> scala.collection.immutable.Map[typing.Any, _toMap__U]: ...
        def toSeq(self) -> scala.collection.Seq[_ParFlatHashTable__T]: ...
        _toSet__B = typing.TypeVar('_toSet__B')  # <B>
        def toSet(self) -> scala.collection.immutable.Set[_toSet__B]: ...
        def toStream(self) -> scala.collection.immutable.Stream[_ParFlatHashTable__T]: ...
        def toString(self) -> str: ...
        def toTraversable(self) -> scala.collection.Traversable[_ParFlatHashTable__T]: ...
        def toVector(self) -> scala.collection.immutable.Vector[_ParFlatHashTable__T]: ...
        def totalsize(self) -> int: ...
        def until(self) -> int: ...
        def withFilter(self, p: scala.Function1[_ParFlatHashTable__T, typing.Any]) -> scala.collection.Iterator[_ParFlatHashTable__T]: ...
        _zip__B = typing.TypeVar('_zip__B')  # <B>
        def zip(self, that: scala.collection.Iterator[_zip__B]) -> scala.collection.Iterator[scala.Tuple2[_ParFlatHashTable__T, _zip__B]]: ...
        _zip2combiner__U = typing.TypeVar('_zip2combiner__U')  # <U>
        _zip2combiner__S = typing.TypeVar('_zip2combiner__S')  # <S>
        _zip2combiner__That = typing.TypeVar('_zip2combiner__That')  # <That>
        def zip2combiner(self, otherpit: scala.collection.parallel.RemainsIterator[_zip2combiner__S], cb: scala.collection.parallel.Combiner[scala.Tuple2[_zip2combiner__U, _zip2combiner__S], _zip2combiner__That]) -> scala.collection.parallel.Combiner[scala.Tuple2[_zip2combiner__U, _zip2combiner__S], _zip2combiner__That]: ...
        _zipAll__B = typing.TypeVar('_zipAll__B')  # <B>
        _zipAll__A1 = typing.TypeVar('_zipAll__A1')  # <A1>
        _zipAll__B1 = typing.TypeVar('_zipAll__B1')  # <B1>
        def zipAll(self, that: scala.collection.Iterator[_zipAll__B], thisElem: _zipAll__A1, thatElem: _zipAll__B1) -> scala.collection.Iterator[scala.Tuple2[_zipAll__A1, _zipAll__B1]]: ...
        _zipAll2combiner__U = typing.TypeVar('_zipAll2combiner__U')  # <U>
        _zipAll2combiner__S = typing.TypeVar('_zipAll2combiner__S')  # <S>
        _zipAll2combiner__That = typing.TypeVar('_zipAll2combiner__That')  # <That>
        def zipAll2combiner(self, that: scala.collection.parallel.RemainsIterator[_zipAll2combiner__S], thiselem: _zipAll2combiner__U, thatelem: _zipAll2combiner__S, cb: scala.collection.parallel.Combiner[scala.Tuple2[_zipAll2combiner__U, _zipAll2combiner__S], _zipAll2combiner__That]) -> scala.collection.parallel.Combiner[scala.Tuple2[_zipAll2combiner__U, _zipAll2combiner__S], _zipAll2combiner__That]: ...
        _zipAllParSeq__S = typing.TypeVar('_zipAllParSeq__S')  # <S>
        _zipAllParSeq__U = typing.TypeVar('_zipAllParSeq__U')  # <U>
        _zipAllParSeq__R = typing.TypeVar('_zipAllParSeq__R')  # <R>
        def zipAllParSeq(self, that: scala.collection.parallel.SeqSplitter[_zipAllParSeq__S], thisElem: _zipAllParSeq__U, thatElem: _zipAllParSeq__R) -> scala.collection.parallel.IterableSplitter.ZippedAll[_zipAllParSeq__U, _zipAllParSeq__R]: ...
        _zipParSeq__S = typing.TypeVar('_zipParSeq__S')  # <S>
        def zipParSeq(self, that: scala.collection.parallel.SeqSplitter[_zipParSeq__S]) -> scala.collection.parallel.IterableSplitter.Zipped[_zipParSeq__S]: ...
        def zipWithIndex(self) -> scala.collection.Iterator[scala.Tuple2[_ParFlatHashTable__T, typing.Any]]: ...

_ParHashTable__EntryIterator__T = typing.TypeVar('_ParHashTable__EntryIterator__T')  # <T>
_ParHashTable__EntryIterator__IterRepr = typing.TypeVar('_ParHashTable__EntryIterator__IterRepr', bound=scala.collection.parallel.IterableSplitter)  # <IterRepr>
_ParHashTable__K = typing.TypeVar('_ParHashTable__K')  # <K>
_ParHashTable__Entry = typing.TypeVar('_ParHashTable__Entry', bound=scala.collection.mutable.HashEntry)  # <Entry>
class ParHashTable(scala.collection.mutable.HashTable[_ParHashTable__K, _ParHashTable__Entry], typing.Generic[_ParHashTable__K, _ParHashTable__Entry]):
    @staticmethod
    def $init$($this: 'ParHashTable') -> None: ...
    def alwaysInitSizeMap(self) -> bool: ...
    class EntryIterator(scala.collection.parallel.IterableSplitter[_ParHashTable__EntryIterator__T], SizeMapUtils, typing.Generic[_ParHashTable__EntryIterator__T, _ParHashTable__EntryIterator__IterRepr]):
        $outer: 'ParHashTable' = ...
        def __init__(self, $outer: 'ParHashTable', idx: int, until: int, totalsize: int, es: _ParHashTable__Entry): ...
        _$colon$bslash__B = typing.TypeVar('_$colon$bslash__B')  # <B>
        def $colon$bslash(self, z: _.colon.bslash__B, op: scala.Function2[_ParHashTable__EntryIterator__T, _.colon.bslash__B, _.colon.bslash__B]) -> _.colon.bslash__B: ...
        _$div$colon__B = typing.TypeVar('_$div$colon__B')  # <B>
        def $div$colon(self, z: _.div.colon__B, op: scala.Function2[_.div.colon__B, _ParHashTable__EntryIterator__T, _.div.colon__B]) -> _.div.colon__B: ...
        _$plus$plus__B = typing.TypeVar('_$plus$plus__B')  # <B>
        def $plus$plus(self, that: scala.Function0[scala.collection.GenTraversableOnce[_.plus.plus__B]]) -> scala.collection.Iterator[_.plus.plus__B]: ...
        def abort(self) -> None: ...
        @typing.overload
        def addString(self, b: scala.collection.mutable.StringBuilder) -> scala.collection.mutable.StringBuilder: ...
        @typing.overload
        def addString(self, b: scala.collection.mutable.StringBuilder, sep: str) -> scala.collection.mutable.StringBuilder: ...
        @typing.overload
        def addString(self, b: scala.collection.mutable.StringBuilder, start: str, sep: str, end: str) -> scala.collection.mutable.StringBuilder: ...
        _aggregate__B = typing.TypeVar('_aggregate__B')  # <B>
        def aggregate(self, z: scala.Function0[_aggregate__B], seqop: scala.Function2[_aggregate__B, _ParHashTable__EntryIterator__T, _aggregate__B], combop: scala.Function2[_aggregate__B, _aggregate__B, _aggregate__B]) -> _aggregate__B: ...
        _appendParIterable__U = typing.TypeVar('_appendParIterable__U')  # <U>
        _appendParIterable__PI = typing.TypeVar('_appendParIterable__PI', bound=scala.collection.parallel.IterableSplitter)  # <PI>
        def appendParIterable(self, that: _appendParIterable__PI) -> scala.collection.parallel.IterableSplitter.Appended[_appendParIterable__U, _appendParIterable__PI]: ...
        def buffered(self) -> scala.collection.BufferedIterator[_ParHashTable__EntryIterator__T]: ...
        def buildString(self, closure: scala.Function1[scala.Function1[str, scala.runtime.BoxedUnit], scala.runtime.BoxedUnit]) -> str: ...
        def calcNumElems(self, from_: int, until: int, tableLength: int, sizeMapBucketSize: int) -> int: ...
        _collect__B = typing.TypeVar('_collect__B')  # <B>
        def collect(self, pf: scala.PartialFunction[_ParHashTable__EntryIterator__T, _collect__B]) -> scala.collection.Iterator[_collect__B]: ...
        _collect2combiner__S = typing.TypeVar('_collect2combiner__S')  # <S>
        _collect2combiner__That = typing.TypeVar('_collect2combiner__That')  # <That>
        def collect2combiner(self, pf: scala.PartialFunction[_ParHashTable__EntryIterator__T, _collect2combiner__S], cb: scala.collection.parallel.Combiner[_collect2combiner__S, _collect2combiner__That]) -> scala.collection.parallel.Combiner[_collect2combiner__S, _collect2combiner__That]: ...
        _collectFirst__B = typing.TypeVar('_collectFirst__B')  # <B>
        def collectFirst(self, pf: scala.PartialFunction[_ParHashTable__EntryIterator__T, _collectFirst__B]) -> scala.Option[_collectFirst__B]: ...
        def contains(self, elem: typing.Any) -> bool: ...
        _copy2builder__U = typing.TypeVar('_copy2builder__U')  # <U>
        _copy2builder__Coll = typing.TypeVar('_copy2builder__Coll')  # <Coll>
        _copy2builder__Bld = typing.TypeVar('_copy2builder__Bld', bound=scala.collection.mutable.Builder)  # <Bld>
        def copy2builder(self, b: _copy2builder__Bld) -> _copy2builder__Bld: ...
        _copyToArray_0__B = typing.TypeVar('_copyToArray_0__B')  # <B>
        _copyToArray_1__B = typing.TypeVar('_copyToArray_1__B')  # <B>
        _copyToArray_2__U = typing.TypeVar('_copyToArray_2__U')  # <U>
        @typing.overload
        def copyToArray(self, xs: typing.Any) -> None: ...
        @typing.overload
        def copyToArray(self, xs: typing.Any, start: int) -> None: ...
        @typing.overload
        def copyToArray(self, array: typing.Any, from_: int, len: int) -> None: ...
        _copyToBuffer__B = typing.TypeVar('_copyToBuffer__B')  # <B>
        def copyToBuffer(self, dest: scala.collection.mutable.Buffer[_copyToBuffer__B]) -> None: ...
        _corresponds__B = typing.TypeVar('_corresponds__B')  # <B>
        def corresponds(self, that: scala.collection.GenTraversableOnce[_corresponds__B], p: scala.Function2[_ParHashTable__EntryIterator__T, _corresponds__B, typing.Any]) -> bool: ...
        def count(self, p: scala.Function1[_ParHashTable__EntryIterator__T, typing.Any]) -> int: ...
        def countBucketSizes(self, fromBucket: int, untilBucket: int) -> int: ...
        def countElems(self, from_: int, until: int) -> int: ...
        def debugInformation(self) -> str: ...
        def drop(self, n: int) -> scala.collection.parallel.IterableSplitter[_ParHashTable__EntryIterator__T]: ...
        _drop2combiner__U = typing.TypeVar('_drop2combiner__U')  # <U>
        _drop2combiner__This = typing.TypeVar('_drop2combiner__This')  # <This>
        def drop2combiner(self, n: int, cb: scala.collection.parallel.Combiner[_drop2combiner__U, _drop2combiner__This]) -> scala.collection.parallel.Combiner[_drop2combiner__U, _drop2combiner__This]: ...
        def dropWhile(self, p: scala.Function1[_ParHashTable__EntryIterator__T, typing.Any]) -> scala.collection.Iterator[_ParHashTable__EntryIterator__T]: ...
        def dup(self) -> _ParHashTable__EntryIterator__IterRepr: ...
        def duplicate(self) -> scala.Tuple2[scala.collection.Iterator[_ParHashTable__EntryIterator__T], scala.collection.Iterator[_ParHashTable__EntryIterator__T]]: ...
        def entry2item(self, e: _ParHashTable__Entry) -> _ParHashTable__EntryIterator__T: ...
        def exists(self, p: scala.Function1[_ParHashTable__EntryIterator__T, typing.Any]) -> bool: ...
        def filter(self, p: scala.Function1[_ParHashTable__EntryIterator__T, typing.Any]) -> scala.collection.Iterator[_ParHashTable__EntryIterator__T]: ...
        _filter2combiner__U = typing.TypeVar('_filter2combiner__U')  # <U>
        _filter2combiner__This = typing.TypeVar('_filter2combiner__This')  # <This>
        def filter2combiner(self, pred: scala.Function1[_ParHashTable__EntryIterator__T, typing.Any], cb: scala.collection.parallel.Combiner[_filter2combiner__U, _filter2combiner__This]) -> scala.collection.parallel.Combiner[_filter2combiner__U, _filter2combiner__This]: ...
        def filterNot(self, p: scala.Function1[_ParHashTable__EntryIterator__T, typing.Any]) -> scala.collection.Iterator[_ParHashTable__EntryIterator__T]: ...
        _filterNot2combiner__U = typing.TypeVar('_filterNot2combiner__U')  # <U>
        _filterNot2combiner__This = typing.TypeVar('_filterNot2combiner__This')  # <This>
        def filterNot2combiner(self, pred: scala.Function1[_ParHashTable__EntryIterator__T, typing.Any], cb: scala.collection.parallel.Combiner[_filterNot2combiner__U, _filterNot2combiner__This]) -> scala.collection.parallel.Combiner[_filterNot2combiner__U, _filterNot2combiner__This]: ...
        def find(self, p: scala.Function1[_ParHashTable__EntryIterator__T, typing.Any]) -> scala.Option[_ParHashTable__EntryIterator__T]: ...
        _flatMap__B = typing.TypeVar('_flatMap__B')  # <B>
        def flatMap(self, f: scala.Function1[_ParHashTable__EntryIterator__T, scala.collection.GenTraversableOnce[_flatMap__B]]) -> scala.collection.Iterator[_flatMap__B]: ...
        _flatmap2combiner__S = typing.TypeVar('_flatmap2combiner__S')  # <S>
        _flatmap2combiner__That = typing.TypeVar('_flatmap2combiner__That')  # <That>
        def flatmap2combiner(self, f: scala.Function1[_ParHashTable__EntryIterator__T, scala.collection.GenTraversableOnce[_flatmap2combiner__S]], cb: scala.collection.parallel.Combiner[_flatmap2combiner__S, _flatmap2combiner__That]) -> scala.collection.parallel.Combiner[_flatmap2combiner__S, _flatmap2combiner__That]: ...
        _fold__U = typing.TypeVar('_fold__U')  # <U>
        def fold(self, z: _fold__U, op: scala.Function2[_fold__U, _fold__U, _fold__U]) -> _fold__U: ...
        _foldLeft__B = typing.TypeVar('_foldLeft__B')  # <B>
        def foldLeft(self, z: _foldLeft__B, op: scala.Function2[_foldLeft__B, _ParHashTable__EntryIterator__T, _foldLeft__B]) -> _foldLeft__B: ...
        _foldRight__B = typing.TypeVar('_foldRight__B')  # <B>
        def foldRight(self, z: _foldRight__B, op: scala.Function2[_ParHashTable__EntryIterator__T, _foldRight__B, _foldRight__B]) -> _foldRight__B: ...
        def forall(self, p: scala.Function1[_ParHashTable__EntryIterator__T, typing.Any]) -> bool: ...
        _foreach__U = typing.TypeVar('_foreach__U')  # <U>
        def foreach(self, f: scala.Function1[_ParHashTable__EntryIterator__T, _foreach__U]) -> None: ...
        _grouped__B = typing.TypeVar('_grouped__B')  # <B>
        def grouped(self, size: int) -> scala.collection.Iterator.GroupedIterator[_grouped__B]: ...
        def hasDefiniteSize(self) -> bool: ...
        def hasNext(self) -> bool: ...
        def indexFlag(self) -> int: ...
        _indexOf_0__B = typing.TypeVar('_indexOf_0__B')  # <B>
        _indexOf_1__B = typing.TypeVar('_indexOf_1__B')  # <B>
        @typing.overload
        def indexOf(self, elem: _indexOf_0__B) -> int: ...
        @typing.overload
        def indexOf(self, elem: _indexOf_1__B, from_: int) -> int: ...
        @typing.overload
        def indexWhere(self, p: scala.Function1[_ParHashTable__EntryIterator__T, typing.Any]) -> int: ...
        @typing.overload
        def indexWhere(self, p: scala.Function1[_ParHashTable__EntryIterator__T, typing.Any], from_: int) -> int: ...
        def isAborted(self) -> bool: ...
        def isEmpty(self) -> bool: ...
        def isRemainingCheap(self) -> bool: ...
        def isTraversableAgain(self) -> bool: ...
        def length(self) -> int: ...
        _map__S = typing.TypeVar('_map__S')  # <S>
        def map(self, f: scala.Function1[_ParHashTable__EntryIterator__T, _map__S]) -> scala.collection.parallel.IterableSplitter.Mapped[_map__S]: ...
        _map2combiner__S = typing.TypeVar('_map2combiner__S')  # <S>
        _map2combiner__That = typing.TypeVar('_map2combiner__That')  # <That>
        def map2combiner(self, f: scala.Function1[_ParHashTable__EntryIterator__T, _map2combiner__S], cb: scala.collection.parallel.Combiner[_map2combiner__S, _map2combiner__That]) -> scala.collection.parallel.Combiner[_map2combiner__S, _map2combiner__That]: ...
        _max__U = typing.TypeVar('_max__U')  # <U>
        def max(self, ord: scala.math.Ordering[_max__U]) -> _ParHashTable__EntryIterator__T: ...
        _maxBy__B = typing.TypeVar('_maxBy__B')  # <B>
        def maxBy(self, f: scala.Function1[_ParHashTable__EntryIterator__T, _maxBy__B], cmp: scala.math.Ordering[_maxBy__B]) -> _ParHashTable__EntryIterator__T: ...
        _min__U = typing.TypeVar('_min__U')  # <U>
        def min(self, ord: scala.math.Ordering[_min__U]) -> _ParHashTable__EntryIterator__T: ...
        _minBy__B = typing.TypeVar('_minBy__B')  # <B>
        def minBy(self, f: scala.Function1[_ParHashTable__EntryIterator__T, _minBy__B], cmp: scala.math.Ordering[_minBy__B]) -> _ParHashTable__EntryIterator__T: ...
        @typing.overload
        def mkString(self) -> str: ...
        @typing.overload
        def mkString(self, sep: str) -> str: ...
        @typing.overload
        def mkString(self, start: str, sep: str, end: str) -> str: ...
        def newIterator(self, idxFrom: int, idxUntil: int, totalSize: int, es: _ParHashTable__Entry) -> _ParHashTable__EntryIterator__IterRepr: ...
        _newSliceInternal__U = typing.TypeVar('_newSliceInternal__U', bound=scala.collection.parallel.IterableSplitter.Taken)  # <U>
        def newSliceInternal(self, it: _newSliceInternal__U, from1: int) -> _newSliceInternal__U: ...
        def newTaken(self, until: int) -> scala.collection.parallel.IterableSplitter.Taken: ...
        def next(self) -> _ParHashTable__EntryIterator__T: ...
        def nonEmpty(self) -> bool: ...
        _padTo__A1 = typing.TypeVar('_padTo__A1')  # <A1>
        def padTo(self, len: int, elem: _padTo__A1) -> scala.collection.Iterator[_padTo__A1]: ...
        def partition(self, p: scala.Function1[_ParHashTable__EntryIterator__T, typing.Any]) -> scala.Tuple2[scala.collection.Iterator[_ParHashTable__EntryIterator__T], scala.collection.Iterator[_ParHashTable__EntryIterator__T]]: ...
        _partition2combiners__U = typing.TypeVar('_partition2combiners__U')  # <U>
        _partition2combiners__This = typing.TypeVar('_partition2combiners__This')  # <This>
        def partition2combiners(self, pred: scala.Function1[_ParHashTable__EntryIterator__T, typing.Any], btrue: scala.collection.parallel.Combiner[_partition2combiners__U, _partition2combiners__This], bfalse: scala.collection.parallel.Combiner[_partition2combiners__U, _partition2combiners__This]) -> scala.Tuple2[scala.collection.parallel.Combiner[_partition2combiners__U, _partition2combiners__This], scala.collection.parallel.Combiner[_partition2combiners__U, _partition2combiners__This]]: ...
        _patch__B = typing.TypeVar('_patch__B')  # <B>
        def patch(self, from_: int, patchElems: scala.collection.Iterator[_patch__B], replaced: int) -> scala.collection.Iterator[_patch__B]: ...
        _product__U = typing.TypeVar('_product__U')  # <U>
        def product(self, num: scala.math.Numeric[_product__U]) -> _product__U: ...
        _reduce__U = typing.TypeVar('_reduce__U')  # <U>
        def reduce(self, op: scala.Function2[_reduce__U, _reduce__U, _reduce__U]) -> _reduce__U: ...
        _reduceLeft_0__U = typing.TypeVar('_reduceLeft_0__U')  # <U>
        _reduceLeft_1__B = typing.TypeVar('_reduceLeft_1__B')  # <B>
        @typing.overload
        def reduceLeft(self, howmany: int, op: scala.Function2[_reduceLeft_0__U, _reduceLeft_0__U, _reduceLeft_0__U]) -> _reduceLeft_0__U: ...
        @typing.overload
        def reduceLeft(self, op: scala.Function2[_reduceLeft_1__B, _ParHashTable__EntryIterator__T, _reduceLeft_1__B]) -> _reduceLeft_1__B: ...
        _reduceLeftOption__B = typing.TypeVar('_reduceLeftOption__B')  # <B>
        def reduceLeftOption(self, op: scala.Function2[_reduceLeftOption__B, _ParHashTable__EntryIterator__T, _reduceLeftOption__B]) -> scala.Option[_reduceLeftOption__B]: ...
        _reduceOption__A1 = typing.TypeVar('_reduceOption__A1')  # <A1>
        def reduceOption(self, op: scala.Function2[_reduceOption__A1, _reduceOption__A1, _reduceOption__A1]) -> scala.Option[_reduceOption__A1]: ...
        _reduceRight__B = typing.TypeVar('_reduceRight__B')  # <B>
        def reduceRight(self, op: scala.Function2[_ParHashTable__EntryIterator__T, _reduceRight__B, _reduceRight__B]) -> _reduceRight__B: ...
        _reduceRightOption__B = typing.TypeVar('_reduceRightOption__B')  # <B>
        def reduceRightOption(self, op: scala.Function2[_ParHashTable__EntryIterator__T, _reduceRightOption__B, _reduceRightOption__B]) -> scala.Option[_reduceRightOption__B]: ...
        def remaining(self) -> int: ...
        def reversed(self) -> scala.collection.immutable.List[_ParHashTable__EntryIterator__T]: ...
        def sameElements(self, that: scala.collection.Iterator[typing.Any]) -> bool: ...
        def scan(self) -> None: ...
        _scanLeft__B = typing.TypeVar('_scanLeft__B')  # <B>
        def scanLeft(self, z: _scanLeft__B, op: scala.Function2[_scanLeft__B, _ParHashTable__EntryIterator__T, _scanLeft__B]) -> scala.collection.Iterator[_scanLeft__B]: ...
        _scanRight__B = typing.TypeVar('_scanRight__B')  # <B>
        def scanRight(self, z: _scanRight__B, op: scala.Function2[_ParHashTable__EntryIterator__T, _scanRight__B, _scanRight__B]) -> scala.collection.Iterator[_scanRight__B]: ...
        _scanToArray__U = typing.TypeVar('_scanToArray__U')  # <U>
        _scanToArray__A = typing.TypeVar('_scanToArray__A')  # <A>
        def scanToArray(self, z: _scanToArray__U, op: scala.Function2[_scanToArray__U, _scanToArray__U, _scanToArray__U], array: typing.Any, from_: int) -> None: ...
        _scanToCombiner_0__U = typing.TypeVar('_scanToCombiner_0__U')  # <U>
        _scanToCombiner_0__That = typing.TypeVar('_scanToCombiner_0__That')  # <That>
        _scanToCombiner_1__U = typing.TypeVar('_scanToCombiner_1__U')  # <U>
        _scanToCombiner_1__That = typing.TypeVar('_scanToCombiner_1__That')  # <That>
        @typing.overload
        def scanToCombiner(self, howmany: int, startValue: _scanToCombiner_0__U, op: scala.Function2[_scanToCombiner_0__U, _scanToCombiner_0__U, _scanToCombiner_0__U], cb: scala.collection.parallel.Combiner[_scanToCombiner_0__U, _scanToCombiner_0__That]) -> scala.collection.parallel.Combiner[_scanToCombiner_0__U, _scanToCombiner_0__That]: ...
        @typing.overload
        def scanToCombiner(self, startValue: _scanToCombiner_1__U, op: scala.Function2[_scanToCombiner_1__U, _scanToCombiner_1__U, _scanToCombiner_1__U], cb: scala.collection.parallel.Combiner[_scanToCombiner_1__U, _scanToCombiner_1__That]) -> scala.collection.parallel.Combiner[_scanToCombiner_1__U, _scanToCombiner_1__That]: ...
        def seq(self) -> scala.collection.Iterator[_ParHashTable__EntryIterator__T]: ...
        def setIndexFlag(self, f: int) -> None: ...
        def setIndexFlagIfGreater(self, f: int) -> None: ...
        def setIndexFlagIfLesser(self, f: int) -> None: ...
        _shouldSplitFurther__S = typing.TypeVar('_shouldSplitFurther__S')  # <S>
        def shouldSplitFurther(self, coll: scala.collection.parallel.ParIterable[_shouldSplitFurther__S], parallelismLevel: int) -> bool: ...
        def signalDelegate(self) -> scala.collection.generic.Signalling: ...
        def signalDelegate_$eq(self, x$1: scala.collection.generic.Signalling) -> None: ...
        def size(self) -> int: ...
        def sizeHintIfCheap(self) -> int: ...
        def slice(self, from1: int, until1: int) -> scala.collection.parallel.IterableSplitter[_ParHashTable__EntryIterator__T]: ...
        _slice2combiner__U = typing.TypeVar('_slice2combiner__U')  # <U>
        _slice2combiner__This = typing.TypeVar('_slice2combiner__This')  # <This>
        def slice2combiner(self, from_: int, until: int, cb: scala.collection.parallel.Combiner[_slice2combiner__U, _slice2combiner__This]) -> scala.collection.parallel.Combiner[_slice2combiner__U, _slice2combiner__This]: ...
        def sliceIterator(self, from_: int, until: int) -> scala.collection.Iterator[_ParHashTable__EntryIterator__T]: ...
        _sliding__B = typing.TypeVar('_sliding__B')  # <B>
        def sliding(self, size: int, step: int) -> scala.collection.Iterator.GroupedIterator[_sliding__B]: ...
        _sliding$default$2__B = typing.TypeVar('_sliding$default$2__B')  # <B>
        def sliding$default$2(self) -> int: ...
        def span(self, p: scala.Function1[_ParHashTable__EntryIterator__T, typing.Any]) -> scala.Tuple2[scala.collection.Iterator[_ParHashTable__EntryIterator__T], scala.collection.Iterator[_ParHashTable__EntryIterator__T]]: ...
        _span2combiners__U = typing.TypeVar('_span2combiners__U')  # <U>
        _span2combiners__This = typing.TypeVar('_span2combiners__This')  # <This>
        def span2combiners(self, p: scala.Function1[_ParHashTable__EntryIterator__T, typing.Any], before: scala.collection.parallel.Combiner[_span2combiners__U, _span2combiners__This], after: scala.collection.parallel.Combiner[_span2combiners__U, _span2combiners__This]) -> scala.Tuple2[scala.collection.parallel.Combiner[_span2combiners__U, _span2combiners__This], scala.collection.parallel.Combiner[_span2combiners__U, _span2combiners__This]]: ...
        def split(self) -> scala.collection.Seq[scala.collection.parallel.IterableSplitter[_ParHashTable__EntryIterator__T]]: ...
        _splitAt2combiners__U = typing.TypeVar('_splitAt2combiners__U')  # <U>
        _splitAt2combiners__This = typing.TypeVar('_splitAt2combiners__This')  # <This>
        def splitAt2combiners(self, at: int, before: scala.collection.parallel.Combiner[_splitAt2combiners__U, _splitAt2combiners__This], after: scala.collection.parallel.Combiner[_splitAt2combiners__U, _splitAt2combiners__This]) -> scala.Tuple2[scala.collection.parallel.Combiner[_splitAt2combiners__U, _splitAt2combiners__This], scala.collection.parallel.Combiner[_splitAt2combiners__U, _splitAt2combiners__This]]: ...
        def splitWithSignalling(self) -> scala.collection.Seq[scala.collection.parallel.IterableSplitter[_ParHashTable__EntryIterator__T]]: ...
        _sum__U = typing.TypeVar('_sum__U')  # <U>
        def sum(self, num: scala.math.Numeric[_sum__U]) -> _sum__U: ...
        def tag(self) -> int: ...
        def take(self, n: int) -> scala.collection.parallel.IterableSplitter[_ParHashTable__EntryIterator__T]: ...
        _take2combiner__U = typing.TypeVar('_take2combiner__U')  # <U>
        _take2combiner__This = typing.TypeVar('_take2combiner__This')  # <This>
        def take2combiner(self, n: int, cb: scala.collection.parallel.Combiner[_take2combiner__U, _take2combiner__This]) -> scala.collection.parallel.Combiner[_take2combiner__U, _take2combiner__This]: ...
        def takeWhile(self, p: scala.Function1[_ParHashTable__EntryIterator__T, typing.Any]) -> scala.collection.Iterator[_ParHashTable__EntryIterator__T]: ...
        _takeWhile2combiner__U = typing.TypeVar('_takeWhile2combiner__U')  # <U>
        _takeWhile2combiner__This = typing.TypeVar('_takeWhile2combiner__This')  # <This>
        def takeWhile2combiner(self, p: scala.Function1[_ParHashTable__EntryIterator__T, typing.Any], cb: scala.collection.parallel.Combiner[_takeWhile2combiner__U, _takeWhile2combiner__This]) -> scala.Tuple2[scala.collection.parallel.Combiner[_takeWhile2combiner__U, _takeWhile2combiner__This], typing.Any]: ...
        _to__Col = typing.TypeVar('_to__Col')  # <Col>
        def to(self, cbf: scala.collection.generic.CanBuildFrom[scala.runtime.Nothing., _ParHashTable__EntryIterator__T, _to__Col]) -> _to__Col: ...
        _toArray__B = typing.TypeVar('_toArray__B')  # <B>
        def toArray(self, evidence$1: scala.reflect.ClassTag[_toArray__B]) -> typing.Any: ...
        _toBuffer__B = typing.TypeVar('_toBuffer__B')  # <B>
        def toBuffer(self) -> scala.collection.mutable.Buffer[_toBuffer__B]: ...
        def toIndexedSeq(self) -> scala.collection.immutable.IndexedSeq[_ParHashTable__EntryIterator__T]: ...
        def toIterable(self) -> scala.collection.Iterable[_ParHashTable__EntryIterator__T]: ...
        def toIterator(self) -> scala.collection.Iterator[_ParHashTable__EntryIterator__T]: ...
        def toList(self) -> scala.collection.immutable.List[_ParHashTable__EntryIterator__T]: ...
        _toMap__T = typing.TypeVar('_toMap__T')  # <T>
        _toMap__U = typing.TypeVar('_toMap__U')  # <U>
        def toMap(self, ev: scala.Predef..less.colon.less[typing.Any, scala.Tuple2[typing.Any, _toMap__U]]) -> scala.collection.immutable.Map[typing.Any, _toMap__U]: ...
        def toSeq(self) -> scala.collection.Seq[_ParHashTable__EntryIterator__T]: ...
        _toSet__B = typing.TypeVar('_toSet__B')  # <B>
        def toSet(self) -> scala.collection.immutable.Set[_toSet__B]: ...
        def toStream(self) -> scala.collection.immutable.Stream[_ParHashTable__EntryIterator__T]: ...
        def toString(self) -> str: ...
        def toTraversable(self) -> scala.collection.Traversable[_ParHashTable__EntryIterator__T]: ...
        def toVector(self) -> scala.collection.immutable.Vector[_ParHashTable__EntryIterator__T]: ...
        def withFilter(self, p: scala.Function1[_ParHashTable__EntryIterator__T, typing.Any]) -> scala.collection.Iterator[_ParHashTable__EntryIterator__T]: ...
        _zip__B = typing.TypeVar('_zip__B')  # <B>
        def zip(self, that: scala.collection.Iterator[_zip__B]) -> scala.collection.Iterator[scala.Tuple2[_ParHashTable__EntryIterator__T, _zip__B]]: ...
        _zip2combiner__U = typing.TypeVar('_zip2combiner__U')  # <U>
        _zip2combiner__S = typing.TypeVar('_zip2combiner__S')  # <S>
        _zip2combiner__That = typing.TypeVar('_zip2combiner__That')  # <That>
        def zip2combiner(self, otherpit: scala.collection.parallel.RemainsIterator[_zip2combiner__S], cb: scala.collection.parallel.Combiner[scala.Tuple2[_zip2combiner__U, _zip2combiner__S], _zip2combiner__That]) -> scala.collection.parallel.Combiner[scala.Tuple2[_zip2combiner__U, _zip2combiner__S], _zip2combiner__That]: ...
        _zipAll__B = typing.TypeVar('_zipAll__B')  # <B>
        _zipAll__A1 = typing.TypeVar('_zipAll__A1')  # <A1>
        _zipAll__B1 = typing.TypeVar('_zipAll__B1')  # <B1>
        def zipAll(self, that: scala.collection.Iterator[_zipAll__B], thisElem: _zipAll__A1, thatElem: _zipAll__B1) -> scala.collection.Iterator[scala.Tuple2[_zipAll__A1, _zipAll__B1]]: ...
        _zipAll2combiner__U = typing.TypeVar('_zipAll2combiner__U')  # <U>
        _zipAll2combiner__S = typing.TypeVar('_zipAll2combiner__S')  # <S>
        _zipAll2combiner__That = typing.TypeVar('_zipAll2combiner__That')  # <That>
        def zipAll2combiner(self, that: scala.collection.parallel.RemainsIterator[_zipAll2combiner__S], thiselem: _zipAll2combiner__U, thatelem: _zipAll2combiner__S, cb: scala.collection.parallel.Combiner[scala.Tuple2[_zipAll2combiner__U, _zipAll2combiner__S], _zipAll2combiner__That]) -> scala.collection.parallel.Combiner[scala.Tuple2[_zipAll2combiner__U, _zipAll2combiner__S], _zipAll2combiner__That]: ...
        _zipAllParSeq__S = typing.TypeVar('_zipAllParSeq__S')  # <S>
        _zipAllParSeq__U = typing.TypeVar('_zipAllParSeq__U')  # <U>
        _zipAllParSeq__R = typing.TypeVar('_zipAllParSeq__R')  # <R>
        def zipAllParSeq(self, that: scala.collection.parallel.SeqSplitter[_zipAllParSeq__S], thisElem: _zipAllParSeq__U, thatElem: _zipAllParSeq__R) -> scala.collection.parallel.IterableSplitter.ZippedAll[_zipAllParSeq__U, _zipAllParSeq__R]: ...
        _zipParSeq__S = typing.TypeVar('_zipParSeq__S')  # <S>
        def zipParSeq(self, that: scala.collection.parallel.SeqSplitter[_zipParSeq__S]) -> scala.collection.parallel.IterableSplitter.Zipped[_zipParSeq__S]: ...
        def zipWithIndex(self) -> scala.collection.Iterator[scala.Tuple2[_ParHashTable__EntryIterator__T, typing.Any]]: ...

_ParSeq__T = typing.TypeVar('_ParSeq__T')  # <T>
class ParSeq(ParIterable[_ParSeq__T], scala.collection.parallel.ParSeq[_ParSeq__T], typing.Generic[_ParSeq__T]):
    @staticmethod
    def $init$($this: 'ParSeq') -> None: ...
    @staticmethod
    def ReusableCBF() -> scala.collection.generic.GenTraversableFactory.GenericCanBuildFrom[scala.runtime.Nothing.]: ...
    _canBuildFrom__T = typing.TypeVar('_canBuildFrom__T')  # <T>
    @staticmethod
    def canBuildFrom() -> scala.collection.generic.CanCombineFrom['ParSeq'[typing.Any], _canBuildFrom__T, 'ParSeq'[_canBuildFrom__T]]: ...
    def companion(self) -> scala.collection.generic.GenericCompanion['ParSeq']: ...
    @staticmethod
    def concat(xss: scala.collection.Seq) -> scala.collection.GenTraversable: ...
    @staticmethod
    def empty() -> scala.collection.GenTraversable: ...
    def equals(self, that: typing.Any) -> bool: ...
    @typing.overload
    @staticmethod
    def fill(n1: int, n2: int, n3: int, n4: int, n5: int, elem: scala.Function0) -> scala.collection.GenTraversable: ...
    @typing.overload
    @staticmethod
    def fill(n1: int, n2: int, n3: int, n4: int, elem: scala.Function0) -> scala.collection.GenTraversable: ...
    @typing.overload
    @staticmethod
    def fill(n1: int, n2: int, n3: int, elem: scala.Function0) -> scala.collection.GenTraversable: ...
    @typing.overload
    @staticmethod
    def fill(n1: int, n2: int, elem: scala.Function0) -> scala.collection.GenTraversable: ...
    @typing.overload
    @staticmethod
    def fill(n: int, elem: scala.Function0) -> scala.collection.GenTraversable: ...
    def hashCode(self) -> int: ...
    @staticmethod
    def iterate(start: typing.Any, len: int, f: scala.Function1) -> scala.collection.GenTraversable: ...
    @typing.overload
    @staticmethod
    def range(start: typing.Any, end: typing.Any, step: typing.Any, evidence$2: scala.math.Integral) -> scala.collection.GenTraversable: ...
    @typing.overload
    @staticmethod
    def range(start: typing.Any, end: typing.Any, evidence$1: scala.math.Integral) -> scala.collection.GenTraversable: ...
    @typing.overload
    def seq(self) -> scala.collection.Iterable[typing.Any]: ...
    @typing.overload
    def seq(self) -> scala.collection.Iterable: ...
    @typing.overload
    def seq(self) -> scala.collection.Seq[typing.Any]: ...
    @typing.overload
    def seq(self) -> scala.collection.Traversable[typing.Any]: ...
    @typing.overload
    def seq(self) -> scala.collection.TraversableOnce[typing.Any]: ...
    @typing.overload
    def seq(self) -> scala.collection.TraversableOnce[typing.Any]: ...
    @typing.overload
    def seq(self) -> scala.collection.mutable.Iterable[_ParSeq__T]: ...
    @typing.overload
    def seq(self) -> scala.collection.mutable.Seq[_ParSeq__T]: ...
    @typing.overload
    @staticmethod
    def tabulate(n1: int, n2: int, n3: int, n4: int, n5: int, f: scala.Function5) -> scala.collection.GenTraversable: ...
    @typing.overload
    @staticmethod
    def tabulate(n1: int, n2: int, n3: int, n4: int, f: scala.Function4) -> scala.collection.GenTraversable: ...
    @typing.overload
    @staticmethod
    def tabulate(n1: int, n2: int, n3: int, f: scala.Function3) -> scala.collection.GenTraversable: ...
    @typing.overload
    @staticmethod
    def tabulate(n1: int, n2: int, f: scala.Function2) -> scala.collection.GenTraversable: ...
    @typing.overload
    @staticmethod
    def tabulate(n: int, f: scala.Function1) -> scala.collection.GenTraversable: ...
    @typing.overload
    def toSeq(self) -> scala.collection.GenSeq[typing.Any]: ...
    @typing.overload
    def toSeq(self) -> scala.collection.parallel.ParSeq[_ParSeq__T]: ...
    @typing.overload
    def toSeq(self) -> 'ParSeq'[_ParSeq__T]: ...
    def toString(self) -> str: ...
    def update(self, i: int, elem: _ParSeq__T) -> None: ...

_ParSet__T = typing.TypeVar('_ParSet__T')  # <T>
class ParSet(ParIterable[_ParSet__T], scala.collection.parallel.ParSet[_ParSet__T], ParSetLike[_ParSet__T, 'ParSet'[_ParSet__T], scala.collection.mutable.Set[_ParSet__T]], typing.Generic[_ParSet__T]):
    @staticmethod
    def $init$($this: 'ParSet') -> None: ...
    _canBuildFrom__T = typing.TypeVar('_canBuildFrom__T')  # <T>
    @staticmethod
    def canBuildFrom() -> scala.collection.generic.CanCombineFrom['ParSet'[typing.Any], _canBuildFrom__T, 'ParSet'[_canBuildFrom__T]]: ...
    def companion(self) -> scala.collection.generic.GenericCompanion['ParSet']: ...
    @typing.overload
    def empty(self) -> scala.collection.GenSet: ...
    @typing.overload
    def empty(self) -> scala.collection.parallel.ParSet[_ParSet__T]: ...
    @typing.overload
    def empty(self) -> 'ParSet'[_ParSet__T]: ...
    def equals(self, that: typing.Any) -> bool: ...
    def hashCode(self) -> int: ...
    @typing.overload
    def seq(self) -> scala.collection.Iterable[typing.Any]: ...
    @typing.overload
    def seq(self) -> scala.collection.Iterable: ...
    @typing.overload
    def seq(self) -> scala.collection.Set[typing.Any]: ...
    @typing.overload
    def seq(self) -> scala.collection.Traversable[typing.Any]: ...
    @typing.overload
    def seq(self) -> scala.collection.TraversableOnce[typing.Any]: ...
    @typing.overload
    def seq(self) -> scala.collection.TraversableOnce[typing.Any]: ...
    @typing.overload
    def seq(self) -> scala.collection.mutable.Iterable[_ParSet__T]: ...
    @typing.overload
    def seq(self) -> scala.collection.mutable.Set[_ParSet__T]: ...
    _setCanBuildFrom__A = typing.TypeVar('_setCanBuildFrom__A')  # <A>
    @staticmethod
    def setCanBuildFrom() -> scala.collection.generic.CanBuildFrom['ParSet'[typing.Any], _setCanBuildFrom__A, 'ParSet'[_setCanBuildFrom__A]]: ...
    @typing.overload
    def toString(self) -> str: ...
    @typing.overload
    def toString(self) -> str: ...

_ResizableParArrayCombiner__T = typing.TypeVar('_ResizableParArrayCombiner__T')  # <T>
class ResizableParArrayCombiner(LazyCombiner[_ResizableParArrayCombiner__T, 'ParArray'[_ResizableParArrayCombiner__T], ExposedArrayBuffer[_ResizableParArrayCombiner__T]], typing.Generic[_ResizableParArrayCombiner__T]):
    @staticmethod
    def $init$($this: 'ResizableParArrayCombiner') -> None: ...
    @typing.overload
    def allocateAndCopy(self) -> typing.Any: ...
    @typing.overload
    def allocateAndCopy(self) -> 'ParArray'[_ResizableParArrayCombiner__T]: ...
    _apply_0__T = typing.TypeVar('_apply_0__T')  # <T>
    _apply_1__T = typing.TypeVar('_apply_1__T')  # <T>
    @typing.overload
    @staticmethod
    def apply() -> 'ResizableParArrayCombiner'[_apply_0__T]: ...
    @typing.overload
    @staticmethod
    def apply(c: scala.collection.mutable.ArrayBuffer[ExposedArrayBuffer[_apply_1__T]]) -> 'ResizableParArrayCombiner'[_apply_1__T]: ...
    @typing.overload
    def newLazyCombiner(self, buffchain: scala.collection.mutable.ArrayBuffer[scala.collection.generic.Growable]) -> LazyCombiner[typing.Any, typing.Any, scala.collection.generic.Growable]: ...
    @typing.overload
    def newLazyCombiner(self, c: scala.collection.mutable.ArrayBuffer[ExposedArrayBuffer[_ResizableParArrayCombiner__T]]) -> 'ResizableParArrayCombiner'[_ResizableParArrayCombiner__T]: ...
    @typing.overload
    def sizeHint(self, coll: scala.collection.TraversableLike[typing.Any, typing.Any]) -> None: ...
    @typing.overload
    def sizeHint(self, coll: scala.collection.TraversableLike[typing.Any, typing.Any], delta: int) -> None: ...
    @typing.overload
    def sizeHint(self, sz: int) -> None: ...
    def toString(self) -> str: ...
    class CopyChainToArray(scala.collection.parallel.Task[scala.runtime.BoxedUnit, 'ResizableParArrayCombiner.CopyChainToArray']):
        $outer: 'ResizableParArrayCombiner' = ...
        def __init__(self, $outer: 'ResizableParArrayCombiner', array: typing.List[typing.Any], offset: int, howmany: int): ...
        def forwardThrowable(self) -> None: ...
        def leaf(self, prev: scala.Option[scala.runtime.BoxedUnit]) -> None: ...
        def merge(self, that: typing.Any) -> None: ...
        def mergeThrowables(self, that: scala.collection.parallel.Task[typing.Any, typing.Any]) -> None: ...
        def repr(self) -> typing.Any: ...
        def result(self) -> None: ...
        def result_$eq(self, x$1: scala.runtime.BoxedUnit) -> None: ...
        def shouldSplitFurther(self) -> bool: ...
        def signalAbort(self) -> None: ...
        def split(self) -> scala.collection.immutable.List['ResizableParArrayCombiner.CopyChainToArray']: ...
        def throwable(self) -> java.lang.Throwable: ...
        def throwable_$eq(self, x$1: java.lang.Throwable) -> None: ...
        def tryLeaf(self, lastres: scala.Option[scala.runtime.BoxedUnit]) -> None: ...
        def tryMerge(self, t: typing.Any) -> None: ...
    class : ...

_ParArray__Map__S = typing.TypeVar('_ParArray__Map__S')  # <S>
_ParArray__ScanToArray__U = typing.TypeVar('_ParArray__ScanToArray__U')  # <U>
_ParArray__T = typing.TypeVar('_ParArray__T')  # <T>
class ParArray(ParSeq[_ParArray__T], scala.Serializable, typing.Generic[_ParArray__T]):
    serialVersionUID: typing.ClassVar[int] = ...
    @typing.overload
    def __init__(self, sz: int): ...
    @typing.overload
    def __init__(self, arrayseq: scala.collection.mutable.ArraySeq[_ParArray__T]): ...
    _$colon$bslash__S = typing.TypeVar('_$colon$bslash__S')  # <S>
    def $colon$bslash(self, z: _.colon.bslash__S, op: scala.Function2[_ParArray__T, _.colon.bslash__S, _.colon.bslash__S]) -> _.colon.bslash__S: ...
    _$colon$plus__U = typing.TypeVar('_$colon$plus__U')  # <U>
    _$colon$plus__That = typing.TypeVar('_$colon$plus__That')  # <That>
    def $colon$plus(self, elem: _.colon.plus__U, bf: scala.collection.generic.CanBuildFrom['ParArray'[_ParArray__T], _.colon.plus__U, _.colon.plus__That]) -> _.colon.plus__That: ...
    _$div$colon__S = typing.TypeVar('_$div$colon__S')  # <S>
    def $div$colon(self, z: _.div.colon__S, op: scala.Function2[_.div.colon__S, _ParArray__T, _.div.colon__S]) -> _.div.colon__S: ...
    _$plus$colon__U = typing.TypeVar('_$plus$colon__U')  # <U>
    _$plus$colon__That = typing.TypeVar('_$plus$colon__That')  # <That>
    def $plus$colon(self, elem: _.plus.colon__U, bf: scala.collection.generic.CanBuildFrom['ParArray'[_ParArray__T], _.plus.colon__U, _.plus.colon__That]) -> _.plus.colon__That: ...
    _$plus$plus__U = typing.TypeVar('_$plus$plus__U')  # <U>
    _$plus$plus__That = typing.TypeVar('_$plus$plus__That')  # <That>
    def $plus$plus(self, that: scala.collection.GenTraversableOnce[_.plus.plus__U], bf: scala.collection.generic.CanBuildFrom['ParArray'[_ParArray__T], _.plus.plus__U, _.plus.plus__That]) -> _.plus.plus__That: ...
    @staticmethod
    def ReusableCBF() -> scala.collection.generic.GenTraversableFactory.GenericCanBuildFrom[scala.runtime.Nothing.]: ...
    def ScanLeaf(self) -> scala.collection.parallel.ParIterableLike.ScanLeaf.: ...
    def ScanNode(self) -> scala.collection.parallel.ParIterableLike.ScanNode.: ...
    _aggregate__S = typing.TypeVar('_aggregate__S')  # <S>
    def aggregate(self, z: scala.Function0[_aggregate__S], seqop: scala.Function2[_aggregate__S, _ParArray__T, _aggregate__S], combop: scala.Function2[_aggregate__S, _aggregate__S, _aggregate__S]) -> _aggregate__S: ...
    def apply(self, i: int) -> _ParArray__T: ...
    def arrayseq(self) -> scala.collection.mutable.ArraySeq[_ParArray__T]: ...
    _bf2seq__S = typing.TypeVar('_bf2seq__S')  # <S>
    _bf2seq__That = typing.TypeVar('_bf2seq__That')  # <That>
    def bf2seq(self, bf: scala.collection.generic.CanBuildFrom['ParArray'[_ParArray__T], _bf2seq__S, _bf2seq__That]) -> scala.collection.generic.CanBuildFrom[scala.collection.mutable.ArraySeq[_ParArray__T], _bf2seq__S, _bf2seq__That]: ...
    def brokenInvariants(self) -> scala.collection.Seq[str]: ...
    _builder2ops__Elem = typing.TypeVar('_builder2ops__Elem')  # <Elem>
    _builder2ops__To = typing.TypeVar('_builder2ops__To')  # <To>
    def builder2ops(self, cb: scala.collection.mutable.Builder[_builder2ops__Elem, _builder2ops__To]) -> scala.collection.parallel.ParIterableLike.BuilderOps[_builder2ops__Elem, _builder2ops__To]: ...
    _canBuildFrom__T = typing.TypeVar('_canBuildFrom__T')  # <T>
    @staticmethod
    def canBuildFrom() -> scala.collection.generic.CanCombineFrom['ParArray'[typing.Any], _canBuildFrom__T, 'ParArray'[_canBuildFrom__T]]: ...
    def canEqual(self, other: typing.Any) -> bool: ...
    _collect__S = typing.TypeVar('_collect__S')  # <S>
    _collect__That = typing.TypeVar('_collect__That')  # <That>
    def collect(self, pf: scala.PartialFunction[_ParArray__T, _collect__S], bf: scala.collection.generic.CanBuildFrom['ParArray'[_ParArray__T], _collect__S, _collect__That]) -> _collect__That: ...
    _combinerFactory_1__S = typing.TypeVar('_combinerFactory_1__S')  # <S>
    _combinerFactory_1__That = typing.TypeVar('_combinerFactory_1__That')  # <That>
    @typing.overload
    def combinerFactory(self) -> scala.collection.parallel.CombinerFactory[_ParArray__T, 'ParArray'[_ParArray__T]]: ...
    @typing.overload
    def combinerFactory(self, cbf: scala.Function0[scala.collection.parallel.Combiner[_combinerFactory_1__S, _combinerFactory_1__That]]) -> scala.collection.parallel.CombinerFactory[_combinerFactory_1__S, _combinerFactory_1__That]: ...
    def companion(self) -> scala.collection.generic.GenericCompanion['ParArray']: ...
    @staticmethod
    def concat(xss: scala.collection.Seq) -> scala.collection.GenTraversable: ...
    _copyToArray_0__U = typing.TypeVar('_copyToArray_0__U')  # <U>
    _copyToArray_1__U = typing.TypeVar('_copyToArray_1__U')  # <U>
    _copyToArray_2__U = typing.TypeVar('_copyToArray_2__U')  # <U>
    @typing.overload
    def copyToArray(self, xs: typing.Any) -> None: ...
    @typing.overload
    def copyToArray(self, xs: typing.Any, start: int) -> None: ...
    @typing.overload
    def copyToArray(self, xs: typing.Any, start: int, len: int) -> None: ...
    _corresponds__S = typing.TypeVar('_corresponds__S')  # <S>
    def corresponds(self, that: scala.collection.GenSeq[_corresponds__S], p: scala.Function2[_ParArray__T, _corresponds__S, typing.Any]) -> bool: ...
    def count(self, p: scala.Function1[_ParArray__T, typing.Any]) -> int: ...
    _createFromCopy__T = typing.TypeVar('_createFromCopy__T')  # <T>
    @staticmethod
    def createFromCopy(arr: typing.List[_createFromCopy__T], evidence$1: scala.reflect.ClassTag[_createFromCopy__T]) -> 'ParArray'[_createFromCopy__T]: ...
    def debugBuffer(self) -> scala.collection.mutable.ArrayBuffer[str]: ...
    def debugInformation(self) -> str: ...
    def debugclear(self) -> None: ...
    def debuglog(self, s: str) -> scala.collection.mutable.ArrayBuffer[str]: ...
    _delegatedSignalling2ops__PI = typing.TypeVar('_delegatedSignalling2ops__PI', bound=scala.collection.generic.DelegatedSignalling)  # <PI>
    def delegatedSignalling2ops(self, it: _delegatedSignalling2ops__PI) -> scala.collection.parallel.ParIterableLike.SignallingOps[_delegatedSignalling2ops__PI]: ...
    def diff(self, that: scala.collection.GenSeq) -> scala.collection.parallel.ParSeq: ...
    def distinct(self) -> scala.collection.parallel.ParSeq: ...
    def down(self, p: scala.collection.parallel.IterableSplitter[typing.Any]) -> scala.collection.parallel.SeqSplitter[_ParArray__T]: ...
    def drop(self, n: int) -> scala.collection.parallel.ParIterable: ...
    def dropWhile(self, pred: scala.Function1) -> scala.collection.parallel.ParIterable: ...
    @staticmethod
    def empty() -> scala.collection.GenTraversable: ...
    _endsWith__S = typing.TypeVar('_endsWith__S')  # <S>
    def endsWith(self, that: scala.collection.GenSeq[_endsWith__S]) -> bool: ...
    def equals(self, that: typing.Any) -> bool: ...
    def exists(self, p: scala.Function1[_ParArray__T, typing.Any]) -> bool: ...
    @typing.overload
    @staticmethod
    def fill(n1: int, n2: int, n3: int, n4: int, n5: int, elem: scala.Function0) -> scala.collection.GenTraversable: ...
    @typing.overload
    @staticmethod
    def fill(n1: int, n2: int, n3: int, n4: int, elem: scala.Function0) -> scala.collection.GenTraversable: ...
    @typing.overload
    @staticmethod
    def fill(n1: int, n2: int, n3: int, elem: scala.Function0) -> scala.collection.GenTraversable: ...
    @typing.overload
    @staticmethod
    def fill(n1: int, n2: int, elem: scala.Function0) -> scala.collection.GenTraversable: ...
    @typing.overload
    @staticmethod
    def fill(n: int, elem: scala.Function0) -> scala.collection.GenTraversable: ...
    def filter(self, pred: scala.Function1) -> scala.collection.parallel.ParIterable: ...
    def filterNot(self, pred: scala.Function1) -> scala.collection.parallel.ParIterable: ...
    def find(self, p: scala.Function1[_ParArray__T, typing.Any]) -> scala.Option[_ParArray__T]: ...
    _flatMap__S = typing.TypeVar('_flatMap__S')  # <S>
    _flatMap__That = typing.TypeVar('_flatMap__That')  # <That>
    def flatMap(self, f: scala.Function1[_ParArray__T, scala.collection.GenTraversableOnce[_flatMap__S]], bf: scala.collection.generic.CanBuildFrom['ParArray'[_ParArray__T], _flatMap__S, _flatMap__That]) -> _flatMap__That: ...
    def flatten(self, asTraversable: scala.Function1) -> scala.collection.GenTraversable: ...
    _fold__U = typing.TypeVar('_fold__U')  # <U>
    def fold(self, z: _fold__U, op: scala.Function2[_fold__U, _fold__U, _fold__U]) -> _fold__U: ...
    _foldLeft__S = typing.TypeVar('_foldLeft__S')  # <S>
    def foldLeft(self, z: _foldLeft__S, op: scala.Function2[_foldLeft__S, _ParArray__T, _foldLeft__S]) -> _foldLeft__S: ...
    _foldRight__S = typing.TypeVar('_foldRight__S')  # <S>
    def foldRight(self, z: _foldRight__S, op: scala.Function2[_ParArray__T, _foldRight__S, _foldRight__S]) -> _foldRight__S: ...
    def forall(self, p: scala.Function1[_ParArray__T, typing.Any]) -> bool: ...
    _foreach__U = typing.TypeVar('_foreach__U')  # <U>
    def foreach(self, f: scala.Function1[_ParArray__T, _foreach__U]) -> None: ...
    _fromTraversables__T = typing.TypeVar('_fromTraversables__T')  # <T>
    @staticmethod
    def fromTraversables(xss: scala.collection.Seq[scala.collection.GenTraversableOnce[_fromTraversables__T]]) -> 'ParArray'[_fromTraversables__T]: ...
    _genericBuilder__B = typing.TypeVar('_genericBuilder__B')  # <B>
    def genericBuilder(self) -> scala.collection.parallel.Combiner[_genericBuilder__B, 'ParArray'[_genericBuilder__B]]: ...
    _genericCombiner__B = typing.TypeVar('_genericCombiner__B')  # <B>
    def genericCombiner(self) -> scala.collection.parallel.Combiner[_genericCombiner__B, 'ParArray'[_genericCombiner__B]]: ...
    _groupBy__K = typing.TypeVar('_groupBy__K')  # <K>
    def groupBy(self, f: scala.Function1[_ParArray__T, _groupBy__K]) -> scala.collection.parallel.immutable.ParMap[_groupBy__K, 'ParArray'[_ParArray__T]]: ...
    _handoff_0__T = typing.TypeVar('_handoff_0__T')  # <T>
    _handoff_1__T = typing.TypeVar('_handoff_1__T')  # <T>
    @typing.overload
    @staticmethod
    def handoff(arr: typing.Any) -> 'ParArray'[_handoff_0__T]: ...
    @typing.overload
    @staticmethod
    def handoff(arr: typing.Any, sz: int) -> 'ParArray'[_handoff_1__T]: ...
    def hasDefiniteSize(self) -> bool: ...
    def hashCode(self) -> int: ...
    def head(self) -> _ParArray__T: ...
    def headOption(self) -> scala.Option[_ParArray__T]: ...
    _indexOf_0__B = typing.TypeVar('_indexOf_0__B')  # <B>
    _indexOf_1__B = typing.TypeVar('_indexOf_1__B')  # <B>
    @typing.overload
    def indexOf(self, elem: _indexOf_0__B) -> int: ...
    @typing.overload
    def indexOf(self, elem: _indexOf_1__B, from_: int) -> int: ...
    @typing.overload
    def indexWhere(self, p: scala.Function1[_ParArray__T, typing.Any]) -> int: ...
    @typing.overload
    def indexWhere(self, p: scala.Function1[_ParArray__T, typing.Any], from_: int) -> int: ...
    def init(self) -> scala.collection.parallel.ParIterable: ...
    def initTaskSupport(self) -> None: ...
    def intersect(self, that: scala.collection.GenSeq) -> scala.collection.parallel.ParSeq: ...
    def isDefinedAt(self, idx: int) -> bool: ...
    def isEmpty(self) -> bool: ...
    def isStrictSplitterCollection(self) -> bool: ...
    def isTraversableAgain(self) -> bool: ...
    @staticmethod
    def iterate(start: typing.Any, len: int, f: scala.Function1) -> scala.collection.GenTraversable: ...
    def iterator(self) -> scala.collection.parallel.PreciseSplitter[_ParArray__T]: ...
    def last(self) -> _ParArray__T: ...
    _lastIndexOf_0__B = typing.TypeVar('_lastIndexOf_0__B')  # <B>
    _lastIndexOf_1__B = typing.TypeVar('_lastIndexOf_1__B')  # <B>
    @typing.overload
    def lastIndexOf(self, elem: _lastIndexOf_0__B) -> int: ...
    @typing.overload
    def lastIndexOf(self, elem: _lastIndexOf_1__B, end: int) -> int: ...
    @typing.overload
    def lastIndexWhere(self, p: scala.Function1[_ParArray__T, typing.Any]) -> int: ...
    @typing.overload
    def lastIndexWhere(self, p: scala.Function1[_ParArray__T, typing.Any], end: int) -> int: ...
    def lastOption(self) -> scala.Option[_ParArray__T]: ...
    def length(self) -> int: ...
    _map__S = typing.TypeVar('_map__S')  # <S>
    _map__That = typing.TypeVar('_map__That')  # <That>
    def map(self, f: scala.Function1[_ParArray__T, _map__S], bf: scala.collection.generic.CanBuildFrom['ParArray'[_ParArray__T], _map__S, _map__That]) -> _map__That: ...
    _max__U = typing.TypeVar('_max__U')  # <U>
    def max(self, ord: scala.math.Ordering[_max__U]) -> _ParArray__T: ...
    _maxBy__S = typing.TypeVar('_maxBy__S')  # <S>
    def maxBy(self, f: scala.Function1[_ParArray__T, _maxBy__S], cmp: scala.math.Ordering[_maxBy__S]) -> _ParArray__T: ...
    _min__U = typing.TypeVar('_min__U')  # <U>
    def min(self, ord: scala.math.Ordering[_min__U]) -> _ParArray__T: ...
    _minBy__S = typing.TypeVar('_minBy__S')  # <S>
    def minBy(self, f: scala.Function1[_ParArray__T, _minBy__S], cmp: scala.math.Ordering[_minBy__S]) -> _ParArray__T: ...
    @typing.overload
    def mkString(self) -> str: ...
    @typing.overload
    def mkString(self, sep: str) -> str: ...
    @typing.overload
    def mkString(self, start: str, sep: str, end: str) -> str: ...
    def newBuilder(self) -> scala.collection.mutable.Builder[_ParArray__T, 'ParArray'[_ParArray__T]]: ...
    def newCombiner(self) -> scala.collection.parallel.Combiner[_ParArray__T, 'ParArray'[_ParArray__T]]: ...
    def nonEmpty(self) -> bool: ...
    _padTo__U = typing.TypeVar('_padTo__U')  # <U>
    _padTo__That = typing.TypeVar('_padTo__That')  # <That>
    def padTo(self, len: int, elem: _padTo__U, bf: scala.collection.generic.CanBuildFrom['ParArray'[_ParArray__T], _padTo__U, _padTo__That]) -> _padTo__That: ...
    def par(self) -> scala.collection.parallel.ParIterable: ...
    def parCombiner(self) -> scala.collection.parallel.Combiner[_ParArray__T, 'ParArray'[_ParArray__T]]: ...
    def partition(self, pred: scala.Function1[_ParArray__T, typing.Any]) -> scala.Tuple2['ParArray'[_ParArray__T], 'ParArray'[_ParArray__T]]: ...
    _patch__U = typing.TypeVar('_patch__U')  # <U>
    _patch__That = typing.TypeVar('_patch__That')  # <That>
    def patch(self, from_: int, patch: scala.collection.GenSeq[_patch__U], replaced: int, bf: scala.collection.generic.CanBuildFrom['ParArray'[_ParArray__T], _patch__U, _patch__That]) -> _patch__That: ...
    def prefixLength(self, p: scala.Function1[_ParArray__T, typing.Any]) -> int: ...
    def printDebugBuffer(self) -> None: ...
    _product__U = typing.TypeVar('_product__U')  # <U>
    def product(self, num: scala.math.Numeric[_product__U]) -> _product__U: ...
    @typing.overload
    @staticmethod
    def range(start: typing.Any, end: typing.Any, step: typing.Any, evidence$2: scala.math.Integral) -> scala.collection.GenTraversable: ...
    @typing.overload
    @staticmethod
    def range(start: typing.Any, end: typing.Any, evidence$1: scala.math.Integral) -> scala.collection.GenTraversable: ...
    _reduce__U = typing.TypeVar('_reduce__U')  # <U>
    def reduce(self, op: scala.Function2[_reduce__U, _reduce__U, _reduce__U]) -> _reduce__U: ...
    _reduceLeft__U = typing.TypeVar('_reduceLeft__U')  # <U>
    def reduceLeft(self, op: scala.Function2[_reduceLeft__U, _ParArray__T, _reduceLeft__U]) -> _reduceLeft__U: ...
    _reduceLeftOption__U = typing.TypeVar('_reduceLeftOption__U')  # <U>
    def reduceLeftOption(self, op: scala.Function2[_reduceLeftOption__U, _ParArray__T, _reduceLeftOption__U]) -> scala.Option[_reduceLeftOption__U]: ...
    _reduceOption__U = typing.TypeVar('_reduceOption__U')  # <U>
    def reduceOption(self, op: scala.Function2[_reduceOption__U, _reduceOption__U, _reduceOption__U]) -> scala.Option[_reduceOption__U]: ...
    _reduceRight__U = typing.TypeVar('_reduceRight__U')  # <U>
    def reduceRight(self, op: scala.Function2[_ParArray__T, _reduceRight__U, _reduceRight__U]) -> _reduceRight__U: ...
    _reduceRightOption__U = typing.TypeVar('_reduceRightOption__U')  # <U>
    def reduceRightOption(self, op: scala.Function2[_ParArray__T, _reduceRightOption__U, _reduceRightOption__U]) -> scala.Option[_reduceRightOption__U]: ...
    def repr(self) -> scala.collection.parallel.ParIterable: ...
    _reuse__S = typing.TypeVar('_reuse__S')  # <S>
    _reuse__That = typing.TypeVar('_reuse__That')  # <That>
    def reuse(self, oldc: scala.Option[scala.collection.parallel.Combiner[_reuse__S, _reuse__That]], newc: scala.collection.parallel.Combiner[_reuse__S, _reuse__That]) -> scala.collection.parallel.Combiner[_reuse__S, _reuse__That]: ...
    def reverse(self) -> scala.collection.parallel.ParSeq: ...
    _reverseMap__S = typing.TypeVar('_reverseMap__S')  # <S>
    _reverseMap__That = typing.TypeVar('_reverseMap__That')  # <That>
    def reverseMap(self, f: scala.Function1[_ParArray__T, _reverseMap__S], bf: scala.collection.generic.CanBuildFrom['ParArray'[_ParArray__T], _reverseMap__S, _reverseMap__That]) -> _reverseMap__That: ...
    _sameElements__U = typing.TypeVar('_sameElements__U')  # <U>
    def sameElements(self, that: scala.collection.GenIterable[_sameElements__U]) -> bool: ...
    def scala$collection$parallel$ParIterableLike$$_tasksupport(self) -> scala.collection.parallel.TaskSupport: ...
    def scala$collection$parallel$ParIterableLike$$_tasksupport_$eq(self, x$1: scala.collection.parallel.TaskSupport) -> None: ...
    def scala$collection$parallel$mutable$ParArray$$array(self) -> typing.List[typing.Any]: ...
    _scan__U = typing.TypeVar('_scan__U')  # <U>
    _scan__That = typing.TypeVar('_scan__That')  # <That>
    def scan(self, z: _scan__U, op: scala.Function2[_scan__U, _scan__U, _scan__U], cbf: scala.collection.generic.CanBuildFrom['ParArray'[_ParArray__T], _scan__U, _scan__That]) -> _scan__That: ...
    def scanBlockSize(self) -> int: ...
    _scanLeft__S = typing.TypeVar('_scanLeft__S')  # <S>
    _scanLeft__That = typing.TypeVar('_scanLeft__That')  # <That>
    def scanLeft(self, z: _scanLeft__S, op: scala.Function2[_scanLeft__S, _ParArray__T, _scanLeft__S], bf: scala.collection.generic.CanBuildFrom['ParArray'[_ParArray__T], _scanLeft__S, _scanLeft__That]) -> _scanLeft__That: ...
    _scanRight__S = typing.TypeVar('_scanRight__S')  # <S>
    _scanRight__That = typing.TypeVar('_scanRight__That')  # <That>
    def scanRight(self, z: _scanRight__S, op: scala.Function2[_ParArray__T, _scanRight__S, _scanRight__S], bf: scala.collection.generic.CanBuildFrom['ParArray'[_ParArray__T], _scanRight__S, _scanRight__That]) -> _scanRight__That: ...
    def segmentLength(self, p: scala.Function1[_ParArray__T, typing.Any], from_: int) -> int: ...
    def seq(self) -> scala.collection.mutable.ArraySeq[_ParArray__T]: ...
    def sequentially(self, b: scala.Function1) -> scala.collection.parallel.ParIterable: ...
    def size(self) -> int: ...
    def sizeHintIfCheap(self) -> int: ...
    def slice(self, unc_from: int, unc_until: int) -> scala.collection.parallel.ParIterable: ...
    def span(self, pred: scala.Function1[_ParArray__T, typing.Any]) -> scala.Tuple2['ParArray'[_ParArray__T], 'ParArray'[_ParArray__T]]: ...
    def splitAt(self, n: int) -> scala.Tuple2['ParArray'[_ParArray__T], 'ParArray'[_ParArray__T]]: ...
    def splitter(self) -> 'ParArray.ParArrayIterator': ...
    _startsWith_0__B = typing.TypeVar('_startsWith_0__B')  # <B>
    _startsWith_1__S = typing.TypeVar('_startsWith_1__S')  # <S>
    @typing.overload
    def startsWith(self, that: scala.collection.GenSeq[_startsWith_0__B]) -> bool: ...
    @typing.overload
    def startsWith(self, that: scala.collection.GenSeq[_startsWith_1__S], offset: int) -> bool: ...
    def stringPrefix(self) -> str: ...
    _sum__U = typing.TypeVar('_sum__U')  # <U>
    def sum(self, num: scala.math.Numeric[_sum__U]) -> _sum__U: ...
    @typing.overload
    @staticmethod
    def tabulate(n1: int, n2: int, n3: int, n4: int, n5: int, f: scala.Function5) -> scala.collection.GenTraversable: ...
    @typing.overload
    @staticmethod
    def tabulate(n1: int, n2: int, n3: int, n4: int, f: scala.Function4) -> scala.collection.GenTraversable: ...
    @typing.overload
    @staticmethod
    def tabulate(n1: int, n2: int, n3: int, f: scala.Function3) -> scala.collection.GenTraversable: ...
    @typing.overload
    @staticmethod
    def tabulate(n1: int, n2: int, f: scala.Function2) -> scala.collection.GenTraversable: ...
    @typing.overload
    @staticmethod
    def tabulate(n: int, f: scala.Function1) -> scala.collection.GenTraversable: ...
    def tail(self) -> scala.collection.parallel.ParIterable: ...
    def take(self, n: int) -> scala.collection.parallel.ParIterable: ...
    def takeWhile(self, pred: scala.Function1) -> scala.collection.parallel.ParIterable: ...
    _task2ops__R = typing.TypeVar('_task2ops__R')  # <R>
    _task2ops__Tp = typing.TypeVar('_task2ops__Tp')  # <Tp>
    def task2ops(self, tsk: scala.collection.parallel.ParIterableLike.StrictSplitterCheckTask[_task2ops__R, _task2ops__Tp]) -> scala.collection.parallel.ParIterableLike.TaskOps[_task2ops__R, _task2ops__Tp]: ...
    def tasksupport(self) -> scala.collection.parallel.TaskSupport: ...
    def tasksupport_$eq(self, ts: scala.collection.parallel.TaskSupport) -> None: ...
    _to__Col = typing.TypeVar('_to__Col')  # <Col>
    def to(self, cbf: scala.collection.generic.CanBuildFrom[scala.runtime.Nothing., _ParArray__T, _to__Col]) -> _to__Col: ...
    _toArray__U = typing.TypeVar('_toArray__U')  # <U>
    def toArray(self, evidence$1: scala.reflect.ClassTag[_toArray__U]) -> typing.Any: ...
    _toBuffer__U = typing.TypeVar('_toBuffer__U')  # <U>
    def toBuffer(self) -> scala.collection.mutable.Buffer[_toBuffer__U]: ...
    def toIndexedSeq(self) -> scala.collection.immutable.IndexedSeq[_ParArray__T]: ...
    def toIterable(self) -> ParIterable[_ParArray__T]: ...
    def toIterator(self) -> scala.collection.Iterator[_ParArray__T]: ...
    def toList(self) -> scala.collection.immutable.List[_ParArray__T]: ...
    _toMap__K = typing.TypeVar('_toMap__K')  # <K>
    _toMap__V = typing.TypeVar('_toMap__V')  # <V>
    def toMap(self, ev: scala.Predef..less.colon.less[_ParArray__T, scala.Tuple2[_toMap__K, _toMap__V]]) -> scala.collection.parallel.immutable.ParMap[_toMap__K, _toMap__V]: ...
    _toParCollection__U = typing.TypeVar('_toParCollection__U')  # <U>
    _toParCollection__That = typing.TypeVar('_toParCollection__That')  # <That>
    def toParCollection(self, cbf: scala.Function0[scala.collection.parallel.Combiner[_toParCollection__U, _toParCollection__That]]) -> _toParCollection__That: ...
    _toParMap__K = typing.TypeVar('_toParMap__K')  # <K>
    _toParMap__V = typing.TypeVar('_toParMap__V')  # <V>
    _toParMap__That = typing.TypeVar('_toParMap__That')  # <That>
    def toParMap(self, cbf: scala.Function0[scala.collection.parallel.Combiner[scala.Tuple2[_toParMap__K, _toParMap__V], _toParMap__That]], ev: scala.Predef..less.colon.less[_ParArray__T, scala.Tuple2[_toParMap__K, _toParMap__V]]) -> _toParMap__That: ...
    def toSeq(self) -> ParSeq[_ParArray__T]: ...
    _toSet__U = typing.TypeVar('_toSet__U')  # <U>
    def toSet(self) -> scala.collection.parallel.immutable.ParSet[_toSet__U]: ...
    def toStream(self) -> scala.collection.immutable.Stream[_ParArray__T]: ...
    def toString(self) -> str: ...
    def toTraversable(self) -> scala.collection.GenTraversable[_ParArray__T]: ...
    def toVector(self) -> scala.collection.immutable.Vector[_ParArray__T]: ...
    def transpose(self, asTraversable: scala.Function1) -> scala.collection.GenTraversable: ...
    _union__B = typing.TypeVar('_union__B')  # <B>
    _union__That = typing.TypeVar('_union__That')  # <That>
    def union(self, that: scala.collection.GenSeq[_union__B], bf: scala.collection.generic.CanBuildFrom['ParArray'[_ParArray__T], _union__B, _union__That]) -> _union__That: ...
    _unzip__A1 = typing.TypeVar('_unzip__A1')  # <A1>
    _unzip__A2 = typing.TypeVar('_unzip__A2')  # <A2>
    def unzip(self, asPair: scala.Function1[_ParArray__T, scala.Tuple2[_unzip__A1, _unzip__A2]]) -> scala.Tuple2['ParArray'[_unzip__A1], 'ParArray'[_unzip__A2]]: ...
    _unzip3__A1 = typing.TypeVar('_unzip3__A1')  # <A1>
    _unzip3__A2 = typing.TypeVar('_unzip3__A2')  # <A2>
    _unzip3__A3 = typing.TypeVar('_unzip3__A3')  # <A3>
    def unzip3(self, asTriple: scala.Function1[_ParArray__T, scala.Tuple3[_unzip3__A1, _unzip3__A2, _unzip3__A3]]) -> scala.Tuple3['ParArray'[_unzip3__A1], 'ParArray'[_unzip3__A2], 'ParArray'[_unzip3__A3]]: ...
    def update(self, i: int, elem: _ParArray__T) -> None: ...
    _updated__U = typing.TypeVar('_updated__U')  # <U>
    _updated__That = typing.TypeVar('_updated__That')  # <That>
    def updated(self, index: int, elem: _updated__U, bf: scala.collection.generic.CanBuildFrom['ParArray'[_ParArray__T], _updated__U, _updated__That]) -> _updated__That: ...
    def view(self) -> scala.collection.SeqView[_ParArray__T, scala.collection.mutable.ArraySeq[_ParArray__T]]: ...
    def withFilter(self, pred: scala.Function1) -> scala.collection.parallel.ParIterable: ...
    _wrap__R = typing.TypeVar('_wrap__R')  # <R>
    def wrap(self, body: scala.Function0[_wrap__R]) -> scala.collection.parallel.ParIterableLike.NonDivisible[_wrap__R]: ...
    _zip__U = typing.TypeVar('_zip__U')  # <U>
    _zip__S = typing.TypeVar('_zip__S')  # <S>
    _zip__That = typing.TypeVar('_zip__That')  # <That>
    def zip(self, that: scala.collection.GenIterable[_zip__S], bf: scala.collection.generic.CanBuildFrom['ParArray'[_ParArray__T], scala.Tuple2[_zip__U, _zip__S], _zip__That]) -> _zip__That: ...
    _zipAll__S = typing.TypeVar('_zipAll__S')  # <S>
    _zipAll__U = typing.TypeVar('_zipAll__U')  # <U>
    _zipAll__That = typing.TypeVar('_zipAll__That')  # <That>
    def zipAll(self, that: scala.collection.GenIterable[_zipAll__S], thisElem: _zipAll__U, thatElem: _zipAll__S, bf: scala.collection.generic.CanBuildFrom['ParArray'[_ParArray__T], scala.Tuple2[_zipAll__U, _zipAll__S], _zipAll__That]) -> _zipAll__That: ...
    _zipWithIndex__U = typing.TypeVar('_zipWithIndex__U')  # <U>
    _zipWithIndex__That = typing.TypeVar('_zipWithIndex__That')  # <That>
    def zipWithIndex(self, bf: scala.collection.generic.CanBuildFrom['ParArray'[_ParArray__T], scala.Tuple2[_zipWithIndex__U, typing.Any], _zipWithIndex__That]) -> _zipWithIndex__That: ...
    class Map(scala.collection.parallel.Task[scala.runtime.BoxedUnit, 'ParArray.Map'[_ParArray__Map__S]], typing.Generic[_ParArray__Map__S]):
        $outer: 'ParArray' = ...
        def __init__(self, $outer: 'ParArray', f: scala.Function1[_ParArray__T, _ParArray__Map__S], targetarr: typing.List[typing.Any], offset: int, howmany: int): ...
        def forwardThrowable(self) -> None: ...
        def leaf(self, prev: scala.Option[scala.runtime.BoxedUnit]) -> None: ...
        def merge(self, that: typing.Any) -> None: ...
        def mergeThrowables(self, that: scala.collection.parallel.Task[typing.Any, typing.Any]) -> None: ...
        def repr(self) -> typing.Any: ...
        def result(self) -> None: ...
        def result_$eq(self, x$1: scala.runtime.BoxedUnit) -> None: ...
        def shouldSplitFurther(self) -> bool: ...
        def signalAbort(self) -> None: ...
        def split(self) -> scala.collection.immutable.List['ParArray.Map'[_ParArray__Map__S]]: ...
        def throwable(self) -> java.lang.Throwable: ...
        def throwable_$eq(self, x$1: java.lang.Throwable) -> None: ...
        def tryLeaf(self, lastres: scala.Option[scala.runtime.BoxedUnit]) -> None: ...
        def tryMerge(self, t: typing.Any) -> None: ...
    class ParArrayIterator(scala.collection.parallel.SeqSplitter[_ParArray__T]):
        $outer: 'ParArray' = ...
        def __init__(self, $outer: 'ParArray', i: int, until: int, arr: typing.List[typing.Any]): ...
        _$colon$bslash__B = typing.TypeVar('_$colon$bslash__B')  # <B>
        def $colon$bslash(self, z: _.colon.bslash__B, op: scala.Function2[_ParArray__T, _.colon.bslash__B, _.colon.bslash__B]) -> _.colon.bslash__B: ...
        _$div$colon__B = typing.TypeVar('_$div$colon__B')  # <B>
        def $div$colon(self, z: _.div.colon__B, op: scala.Function2[_.div.colon__B, _ParArray__T, _.div.colon__B]) -> _.div.colon__B: ...
        _$plus$plus__B = typing.TypeVar('_$plus$plus__B')  # <B>
        def $plus$plus(self, that: scala.Function0[scala.collection.GenTraversableOnce[_.plus.plus__B]]) -> scala.collection.Iterator[_.plus.plus__B]: ...
        def abort(self) -> None: ...
        @typing.overload
        def addString(self, b: scala.collection.mutable.StringBuilder) -> scala.collection.mutable.StringBuilder: ...
        @typing.overload
        def addString(self, b: scala.collection.mutable.StringBuilder, sep: str) -> scala.collection.mutable.StringBuilder: ...
        @typing.overload
        def addString(self, b: scala.collection.mutable.StringBuilder, start: str, sep: str, end: str) -> scala.collection.mutable.StringBuilder: ...
        _aggregate__S = typing.TypeVar('_aggregate__S')  # <S>
        def aggregate(self, z: scala.Function0[_aggregate__S], seqop: scala.Function2[_aggregate__S, _ParArray__T, _aggregate__S], combop: scala.Function2[_aggregate__S, _aggregate__S, _aggregate__S]) -> _aggregate__S: ...
        _appendParIterable__U = typing.TypeVar('_appendParIterable__U')  # <U>
        _appendParIterable__PI = typing.TypeVar('_appendParIterable__PI', bound=scala.collection.parallel.IterableSplitter)  # <PI>
        def appendParIterable(self, that: _appendParIterable__PI) -> scala.collection.parallel.IterableSplitter.Appended[_appendParIterable__U, _appendParIterable__PI]: ...
        _appendParSeq__U = typing.TypeVar('_appendParSeq__U')  # <U>
        _appendParSeq__PI = typing.TypeVar('_appendParSeq__PI', bound=scala.collection.parallel.SeqSplitter)  # <PI>
        def appendParSeq(self, that: _appendParSeq__PI) -> scala.collection.parallel.SeqSplitter.Appended[_appendParSeq__U, _appendParSeq__PI]: ...
        def arr(self) -> typing.List[typing.Any]: ...
        def buffered(self) -> scala.collection.BufferedIterator[_ParArray__T]: ...
        def buildString(self, closure: scala.Function1[scala.Function1[str, scala.runtime.BoxedUnit], scala.runtime.BoxedUnit]) -> str: ...
        _collect__B = typing.TypeVar('_collect__B')  # <B>
        def collect(self, pf: scala.PartialFunction[_ParArray__T, _collect__B]) -> scala.collection.Iterator[_collect__B]: ...
        _collect2combiner__S = typing.TypeVar('_collect2combiner__S')  # <S>
        _collect2combiner__That = typing.TypeVar('_collect2combiner__That')  # <That>
        def collect2combiner(self, pf: scala.PartialFunction[_ParArray__T, _collect2combiner__S], cb: scala.collection.parallel.Combiner[_collect2combiner__S, _collect2combiner__That]) -> scala.collection.parallel.Combiner[_collect2combiner__S, _collect2combiner__That]: ...
        _collectFirst__B = typing.TypeVar('_collectFirst__B')  # <B>
        def collectFirst(self, pf: scala.PartialFunction[_ParArray__T, _collectFirst__B]) -> scala.Option[_collectFirst__B]: ...
        def contains(self, elem: typing.Any) -> bool: ...
        _copy2builder__U = typing.TypeVar('_copy2builder__U')  # <U>
        _copy2builder__Coll = typing.TypeVar('_copy2builder__Coll')  # <Coll>
        _copy2builder__Bld = typing.TypeVar('_copy2builder__Bld', bound=scala.collection.mutable.Builder)  # <Bld>
        def copy2builder(self, cb: _copy2builder__Bld) -> _copy2builder__Bld: ...
        _copyToArray_0__B = typing.TypeVar('_copyToArray_0__B')  # <B>
        _copyToArray_1__B = typing.TypeVar('_copyToArray_1__B')  # <B>
        _copyToArray_2__U = typing.TypeVar('_copyToArray_2__U')  # <U>
        @typing.overload
        def copyToArray(self, xs: typing.Any) -> None: ...
        @typing.overload
        def copyToArray(self, xs: typing.Any, start: int) -> None: ...
        @typing.overload
        def copyToArray(self, array: typing.Any, from_: int, len: int) -> None: ...
        _copyToBuffer__B = typing.TypeVar('_copyToBuffer__B')  # <B>
        def copyToBuffer(self, dest: scala.collection.mutable.Buffer[_copyToBuffer__B]) -> None: ...
        _corresponds_0__S = typing.TypeVar('_corresponds_0__S')  # <S>
        _corresponds_1__B = typing.TypeVar('_corresponds_1__B')  # <B>
        @typing.overload
        def corresponds(self, corr: scala.Function2[_ParArray__T, _corresponds_0__S, typing.Any], that: scala.collection.Iterator[_corresponds_0__S]) -> bool: ...
        @typing.overload
        def corresponds(self, that: scala.collection.GenTraversableOnce[_corresponds_1__B], p: scala.Function2[_ParArray__T, _corresponds_1__B, typing.Any]) -> bool: ...
        def count(self, p: scala.Function1[_ParArray__T, typing.Any]) -> int: ...
        def debugInformation(self) -> str: ...
        def drop(self, n: int) -> 'ParArray.ParArrayIterator': ...
        _drop2combiner__U = typing.TypeVar('_drop2combiner__U')  # <U>
        _drop2combiner__This = typing.TypeVar('_drop2combiner__This')  # <This>
        def drop2combiner(self, n: int, cb: scala.collection.parallel.Combiner[_drop2combiner__U, _drop2combiner__This]) -> scala.collection.parallel.Combiner[_drop2combiner__U, _drop2combiner__This]: ...
        def dropWhile(self, p: scala.Function1[_ParArray__T, typing.Any]) -> scala.collection.Iterator[_ParArray__T]: ...
        def dup(self) -> 'ParArray.ParArrayIterator': ...
        def duplicate(self) -> scala.Tuple2[scala.collection.Iterator[_ParArray__T], scala.collection.Iterator[_ParArray__T]]: ...
        def exists(self, p: scala.Function1[_ParArray__T, typing.Any]) -> bool: ...
        def filter(self, p: scala.Function1[_ParArray__T, typing.Any]) -> scala.collection.Iterator[_ParArray__T]: ...
        _filter2combiner__U = typing.TypeVar('_filter2combiner__U')  # <U>
        _filter2combiner__This = typing.TypeVar('_filter2combiner__This')  # <This>
        def filter2combiner(self, pred: scala.Function1[_ParArray__T, typing.Any], cb: scala.collection.parallel.Combiner[_filter2combiner__U, _filter2combiner__This]) -> scala.collection.parallel.Combiner[_filter2combiner__U, _filter2combiner__This]: ...
        def filterNot(self, p: scala.Function1[_ParArray__T, typing.Any]) -> scala.collection.Iterator[_ParArray__T]: ...
        _filterNot2combiner__U = typing.TypeVar('_filterNot2combiner__U')  # <U>
        _filterNot2combiner__This = typing.TypeVar('_filterNot2combiner__This')  # <This>
        def filterNot2combiner(self, pred: scala.Function1[_ParArray__T, typing.Any], cb: scala.collection.parallel.Combiner[_filterNot2combiner__U, _filterNot2combiner__This]) -> scala.collection.parallel.Combiner[_filterNot2combiner__U, _filterNot2combiner__This]: ...
        def find(self, p: scala.Function1[_ParArray__T, typing.Any]) -> scala.Option[_ParArray__T]: ...
        _flatMap__B = typing.TypeVar('_flatMap__B')  # <B>
        def flatMap(self, f: scala.Function1[_ParArray__T, scala.collection.GenTraversableOnce[_flatMap__B]]) -> scala.collection.Iterator[_flatMap__B]: ...
        _flatmap2combiner__S = typing.TypeVar('_flatmap2combiner__S')  # <S>
        _flatmap2combiner__That = typing.TypeVar('_flatmap2combiner__That')  # <That>
        def flatmap2combiner(self, f: scala.Function1[_ParArray__T, scala.collection.GenTraversableOnce[_flatmap2combiner__S]], cb: scala.collection.parallel.Combiner[_flatmap2combiner__S, _flatmap2combiner__That]) -> scala.collection.parallel.Combiner[_flatmap2combiner__S, _flatmap2combiner__That]: ...
        _fold__U = typing.TypeVar('_fold__U')  # <U>
        def fold(self, z: _fold__U, op: scala.Function2[_fold__U, _fold__U, _fold__U]) -> _fold__U: ...
        _foldLeft__S = typing.TypeVar('_foldLeft__S')  # <S>
        def foldLeft(self, z: _foldLeft__S, op: scala.Function2[_foldLeft__S, _ParArray__T, _foldLeft__S]) -> _foldLeft__S: ...
        _foldRight__B = typing.TypeVar('_foldRight__B')  # <B>
        def foldRight(self, z: _foldRight__B, op: scala.Function2[_ParArray__T, _foldRight__B, _foldRight__B]) -> _foldRight__B: ...
        def forall(self, p: scala.Function1[_ParArray__T, typing.Any]) -> bool: ...
        _foreach__U = typing.TypeVar('_foreach__U')  # <U>
        def foreach(self, f: scala.Function1[_ParArray__T, _foreach__U]) -> None: ...
        _grouped__B = typing.TypeVar('_grouped__B')  # <B>
        def grouped(self, size: int) -> scala.collection.Iterator.GroupedIterator[_grouped__B]: ...
        def hasDefiniteSize(self) -> bool: ...
        def hasNext(self) -> bool: ...
        def i(self) -> int: ...
        def i_$eq(self, x$1: int) -> None: ...
        def indexFlag(self) -> int: ...
        _indexOf_0__B = typing.TypeVar('_indexOf_0__B')  # <B>
        _indexOf_1__B = typing.TypeVar('_indexOf_1__B')  # <B>
        @typing.overload
        def indexOf(self, elem: _indexOf_0__B) -> int: ...
        @typing.overload
        def indexOf(self, elem: _indexOf_1__B, from_: int) -> int: ...
        @typing.overload
        def indexWhere(self, pred: scala.Function1[_ParArray__T, typing.Any]) -> int: ...
        @typing.overload
        def indexWhere(self, p: scala.Function1[_ParArray__T, typing.Any], from_: int) -> int: ...
        def isAborted(self) -> bool: ...
        def isEmpty(self) -> bool: ...
        def isRemainingCheap(self) -> bool: ...
        def isTraversableAgain(self) -> bool: ...
        def lastIndexWhere(self, pred: scala.Function1[_ParArray__T, typing.Any]) -> int: ...
        def length(self) -> int: ...
        _map__S = typing.TypeVar('_map__S')  # <S>
        def map(self, f: scala.Function1[_ParArray__T, _map__S]) -> scala.collection.parallel.SeqSplitter.Mapped[_map__S]: ...
        _map2combiner__S = typing.TypeVar('_map2combiner__S')  # <S>
        _map2combiner__That = typing.TypeVar('_map2combiner__That')  # <That>
        def map2combiner(self, f: scala.Function1[_ParArray__T, _map2combiner__S], cb: scala.collection.parallel.Combiner[_map2combiner__S, _map2combiner__That]) -> scala.collection.parallel.Combiner[_map2combiner__S, _map2combiner__That]: ...
        _max__U = typing.TypeVar('_max__U')  # <U>
        def max(self, ord: scala.math.Ordering[_max__U]) -> _ParArray__T: ...
        _maxBy__B = typing.TypeVar('_maxBy__B')  # <B>
        def maxBy(self, f: scala.Function1[_ParArray__T, _maxBy__B], cmp: scala.math.Ordering[_maxBy__B]) -> _ParArray__T: ...
        _min__U = typing.TypeVar('_min__U')  # <U>
        def min(self, ord: scala.math.Ordering[_min__U]) -> _ParArray__T: ...
        _minBy__B = typing.TypeVar('_minBy__B')  # <B>
        def minBy(self, f: scala.Function1[_ParArray__T, _minBy__B], cmp: scala.math.Ordering[_minBy__B]) -> _ParArray__T: ...
        @typing.overload
        def mkString(self) -> str: ...
        @typing.overload
        def mkString(self, sep: str) -> str: ...
        @typing.overload
        def mkString(self, start: str, sep: str, end: str) -> str: ...
        _newSliceInternal__U = typing.TypeVar('_newSliceInternal__U', bound=scala.collection.parallel.IterableSplitter.Taken)  # <U>
        def newSliceInternal(self, it: _newSliceInternal__U, from1: int) -> _newSliceInternal__U: ...
        def newTaken(self, until: int) -> scala.collection.parallel.SeqSplitter.Taken: ...
        def next(self) -> _ParArray__T: ...
        def nonEmpty(self) -> bool: ...
        _padTo__A1 = typing.TypeVar('_padTo__A1')  # <A1>
        def padTo(self, len: int, elem: _padTo__A1) -> scala.collection.Iterator[_padTo__A1]: ...
        def partition(self, p: scala.Function1[_ParArray__T, typing.Any]) -> scala.Tuple2[scala.collection.Iterator[_ParArray__T], scala.collection.Iterator[_ParArray__T]]: ...
        _partition2combiners__U = typing.TypeVar('_partition2combiners__U')  # <U>
        _partition2combiners__This = typing.TypeVar('_partition2combiners__This')  # <This>
        def partition2combiners(self, pred: scala.Function1[_ParArray__T, typing.Any], btrue: scala.collection.parallel.Combiner[_partition2combiners__U, _partition2combiners__This], bfalse: scala.collection.parallel.Combiner[_partition2combiners__U, _partition2combiners__This]) -> scala.Tuple2[scala.collection.parallel.Combiner[_partition2combiners__U, _partition2combiners__This], scala.collection.parallel.Combiner[_partition2combiners__U, _partition2combiners__This]]: ...
        _patch__B = typing.TypeVar('_patch__B')  # <B>
        def patch(self, from_: int, patchElems: scala.collection.Iterator[_patch__B], replaced: int) -> scala.collection.Iterator[_patch__B]: ...
        _patchParSeq__U = typing.TypeVar('_patchParSeq__U')  # <U>
        def patchParSeq(self, from_: int, patchElems: scala.collection.parallel.SeqSplitter[_patchParSeq__U], replaced: int) -> scala.collection.parallel.SeqSplitter.Patched[_patchParSeq__U]: ...
        def prefixLength(self, pred: scala.Function1[_ParArray__T, typing.Any]) -> int: ...
        _product__U = typing.TypeVar('_product__U')  # <U>
        def product(self, num: scala.math.Numeric[_product__U]) -> _product__U: ...
        def psplit(self, sizesIncomplete: scala.collection.Seq[typing.Any]) -> scala.collection.Seq['ParArray.ParArrayIterator']: ...
        def psplitWithSignalling(self, sizes: scala.collection.Seq[typing.Any]) -> scala.collection.Seq[scala.collection.parallel.SeqSplitter[_ParArray__T]]: ...
        _reduce__U = typing.TypeVar('_reduce__U')  # <U>
        def reduce(self, op: scala.Function2[_reduce__U, _reduce__U, _reduce__U]) -> _reduce__U: ...
        _reduceLeft_0__U = typing.TypeVar('_reduceLeft_0__U')  # <U>
        _reduceLeft_1__B = typing.TypeVar('_reduceLeft_1__B')  # <B>
        @typing.overload
        def reduceLeft(self, howmany: int, op: scala.Function2[_reduceLeft_0__U, _reduceLeft_0__U, _reduceLeft_0__U]) -> _reduceLeft_0__U: ...
        @typing.overload
        def reduceLeft(self, op: scala.Function2[_reduceLeft_1__B, _ParArray__T, _reduceLeft_1__B]) -> _reduceLeft_1__B: ...
        _reduceLeftOption__B = typing.TypeVar('_reduceLeftOption__B')  # <B>
        def reduceLeftOption(self, op: scala.Function2[_reduceLeftOption__B, _ParArray__T, _reduceLeftOption__B]) -> scala.Option[_reduceLeftOption__B]: ...
        _reduceOption__A1 = typing.TypeVar('_reduceOption__A1')  # <A1>
        def reduceOption(self, op: scala.Function2[_reduceOption__A1, _reduceOption__A1, _reduceOption__A1]) -> scala.Option[_reduceOption__A1]: ...
        _reduceRight__B = typing.TypeVar('_reduceRight__B')  # <B>
        def reduceRight(self, op: scala.Function2[_ParArray__T, _reduceRight__B, _reduceRight__B]) -> _reduceRight__B: ...
        _reduceRightOption__B = typing.TypeVar('_reduceRightOption__B')  # <B>
        def reduceRightOption(self, op: scala.Function2[_ParArray__T, _reduceRightOption__B, _reduceRightOption__B]) -> scala.Option[_reduceRightOption__B]: ...
        def remaining(self) -> int: ...
        def reverse(self) -> scala.collection.parallel.SeqSplitter[_ParArray__T]: ...
        _reverse2combiner__U = typing.TypeVar('_reverse2combiner__U')  # <U>
        _reverse2combiner__This = typing.TypeVar('_reverse2combiner__This')  # <This>
        def reverse2combiner(self, cb: scala.collection.parallel.Combiner[_reverse2combiner__U, _reverse2combiner__This]) -> scala.collection.parallel.Combiner[_reverse2combiner__U, _reverse2combiner__This]: ...
        _reverseMap2combiner__S = typing.TypeVar('_reverseMap2combiner__S')  # <S>
        _reverseMap2combiner__That = typing.TypeVar('_reverseMap2combiner__That')  # <That>
        def reverseMap2combiner(self, f: scala.Function1[_ParArray__T, _reverseMap2combiner__S], cb: scala.collection.parallel.Combiner[_reverseMap2combiner__S, _reverseMap2combiner__That]) -> scala.collection.parallel.Combiner[_reverseMap2combiner__S, _reverseMap2combiner__That]: ...
        def reversed(self) -> scala.collection.immutable.List[_ParArray__T]: ...
        def sameElements(self, that: scala.collection.Iterator[typing.Any]) -> bool: ...
        _scanLeft__B = typing.TypeVar('_scanLeft__B')  # <B>
        def scanLeft(self, z: _scanLeft__B, op: scala.Function2[_scanLeft__B, _ParArray__T, _scanLeft__B]) -> scala.collection.Iterator[_scanLeft__B]: ...
        _scanRight__B = typing.TypeVar('_scanRight__B')  # <B>
        def scanRight(self, z: _scanRight__B, op: scala.Function2[_ParArray__T, _scanRight__B, _scanRight__B]) -> scala.collection.Iterator[_scanRight__B]: ...
        _scanToArray__U = typing.TypeVar('_scanToArray__U')  # <U>
        _scanToArray__A = typing.TypeVar('_scanToArray__A')  # <A>
        def scanToArray(self, z: _scanToArray__U, op: scala.Function2[_scanToArray__U, _scanToArray__U, _scanToArray__U], destarr: typing.Any, from_: int) -> None: ...
        _scanToArray_quick__U = typing.TypeVar('_scanToArray_quick__U')  # <U>
        def scanToArray_quick(self, srcarr: typing.List[typing.Any], destarr: typing.List[typing.Any], op: scala.Function2[_scanToArray_quick__U, _scanToArray_quick__U, _scanToArray_quick__U], z: _scanToArray_quick__U, srcfrom: int, srcntil: int, destfrom: int) -> None: ...
        _scanToCombiner_0__U = typing.TypeVar('_scanToCombiner_0__U')  # <U>
        _scanToCombiner_0__That = typing.TypeVar('_scanToCombiner_0__That')  # <That>
        _scanToCombiner_1__U = typing.TypeVar('_scanToCombiner_1__U')  # <U>
        _scanToCombiner_1__That = typing.TypeVar('_scanToCombiner_1__That')  # <That>
        @typing.overload
        def scanToCombiner(self, howmany: int, startValue: _scanToCombiner_0__U, op: scala.Function2[_scanToCombiner_0__U, _scanToCombiner_0__U, _scanToCombiner_0__U], cb: scala.collection.parallel.Combiner[_scanToCombiner_0__U, _scanToCombiner_0__That]) -> scala.collection.parallel.Combiner[_scanToCombiner_0__U, _scanToCombiner_0__That]: ...
        @typing.overload
        def scanToCombiner(self, startValue: _scanToCombiner_1__U, op: scala.Function2[_scanToCombiner_1__U, _scanToCombiner_1__U, _scanToCombiner_1__U], cb: scala.collection.parallel.Combiner[_scanToCombiner_1__U, _scanToCombiner_1__That]) -> scala.collection.parallel.Combiner[_scanToCombiner_1__U, _scanToCombiner_1__That]: ...
        def seq(self) -> scala.collection.Iterator[_ParArray__T]: ...
        def setIndexFlag(self, f: int) -> None: ...
        def setIndexFlagIfGreater(self, f: int) -> None: ...
        def setIndexFlagIfLesser(self, f: int) -> None: ...
        _shouldSplitFurther__S = typing.TypeVar('_shouldSplitFurther__S')  # <S>
        def shouldSplitFurther(self, coll: scala.collection.parallel.ParIterable[_shouldSplitFurther__S], parallelismLevel: int) -> bool: ...
        def signalDelegate(self) -> scala.collection.generic.Signalling: ...
        def signalDelegate_$eq(self, x$1: scala.collection.generic.Signalling) -> None: ...
        def size(self) -> int: ...
        def sizeHintIfCheap(self) -> int: ...
        def slice(self, from1: int, until1: int) -> scala.collection.parallel.SeqSplitter[_ParArray__T]: ...
        _slice2combiner__U = typing.TypeVar('_slice2combiner__U')  # <U>
        _slice2combiner__This = typing.TypeVar('_slice2combiner__This')  # <This>
        def slice2combiner(self, from_: int, until: int, cb: scala.collection.parallel.Combiner[_slice2combiner__U, _slice2combiner__This]) -> scala.collection.parallel.Combiner[_slice2combiner__U, _slice2combiner__This]: ...
        def sliceIterator(self, from_: int, until: int) -> scala.collection.Iterator[_ParArray__T]: ...
        _sliding__B = typing.TypeVar('_sliding__B')  # <B>
        def sliding(self, size: int, step: int) -> scala.collection.Iterator.GroupedIterator[_sliding__B]: ...
        _sliding$default$2__B = typing.TypeVar('_sliding$default$2__B')  # <B>
        def sliding$default$2(self) -> int: ...
        def span(self, p: scala.Function1[_ParArray__T, typing.Any]) -> scala.Tuple2[scala.collection.Iterator[_ParArray__T], scala.collection.Iterator[_ParArray__T]]: ...
        _span2combiners__U = typing.TypeVar('_span2combiners__U')  # <U>
        _span2combiners__This = typing.TypeVar('_span2combiners__This')  # <This>
        def span2combiners(self, p: scala.Function1[_ParArray__T, typing.Any], before: scala.collection.parallel.Combiner[_span2combiners__U, _span2combiners__This], after: scala.collection.parallel.Combiner[_span2combiners__U, _span2combiners__This]) -> scala.Tuple2[scala.collection.parallel.Combiner[_span2combiners__U, _span2combiners__This], scala.collection.parallel.Combiner[_span2combiners__U, _span2combiners__This]]: ...
        def split(self) -> scala.collection.Seq['ParArray.ParArrayIterator']: ...
        _splitAt2combiners__U = typing.TypeVar('_splitAt2combiners__U')  # <U>
        _splitAt2combiners__This = typing.TypeVar('_splitAt2combiners__This')  # <This>
        def splitAt2combiners(self, at: int, before: scala.collection.parallel.Combiner[_splitAt2combiners__U, _splitAt2combiners__This], after: scala.collection.parallel.Combiner[_splitAt2combiners__U, _splitAt2combiners__This]) -> scala.Tuple2[scala.collection.parallel.Combiner[_splitAt2combiners__U, _splitAt2combiners__This], scala.collection.parallel.Combiner[_splitAt2combiners__U, _splitAt2combiners__This]]: ...
        def splitWithSignalling(self) -> scala.collection.Seq[scala.collection.parallel.SeqSplitter[_ParArray__T]]: ...
        _sum__U = typing.TypeVar('_sum__U')  # <U>
        def sum(self, num: scala.math.Numeric[_sum__U]) -> _sum__U: ...
        def tag(self) -> int: ...
        def take(self, n: int) -> scala.collection.parallel.SeqSplitter[_ParArray__T]: ...
        _take2combiner__U = typing.TypeVar('_take2combiner__U')  # <U>
        _take2combiner__This = typing.TypeVar('_take2combiner__This')  # <This>
        def take2combiner(self, n: int, cb: scala.collection.parallel.Combiner[_take2combiner__U, _take2combiner__This]) -> scala.collection.parallel.Combiner[_take2combiner__U, _take2combiner__This]: ...
        def takeWhile(self, p: scala.Function1[_ParArray__T, typing.Any]) -> scala.collection.Iterator[_ParArray__T]: ...
        _takeWhile2combiner__U = typing.TypeVar('_takeWhile2combiner__U')  # <U>
        _takeWhile2combiner__This = typing.TypeVar('_takeWhile2combiner__This')  # <This>
        def takeWhile2combiner(self, p: scala.Function1[_ParArray__T, typing.Any], cb: scala.collection.parallel.Combiner[_takeWhile2combiner__U, _takeWhile2combiner__This]) -> scala.Tuple2[scala.collection.parallel.Combiner[_takeWhile2combiner__U, _takeWhile2combiner__This], typing.Any]: ...
        _to__Col = typing.TypeVar('_to__Col')  # <Col>
        def to(self, cbf: scala.collection.generic.CanBuildFrom[scala.runtime.Nothing., _ParArray__T, _to__Col]) -> _to__Col: ...
        _toArray__B = typing.TypeVar('_toArray__B')  # <B>
        def toArray(self, evidence$1: scala.reflect.ClassTag[_toArray__B]) -> typing.Any: ...
        _toBuffer__B = typing.TypeVar('_toBuffer__B')  # <B>
        def toBuffer(self) -> scala.collection.mutable.Buffer[_toBuffer__B]: ...
        def toIndexedSeq(self) -> scala.collection.immutable.IndexedSeq[_ParArray__T]: ...
        def toIterable(self) -> scala.collection.Iterable[_ParArray__T]: ...
        def toIterator(self) -> scala.collection.Iterator[_ParArray__T]: ...
        def toList(self) -> scala.collection.immutable.List[_ParArray__T]: ...
        _toMap__T = typing.TypeVar('_toMap__T')  # <T>
        _toMap__U = typing.TypeVar('_toMap__U')  # <U>
        def toMap(self, ev: scala.Predef..less.colon.less[typing.Any, scala.Tuple2[typing.Any, _toMap__U]]) -> scala.collection.immutable.Map[typing.Any, _toMap__U]: ...
        def toSeq(self) -> scala.collection.Seq[_ParArray__T]: ...
        _toSet__B = typing.TypeVar('_toSet__B')  # <B>
        def toSet(self) -> scala.collection.immutable.Set[_toSet__B]: ...
        def toStream(self) -> scala.collection.immutable.Stream[_ParArray__T]: ...
        def toString(self) -> str: ...
        def toTraversable(self) -> scala.collection.Traversable[_ParArray__T]: ...
        def toVector(self) -> scala.collection.immutable.Vector[_ParArray__T]: ...
        def until(self) -> int: ...
        _updated2combiner__U = typing.TypeVar('_updated2combiner__U')  # <U>
        _updated2combiner__That = typing.TypeVar('_updated2combiner__That')  # <That>
        def updated2combiner(self, index: int, elem: _updated2combiner__U, cb: scala.collection.parallel.Combiner[_updated2combiner__U, _updated2combiner__That]) -> scala.collection.parallel.Combiner[_updated2combiner__U, _updated2combiner__That]: ...
        def withFilter(self, p: scala.Function1[_ParArray__T, typing.Any]) -> scala.collection.Iterator[_ParArray__T]: ...
        _zip__B = typing.TypeVar('_zip__B')  # <B>
        def zip(self, that: scala.collection.Iterator[_zip__B]) -> scala.collection.Iterator[scala.Tuple2[_ParArray__T, _zip__B]]: ...
        _zip2combiner__U = typing.TypeVar('_zip2combiner__U')  # <U>
        _zip2combiner__S = typing.TypeVar('_zip2combiner__S')  # <S>
        _zip2combiner__That = typing.TypeVar('_zip2combiner__That')  # <That>
        def zip2combiner(self, otherpit: scala.collection.parallel.RemainsIterator[_zip2combiner__S], cb: scala.collection.parallel.Combiner[scala.Tuple2[_zip2combiner__U, _zip2combiner__S], _zip2combiner__That]) -> scala.collection.parallel.Combiner[scala.Tuple2[_zip2combiner__U, _zip2combiner__S], _zip2combiner__That]: ...
        _zipAll__B = typing.TypeVar('_zipAll__B')  # <B>
        _zipAll__A1 = typing.TypeVar('_zipAll__A1')  # <A1>
        _zipAll__B1 = typing.TypeVar('_zipAll__B1')  # <B1>
        def zipAll(self, that: scala.collection.Iterator[_zipAll__B], thisElem: _zipAll__A1, thatElem: _zipAll__B1) -> scala.collection.Iterator[scala.Tuple2[_zipAll__A1, _zipAll__B1]]: ...
        _zipAll2combiner__U = typing.TypeVar('_zipAll2combiner__U')  # <U>
        _zipAll2combiner__S = typing.TypeVar('_zipAll2combiner__S')  # <S>
        _zipAll2combiner__That = typing.TypeVar('_zipAll2combiner__That')  # <That>
        def zipAll2combiner(self, that: scala.collection.parallel.RemainsIterator[_zipAll2combiner__S], thiselem: _zipAll2combiner__U, thatelem: _zipAll2combiner__S, cb: scala.collection.parallel.Combiner[scala.Tuple2[_zipAll2combiner__U, _zipAll2combiner__S], _zipAll2combiner__That]) -> scala.collection.parallel.Combiner[scala.Tuple2[_zipAll2combiner__U, _zipAll2combiner__S], _zipAll2combiner__That]: ...
        _zipAllParSeq__S = typing.TypeVar('_zipAllParSeq__S')  # <S>
        _zipAllParSeq__U = typing.TypeVar('_zipAllParSeq__U')  # <U>
        _zipAllParSeq__R = typing.TypeVar('_zipAllParSeq__R')  # <R>
        def zipAllParSeq(self, that: scala.collection.parallel.SeqSplitter[_zipAllParSeq__S], thisElem: _zipAllParSeq__U, thatElem: _zipAllParSeq__R) -> scala.collection.parallel.SeqSplitter.ZippedAll[_zipAllParSeq__U, _zipAllParSeq__R]: ...
        _zipParSeq__S = typing.TypeVar('_zipParSeq__S')  # <S>
        def zipParSeq(self, that: scala.collection.parallel.SeqSplitter[_zipParSeq__S]) -> scala.collection.parallel.SeqSplitter.Zipped[_zipParSeq__S]: ...
        def zipWithIndex(self) -> scala.collection.Iterator[scala.Tuple2[_ParArray__T, typing.Any]]: ...
    class ParArrayIterator$:
        def __init__(self, $outer: 'ParArray'): ...
        def $lessinit$greater$default$1(self) -> int: ...
        def $lessinit$greater$default$2(self) -> int: ...
        def $lessinit$greater$default$3(self) -> typing.List[typing.Any]: ...
    class ScanToArray(scala.collection.parallel.Task[scala.runtime.BoxedUnit, 'ParArray.ScanToArray'[_ParArray__ScanToArray__U]], typing.Generic[_ParArray__ScanToArray__U]):
        $outer: 'ParArray' = ...
        def __init__(self, $outer: 'ParArray', tree: scala.collection.parallel.ParIterableLike.ScanTree[_ParArray__ScanToArray__U], z: _ParArray__ScanToArray__U, op: scala.Function2[_ParArray__ScanToArray__U, _ParArray__ScanToArray__U, _ParArray__ScanToArray__U], targetarr: typing.List[typing.Any]): ...
        def forwardThrowable(self) -> None: ...
        def leaf(self, prev: scala.Option[scala.runtime.BoxedUnit]) -> None: ...
        def merge(self, that: typing.Any) -> None: ...
        def mergeThrowables(self, that: scala.collection.parallel.Task[typing.Any, typing.Any]) -> None: ...
        def repr(self) -> typing.Any: ...
        def result(self) -> None: ...
        def result_$eq(self, x$1: scala.runtime.BoxedUnit) -> None: ...
        def shouldSplitFurther(self) -> bool: ...
        def signalAbort(self) -> None: ...
        def split(self) -> scala.collection.Seq[scala.collection.parallel.Task[scala.runtime.BoxedUnit, 'ParArray.ScanToArray'[_ParArray__ScanToArray__U]]]: ...
        def throwable(self) -> java.lang.Throwable: ...
        def throwable_$eq(self, x$1: java.lang.Throwable) -> None: ...
        def tryLeaf(self, lastres: scala.Option[scala.runtime.BoxedUnit]) -> None: ...
        def tryMerge(self, t: typing.Any) -> None: ...

_ParHashSet__T = typing.TypeVar('_ParHashSet__T')  # <T>
class ParHashSet(ParSet[_ParHashSet__T], ParFlatHashTable[_ParHashSet__T], scala.Serializable, typing.Generic[_ParHashSet__T]):
    serialVersionUID: typing.ClassVar[int] = ...
    @typing.overload
    def __init__(self): ...
    @typing.overload
    def __init__(self, contents: scala.collection.mutable.FlatHashTable.Contents[_ParHashSet__T]): ...
    def $amp(self, that: scala.collection.GenSet) -> typing.Any: ...
    def $amp$tilde(self, that: scala.collection.GenSet) -> typing.Any: ...
    def $bar(self, that: scala.collection.GenSet) -> typing.Any: ...
    _$colon$bslash__S = typing.TypeVar('_$colon$bslash__S')  # <S>
    def $colon$bslash(self, z: _.colon.bslash__S, op: scala.Function2[_ParHashSet__T, _.colon.bslash__S, _.colon.bslash__S]) -> _.colon.bslash__S: ...
    _$div$colon__S = typing.TypeVar('_$div$colon__S')  # <S>
    def $div$colon(self, z: _.div.colon__S, op: scala.Function2[_.div.colon__S, _ParHashSet__T, _.div.colon__S]) -> _.div.colon__S: ...
    def $minus(self, elem: typing.Any) -> ParSet: ...
    @typing.overload
    def $minus$eq(self, elem1: _ParHashSet__T, elem2: _ParHashSet__T, elems: scala.collection.Seq[_ParHashSet__T]) -> scala.collection.generic.Shrinkable[_ParHashSet__T]: ...
    @typing.overload
    def $minus$eq(self, elem: _ParHashSet__T) -> 'ParHashSet'[_ParHashSet__T]: ...
    def $minus$minus$eq(self, xs: scala.collection.TraversableOnce[_ParHashSet__T]) -> scala.collection.generic.Shrinkable[_ParHashSet__T]: ...
    def $plus(self, elem: typing.Any) -> ParSet: ...
    @typing.overload
    def $plus$eq(self, elem1: _ParHashSet__T, elem2: _ParHashSet__T, elems: scala.collection.Seq[_ParHashSet__T]) -> scala.collection.generic.Growable[_ParHashSet__T]: ...
    @typing.overload
    def $plus$eq(self, elem: _ParHashSet__T) -> 'ParHashSet'[_ParHashSet__T]: ...
    _$plus$plus__U = typing.TypeVar('_$plus$plus__U')  # <U>
    _$plus$plus__That = typing.TypeVar('_$plus$plus__That')  # <That>
    def $plus$plus(self, that: scala.collection.GenTraversableOnce[_.plus.plus__U], bf: scala.collection.generic.CanBuildFrom['ParHashSet'[_ParHashSet__T], _.plus.plus__U, _.plus.plus__That]) -> _.plus.plus__That: ...
    def $plus$plus$eq(self, xs: scala.collection.TraversableOnce[_ParHashSet__T]) -> scala.collection.generic.Growable[_ParHashSet__T]: ...
    def ScanLeaf(self) -> scala.collection.parallel.ParIterableLike.ScanLeaf.: ...
    def ScanNode(self) -> scala.collection.parallel.ParIterableLike.ScanNode.: ...
    def _loadFactor(self) -> int: ...
    def _loadFactor_$eq(self, x$1: int) -> None: ...
    def addElem(self, elem: _ParHashSet__T) -> bool: ...
    def addEntry(self, newEntry: typing.Any) -> bool: ...
    _aggregate__S = typing.TypeVar('_aggregate__S')  # <S>
    def aggregate(self, z: scala.Function0[_aggregate__S], seqop: scala.Function2[_aggregate__S, _ParHashSet__T, _aggregate__S], combop: scala.Function2[_aggregate__S, _aggregate__S, _aggregate__S]) -> _aggregate__S: ...
    def alwaysInitSizeMap(self) -> bool: ...
    _andThen__A = typing.TypeVar('_andThen__A')  # <A>
    def andThen(self, g: scala.Function1[typing.Any, _andThen__A]) -> scala.Function1[_ParHashSet__T, _andThen__A]: ...
    def apply(self, elem: _ParHashSet__T) -> bool: ...
    def apply$mcDD$sp(self, v1: float) -> float: ...
    def apply$mcDF$sp(self, v1: float) -> float: ...
    def apply$mcDI$sp(self, v1: int) -> float: ...
    def apply$mcDJ$sp(self, v1: int) -> float: ...
    def apply$mcFD$sp(self, v1: float) -> float: ...
    def apply$mcFF$sp(self, v1: float) -> float: ...
    def apply$mcFI$sp(self, v1: int) -> float: ...
    def apply$mcFJ$sp(self, v1: int) -> float: ...
    def apply$mcID$sp(self, v1: float) -> int: ...
    def apply$mcIF$sp(self, v1: float) -> int: ...
    def apply$mcII$sp(self, v1: int) -> int: ...
    def apply$mcIJ$sp(self, v1: int) -> int: ...
    def apply$mcJD$sp(self, v1: float) -> int: ...
    def apply$mcJF$sp(self, v1: float) -> int: ...
    def apply$mcJI$sp(self, v1: int) -> int: ...
    def apply$mcJJ$sp(self, v1: int) -> int: ...
    def apply$mcVD$sp(self, v1: float) -> None: ...
    def apply$mcVF$sp(self, v1: float) -> None: ...
    def apply$mcVI$sp(self, v1: int) -> None: ...
    def apply$mcVJ$sp(self, v1: int) -> None: ...
    def apply$mcZD$sp(self, v1: float) -> bool: ...
    def apply$mcZF$sp(self, v1: float) -> bool: ...
    def apply$mcZI$sp(self, v1: int) -> bool: ...
    def apply$mcZJ$sp(self, v1: int) -> bool: ...
    _bf2seq__S = typing.TypeVar('_bf2seq__S')  # <S>
    _bf2seq__That = typing.TypeVar('_bf2seq__That')  # <That>
    def bf2seq(self, bf: scala.collection.generic.CanBuildFrom['ParHashSet'[_ParHashSet__T], _bf2seq__S, _bf2seq__That]) -> scala.collection.generic.CanBuildFrom[scala.collection.mutable.HashSet[_ParHashSet__T], _bf2seq__S, _bf2seq__That]: ...
    def brokenInvariants(self) -> scala.collection.Seq[str]: ...
    _builder2ops__Elem = typing.TypeVar('_builder2ops__Elem')  # <Elem>
    _builder2ops__To = typing.TypeVar('_builder2ops__To')  # <To>
    def builder2ops(self, cb: scala.collection.mutable.Builder[_builder2ops__Elem, _builder2ops__To]) -> scala.collection.parallel.ParIterableLike.BuilderOps[_builder2ops__Elem, _builder2ops__To]: ...
    def calcSizeMapSize(self, tableLength: int) -> int: ...
    _canBuildFrom__T = typing.TypeVar('_canBuildFrom__T')  # <T>
    @staticmethod
    def canBuildFrom() -> scala.collection.generic.CanCombineFrom['ParHashSet'[typing.Any], _canBuildFrom__T, 'ParHashSet'[_canBuildFrom__T]]: ...
    def canEqual(self, other: typing.Any) -> bool: ...
    def capacity(self, expectedSize: int) -> int: ...
    def clear(self) -> None: ...
    def clearTable(self) -> None: ...
    def clone(self) -> typing.Any: ...
    _collect__S = typing.TypeVar('_collect__S')  # <S>
    _collect__That = typing.TypeVar('_collect__That')  # <That>
    def collect(self, pf: scala.PartialFunction[_ParHashSet__T, _collect__S], bf: scala.collection.generic.CanBuildFrom['ParHashSet'[_ParHashSet__T], _collect__S, _collect__That]) -> _collect__That: ...
    _combinerFactory_1__S = typing.TypeVar('_combinerFactory_1__S')  # <S>
    _combinerFactory_1__That = typing.TypeVar('_combinerFactory_1__That')  # <That>
    @typing.overload
    def combinerFactory(self) -> scala.collection.parallel.CombinerFactory[_ParHashSet__T, 'ParHashSet'[_ParHashSet__T]]: ...
    @typing.overload
    def combinerFactory(self, cbf: scala.Function0[scala.collection.parallel.Combiner[_combinerFactory_1__S, _combinerFactory_1__That]]) -> scala.collection.parallel.CombinerFactory[_combinerFactory_1__S, _combinerFactory_1__That]: ...
    def companion(self) -> 'ParHashSet.': ...
    _compose__A = typing.TypeVar('_compose__A')  # <A>
    def compose(self, g: scala.Function1[_compose__A, _ParHashSet__T]) -> scala.Function1[_compose__A, typing.Any]: ...
    def contains(self, elem: _ParHashSet__T) -> bool: ...
    def containsElem(self, elem: _ParHashSet__T) -> bool: ...
    _copyToArray_0__U = typing.TypeVar('_copyToArray_0__U')  # <U>
    _copyToArray_1__U = typing.TypeVar('_copyToArray_1__U')  # <U>
    _copyToArray_2__U = typing.TypeVar('_copyToArray_2__U')  # <U>
    @typing.overload
    def copyToArray(self, xs: typing.Any) -> None: ...
    @typing.overload
    def copyToArray(self, xs: typing.Any, start: int) -> None: ...
    @typing.overload
    def copyToArray(self, xs: typing.Any, start: int, len: int) -> None: ...
    def count(self, p: scala.Function1[_ParHashSet__T, typing.Any]) -> int: ...
    def debugBuffer(self) -> scala.collection.mutable.ArrayBuffer[str]: ...
    def debugInformation(self) -> str: ...
    def debugclear(self) -> None: ...
    def debuglog(self, s: str) -> scala.collection.mutable.ArrayBuffer[str]: ...
    _delegatedSignalling2ops__PI = typing.TypeVar('_delegatedSignalling2ops__PI', bound=scala.collection.generic.DelegatedSignalling)  # <PI>
    def delegatedSignalling2ops(self, it: _delegatedSignalling2ops__PI) -> scala.collection.parallel.ParIterableLike.SignallingOps[_delegatedSignalling2ops__PI]: ...
    def diff(self, that: scala.collection.GenSet) -> scala.collection.parallel.ParSet: ...
    def drop(self, n: int) -> scala.collection.parallel.ParIterable: ...
    def dropWhile(self, pred: scala.Function1) -> scala.collection.parallel.ParIterable: ...
    def elemToEntry(self, elem: _ParHashSet__T) -> typing.Any: ...
    def empty(self) -> 'ParHashSet'[_ParHashSet__T]: ...
    def entryToElem(self, entry: typing.Any) -> _ParHashSet__T: ...
    def equals(self, that: typing.Any) -> bool: ...
    def exists(self, p: scala.Function1[_ParHashSet__T, typing.Any]) -> bool: ...
    def filter(self, pred: scala.Function1) -> scala.collection.parallel.ParIterable: ...
    def filterNot(self, pred: scala.Function1) -> scala.collection.parallel.ParIterable: ...
    def find(self, p: scala.Function1[_ParHashSet__T, typing.Any]) -> scala.Option[_ParHashSet__T]: ...
    def findEntry(self, elem: _ParHashSet__T) -> scala.Option[_ParHashSet__T]: ...
    _flatMap__S = typing.TypeVar('_flatMap__S')  # <S>
    _flatMap__That = typing.TypeVar('_flatMap__That')  # <That>
    def flatMap(self, f: scala.Function1[_ParHashSet__T, scala.collection.GenTraversableOnce[_flatMap__S]], bf: scala.collection.generic.CanBuildFrom['ParHashSet'[_ParHashSet__T], _flatMap__S, _flatMap__That]) -> _flatMap__That: ...
    def flatten(self, asTraversable: scala.Function1) -> scala.collection.GenTraversable: ...
    _fold__U = typing.TypeVar('_fold__U')  # <U>
    def fold(self, z: _fold__U, op: scala.Function2[_fold__U, _fold__U, _fold__U]) -> _fold__U: ...
    _foldLeft__S = typing.TypeVar('_foldLeft__S')  # <S>
    def foldLeft(self, z: _foldLeft__S, op: scala.Function2[_foldLeft__S, _ParHashSet__T, _foldLeft__S]) -> _foldLeft__S: ...
    _foldRight__S = typing.TypeVar('_foldRight__S')  # <S>
    def foldRight(self, z: _foldRight__S, op: scala.Function2[_ParHashSet__T, _foldRight__S, _foldRight__S]) -> _foldRight__S: ...
    def forall(self, p: scala.Function1[_ParHashSet__T, typing.Any]) -> bool: ...
    _foreach__U = typing.TypeVar('_foreach__U')  # <U>
    def foreach(self, f: scala.Function1[_ParHashSet__T, _foreach__U]) -> None: ...
    _genericBuilder__B = typing.TypeVar('_genericBuilder__B')  # <B>
    def genericBuilder(self) -> scala.collection.parallel.Combiner[_genericBuilder__B, 'ParHashSet'[_genericBuilder__B]]: ...
    _genericCombiner__B = typing.TypeVar('_genericCombiner__B')  # <B>
    def genericCombiner(self) -> scala.collection.parallel.Combiner[_genericCombiner__B, 'ParHashSet'[_genericCombiner__B]]: ...
    _groupBy__K = typing.TypeVar('_groupBy__K')  # <K>
    def groupBy(self, f: scala.Function1[_ParHashSet__T, _groupBy__K]) -> scala.collection.parallel.immutable.ParMap[_groupBy__K, 'ParHashSet'[_ParHashSet__T]]: ...
    def hasDefiniteSize(self) -> bool: ...
    def hashCode(self) -> int: ...
    def hashTableContents(self) -> scala.collection.mutable.FlatHashTable.Contents[_ParHashSet__T]: ...
    def head(self) -> _ParHashSet__T: ...
    def headOption(self) -> scala.Option[_ParHashSet__T]: ...
    def improve(self, hcode: int, seed: int) -> int: ...
    def index(self, hcode: int) -> int: ...
    @typing.overload
    def init(self) -> scala.collection.parallel.ParIterable: ...
    @typing.overload
    def init(self, in_: java.io.ObjectInputStream, f: scala.Function1[_ParHashSet__T, scala.runtime.BoxedUnit]) -> None: ...
    def initTaskSupport(self) -> None: ...
    def initWithContents(self, c: scala.collection.mutable.FlatHashTable.Contents[_ParHashSet__T]) -> None: ...
    def initialSize(self) -> int: ...
    def intersect(self, that: scala.collection.GenSet) -> typing.Any: ...
    def isEmpty(self) -> bool: ...
    def isSizeMapDefined(self) -> bool: ...
    def isStrictSplitterCollection(self) -> bool: ...
    def isTraversableAgain(self) -> bool: ...
    def iterator(self) -> 'ParHashSet.ParHashSetIterator': ...
    def last(self) -> _ParHashSet__T: ...
    def lastOption(self) -> scala.Option[_ParHashSet__T]: ...
    _map__S = typing.TypeVar('_map__S')  # <S>
    _map__That = typing.TypeVar('_map__That')  # <That>
    def map(self, f: scala.Function1[_ParHashSet__T, _map__S], bf: scala.collection.generic.CanBuildFrom['ParHashSet'[_ParHashSet__T], _map__S, _map__That]) -> _map__That: ...
    _max__U = typing.TypeVar('_max__U')  # <U>
    def max(self, ord: scala.math.Ordering[_max__U]) -> _ParHashSet__T: ...
    _maxBy__S = typing.TypeVar('_maxBy__S')  # <S>
    def maxBy(self, f: scala.Function1[_ParHashSet__T, _maxBy__S], cmp: scala.math.Ordering[_maxBy__S]) -> _ParHashSet__T: ...
    _min__U = typing.TypeVar('_min__U')  # <U>
    def min(self, ord: scala.math.Ordering[_min__U]) -> _ParHashSet__T: ...
    _minBy__S = typing.TypeVar('_minBy__S')  # <S>
    def minBy(self, f: scala.Function1[_ParHashSet__T, _minBy__S], cmp: scala.math.Ordering[_minBy__S]) -> _ParHashSet__T: ...
    @typing.overload
    def mkString(self) -> str: ...
    @typing.overload
    def mkString(self, sep: str) -> str: ...
    @typing.overload
    def mkString(self, start: str, sep: str, end: str) -> str: ...
    def newBuilder(self) -> scala.collection.mutable.Builder[_ParHashSet__T, 'ParHashSet'[_ParHashSet__T]]: ...
    def newCombiner(self) -> scala.collection.parallel.Combiner[_ParHashSet__T, 'ParHashSet'[_ParHashSet__T]]: ...
    def nnSizeMapAdd(self, h: int) -> None: ...
    def nnSizeMapRemove(self, h: int) -> None: ...
    def nnSizeMapReset(self, tableLength: int) -> None: ...
    def nonEmpty(self) -> bool: ...
    def par(self) -> scala.collection.parallel.ParIterable: ...
    def parCombiner(self) -> scala.collection.parallel.Combiner[_ParHashSet__T, 'ParHashSet'[_ParHashSet__T]]: ...
    def partition(self, pred: scala.Function1[_ParHashSet__T, typing.Any]) -> scala.Tuple2['ParHashSet'[_ParHashSet__T], 'ParHashSet'[_ParHashSet__T]]: ...
    def printContents(self) -> None: ...
    def printDebugBuffer(self) -> None: ...
    def printSizeMap(self) -> None: ...
    _product__U = typing.TypeVar('_product__U')  # <U>
    def product(self, num: scala.math.Numeric[_product__U]) -> _product__U: ...
    def randomSeed(self) -> int: ...
    _reduce__U = typing.TypeVar('_reduce__U')  # <U>
    def reduce(self, op: scala.Function2[_reduce__U, _reduce__U, _reduce__U]) -> _reduce__U: ...
    _reduceLeft__U = typing.TypeVar('_reduceLeft__U')  # <U>
    def reduceLeft(self, op: scala.Function2[_reduceLeft__U, _ParHashSet__T, _reduceLeft__U]) -> _reduceLeft__U: ...
    _reduceLeftOption__U = typing.TypeVar('_reduceLeftOption__U')  # <U>
    def reduceLeftOption(self, op: scala.Function2[_reduceLeftOption__U, _ParHashSet__T, _reduceLeftOption__U]) -> scala.Option[_reduceLeftOption__U]: ...
    _reduceOption__U = typing.TypeVar('_reduceOption__U')  # <U>
    def reduceOption(self, op: scala.Function2[_reduceOption__U, _reduceOption__U, _reduceOption__U]) -> scala.Option[_reduceOption__U]: ...
    _reduceRight__U = typing.TypeVar('_reduceRight__U')  # <U>
    def reduceRight(self, op: scala.Function2[_ParHashSet__T, _reduceRight__U, _reduceRight__U]) -> _reduceRight__U: ...
    _reduceRightOption__U = typing.TypeVar('_reduceRightOption__U')  # <U>
    def reduceRightOption(self, op: scala.Function2[_ParHashSet__T, _reduceRightOption__U, _reduceRightOption__U]) -> scala.Option[_reduceRightOption__U]: ...
    def removeElem(self, elem: _ParHashSet__T) -> bool: ...
    def repr(self) -> scala.collection.parallel.ParIterable: ...
    _reuse__S = typing.TypeVar('_reuse__S')  # <S>
    _reuse__That = typing.TypeVar('_reuse__That')  # <That>
    def reuse(self, oldc: scala.Option[scala.collection.parallel.Combiner[_reuse__S, _reuse__That]], newc: scala.collection.parallel.Combiner[_reuse__S, _reuse__That]) -> scala.collection.parallel.Combiner[_reuse__S, _reuse__That]: ...
    _sameElements__U = typing.TypeVar('_sameElements__U')  # <U>
    def sameElements(self, that: scala.collection.GenIterable[_sameElements__U]) -> bool: ...
    def scala$collection$parallel$ParIterableLike$$_tasksupport(self) -> scala.collection.parallel.TaskSupport: ...
    def scala$collection$parallel$ParIterableLike$$_tasksupport_$eq(self, x$1: scala.collection.parallel.TaskSupport) -> None: ...
    _scan__U = typing.TypeVar('_scan__U')  # <U>
    _scan__That = typing.TypeVar('_scan__That')  # <That>
    def scan(self, z: _scan__U, op: scala.Function2[_scan__U, _scan__U, _scan__U], bf: scala.collection.generic.CanBuildFrom['ParHashSet'[_ParHashSet__T], _scan__U, _scan__That]) -> _scan__That: ...
    def scanBlockSize(self) -> int: ...
    _scanLeft__S = typing.TypeVar('_scanLeft__S')  # <S>
    _scanLeft__That = typing.TypeVar('_scanLeft__That')  # <That>
    def scanLeft(self, z: _scanLeft__S, op: scala.Function2[_scanLeft__S, _ParHashSet__T, _scanLeft__S], bf: scala.collection.generic.CanBuildFrom['ParHashSet'[_ParHashSet__T], _scanLeft__S, _scanLeft__That]) -> _scanLeft__That: ...
    _scanRight__S = typing.TypeVar('_scanRight__S')  # <S>
    _scanRight__That = typing.TypeVar('_scanRight__That')  # <That>
    def scanRight(self, z: _scanRight__S, op: scala.Function2[_ParHashSet__T, _scanRight__S, _scanRight__S], bf: scala.collection.generic.CanBuildFrom['ParHashSet'[_ParHashSet__T], _scanRight__S, _scanRight__That]) -> _scanRight__That: ...
    def seedvalue(self) -> int: ...
    def seedvalue_$eq(self, x$1: int) -> None: ...
    def seq(self) -> scala.collection.mutable.HashSet[_ParHashSet__T]: ...
    def sequentially(self, b: scala.Function1) -> scala.collection.parallel.ParIterable: ...
    def serializeTo(self, out: java.io.ObjectOutputStream) -> None: ...
    _setCanBuildFrom__A = typing.TypeVar('_setCanBuildFrom__A')  # <A>
    @staticmethod
    def setCanBuildFrom() -> scala.collection.generic.CanBuildFrom['ParHashSet'[typing.Any], _setCanBuildFrom__A, 'ParHashSet'[_setCanBuildFrom__A]]: ...
    def size(self) -> int: ...
    def sizeHintIfCheap(self) -> int: ...
    def sizeMapBucketBitSize(self) -> int: ...
    def sizeMapBucketSize(self) -> int: ...
    def sizeMapDisable(self) -> None: ...
    def sizeMapInit(self, tableLength: int) -> None: ...
    def sizeMapInitAndRebuild(self) -> None: ...
    def sizemap(self) -> typing.List[int]: ...
    def sizemap_$eq(self, x$1: typing.List[int]) -> None: ...
    def slice(self, unc_from: int, unc_until: int) -> scala.collection.parallel.ParIterable: ...
    def span(self, pred: scala.Function1[_ParHashSet__T, typing.Any]) -> scala.Tuple2['ParHashSet'[_ParHashSet__T], 'ParHashSet'[_ParHashSet__T]]: ...
    def splitAt(self, n: int) -> scala.Tuple2['ParHashSet'[_ParHashSet__T], 'ParHashSet'[_ParHashSet__T]]: ...
    def splitter(self) -> 'ParHashSet.ParHashSetIterator': ...
    def stringPrefix(self) -> str: ...
    def subsetOf(self, that: scala.collection.GenSet[_ParHashSet__T]) -> bool: ...
    _sum__U = typing.TypeVar('_sum__U')  # <U>
    def sum(self, num: scala.math.Numeric[_sum__U]) -> _sum__U: ...
    def table(self) -> typing.List[typing.Any]: ...
    def tableSize(self) -> int: ...
    def tableSizeSeed(self) -> int: ...
    def tableSize_$eq(self, x$1: int) -> None: ...
    def table_$eq(self, x$1: typing.List[typing.Any]) -> None: ...
    def tail(self) -> scala.collection.parallel.ParIterable: ...
    def take(self, n: int) -> scala.collection.parallel.ParIterable: ...
    def takeWhile(self, pred: scala.Function1) -> scala.collection.parallel.ParIterable: ...
    _task2ops__R = typing.TypeVar('_task2ops__R')  # <R>
    _task2ops__Tp = typing.TypeVar('_task2ops__Tp')  # <Tp>
    def task2ops(self, tsk: scala.collection.parallel.ParIterableLike.StrictSplitterCheckTask[_task2ops__R, _task2ops__Tp]) -> scala.collection.parallel.ParIterableLike.TaskOps[_task2ops__R, _task2ops__Tp]: ...
    def tasksupport(self) -> scala.collection.parallel.TaskSupport: ...
    def tasksupport_$eq(self, ts: scala.collection.parallel.TaskSupport) -> None: ...
    def threshold(self) -> int: ...
    def threshold_$eq(self, x$1: int) -> None: ...
    _to__Col = typing.TypeVar('_to__Col')  # <Col>
    def to(self, cbf: scala.collection.generic.CanBuildFrom[scala.runtime.Nothing., _ParHashSet__T, _to__Col]) -> _to__Col: ...
    _toArray__U = typing.TypeVar('_toArray__U')  # <U>
    def toArray(self, evidence$1: scala.reflect.ClassTag[_toArray__U]) -> typing.Any: ...
    _toBuffer__U = typing.TypeVar('_toBuffer__U')  # <U>
    def toBuffer(self) -> scala.collection.mutable.Buffer[_toBuffer__U]: ...
    def toIndexedSeq(self) -> scala.collection.immutable.IndexedSeq[_ParHashSet__T]: ...
    def toIterable(self) -> ParIterable[_ParHashSet__T]: ...
    def toIterator(self) -> scala.collection.Iterator[_ParHashSet__T]: ...
    def toList(self) -> scala.collection.immutable.List[_ParHashSet__T]: ...
    _toMap__K = typing.TypeVar('_toMap__K')  # <K>
    _toMap__V = typing.TypeVar('_toMap__V')  # <V>
    def toMap(self, ev: scala.Predef..less.colon.less[_ParHashSet__T, scala.Tuple2[_toMap__K, _toMap__V]]) -> scala.collection.parallel.immutable.ParMap[_toMap__K, _toMap__V]: ...
    _toParCollection__U = typing.TypeVar('_toParCollection__U')  # <U>
    _toParCollection__That = typing.TypeVar('_toParCollection__That')  # <That>
    def toParCollection(self, cbf: scala.Function0[scala.collection.parallel.Combiner[_toParCollection__U, _toParCollection__That]]) -> _toParCollection__That: ...
    _toParMap__K = typing.TypeVar('_toParMap__K')  # <K>
    _toParMap__V = typing.TypeVar('_toParMap__V')  # <V>
    _toParMap__That = typing.TypeVar('_toParMap__That')  # <That>
    def toParMap(self, cbf: scala.Function0[scala.collection.parallel.Combiner[scala.Tuple2[_toParMap__K, _toParMap__V], _toParMap__That]], ev: scala.Predef..less.colon.less[_ParHashSet__T, scala.Tuple2[_toParMap__K, _toParMap__V]]) -> _toParMap__That: ...
    def toSeq(self) -> ParSeq[_ParHashSet__T]: ...
    _toSet__U = typing.TypeVar('_toSet__U')  # <U>
    def toSet(self) -> scala.collection.parallel.immutable.ParSet[_toSet__U]: ...
    def toStream(self) -> scala.collection.immutable.Stream[_ParHashSet__T]: ...
    def toString(self) -> str: ...
    def toTraversable(self) -> scala.collection.GenTraversable[_ParHashSet__T]: ...
    def toVector(self) -> scala.collection.immutable.Vector[_ParHashSet__T]: ...
    def totalSizeMapBuckets(self) -> int: ...
    def transpose(self, asTraversable: scala.Function1) -> scala.collection.GenTraversable: ...
    def union(self, that: scala.collection.GenSet) -> scala.collection.parallel.ParSet: ...
    _unzip__A1 = typing.TypeVar('_unzip__A1')  # <A1>
    _unzip__A2 = typing.TypeVar('_unzip__A2')  # <A2>
    def unzip(self, asPair: scala.Function1[_ParHashSet__T, scala.Tuple2[_unzip__A1, _unzip__A2]]) -> scala.Tuple2['ParHashSet'[_unzip__A1], 'ParHashSet'[_unzip__A2]]: ...
    _unzip3__A1 = typing.TypeVar('_unzip3__A1')  # <A1>
    _unzip3__A2 = typing.TypeVar('_unzip3__A2')  # <A2>
    _unzip3__A3 = typing.TypeVar('_unzip3__A3')  # <A3>
    def unzip3(self, asTriple: scala.Function1[_ParHashSet__T, scala.Tuple3[_unzip3__A1, _unzip3__A2, _unzip3__A3]]) -> scala.Tuple3['ParHashSet'[_unzip3__A1], 'ParHashSet'[_unzip3__A2], 'ParHashSet'[_unzip3__A3]]: ...
    def view(self) -> scala.collection.IterableView[_ParHashSet__T, scala.collection.mutable.HashSet[_ParHashSet__T]]: ...
    def withFilter(self, pred: scala.Function1) -> scala.collection.parallel.ParIterable: ...
    _wrap__R = typing.TypeVar('_wrap__R')  # <R>
    def wrap(self, body: scala.Function0[_wrap__R]) -> scala.collection.parallel.ParIterableLike.NonDivisible[_wrap__R]: ...
    _zip__U = typing.TypeVar('_zip__U')  # <U>
    _zip__S = typing.TypeVar('_zip__S')  # <S>
    _zip__That = typing.TypeVar('_zip__That')  # <That>
    def zip(self, that: scala.collection.GenIterable[_zip__S], bf: scala.collection.generic.CanBuildFrom['ParHashSet'[_ParHashSet__T], scala.Tuple2[_zip__U, _zip__S], _zip__That]) -> _zip__That: ...
    _zipAll__S = typing.TypeVar('_zipAll__S')  # <S>
    _zipAll__U = typing.TypeVar('_zipAll__U')  # <U>
    _zipAll__That = typing.TypeVar('_zipAll__That')  # <That>
    def zipAll(self, that: scala.collection.GenIterable[_zipAll__S], thisElem: _zipAll__U, thatElem: _zipAll__S, bf: scala.collection.generic.CanBuildFrom['ParHashSet'[_ParHashSet__T], scala.Tuple2[_zipAll__U, _zipAll__S], _zipAll__That]) -> _zipAll__That: ...
    _zipWithIndex__U = typing.TypeVar('_zipWithIndex__U')  # <U>
    _zipWithIndex__That = typing.TypeVar('_zipWithIndex__That')  # <That>
    def zipWithIndex(self, bf: scala.collection.generic.CanBuildFrom['ParHashSet'[_ParHashSet__T], scala.Tuple2[_zipWithIndex__U, typing.Any], _zipWithIndex__That]) -> _zipWithIndex__That: ...
    class ParHashSetIterator(ParFlatHashTable.ParFlatHashTableIterator):
        def __init__(self, $outer: 'ParHashSet', start: int, iteratesUntil: int, totalElements: int): ...
        def newIterator(self, start: int, until: int, total: int) -> 'ParHashSet.ParHashSetIterator': ...
    class : ...

_ParHashMap__K = typing.TypeVar('_ParHashMap__K')  # <K>
_ParHashMap__V = typing.TypeVar('_ParHashMap__V')  # <V>
class ParHashMap(scala.collection.parallel.mutable.ParMap[_ParHashMap__K, _ParHashMap__V], ParHashTable[_ParHashMap__K, scala.collection.mutable.DefaultEntry[_ParHashMap__K, _ParHashMap__V]], scala.Serializable, typing.Generic[_ParHashMap__K, _ParHashMap__V]):
    serialVersionUID: typing.ClassVar[int] = ...
    @typing.overload
    def __init__(self): ...
    @typing.overload
    def __init__(self, contents: scala.collection.mutable.HashTable.Contents[_ParHashMap__K, scala.collection.mutable.DefaultEntry[_ParHashMap__K, _ParHashMap__V]]): ...
    _$colon$bslash__S = typing.TypeVar('_$colon$bslash__S')  # <S>
    def $colon$bslash(self, z: _.colon.bslash__S, op: scala.Function2[scala.Tuple2[_ParHashMap__K, _ParHashMap__V], _.colon.bslash__S, _.colon.bslash__S]) -> _.colon.bslash__S: ...
    _$div$colon__S = typing.TypeVar('_$div$colon__S')  # <S>
    def $div$colon(self, z: _.div.colon__S, op: scala.Function2[_.div.colon__S, scala.Tuple2[_ParHashMap__K, _ParHashMap__V], _.div.colon__S]) -> _.div.colon__S: ...
    def $minus(self, key: typing.Any) -> 'ParMap': ...
    @typing.overload
    def $minus$eq(self, elem1: _ParHashMap__K, elem2: _ParHashMap__K, elems: scala.collection.Seq[_ParHashMap__K]) -> scala.collection.generic.Shrinkable[_ParHashMap__K]: ...
    @typing.overload
    def $minus$eq(self, key: _ParHashMap__K) -> 'ParHashMap'[_ParHashMap__K, _ParHashMap__V]: ...
    def $minus$minus$eq(self, xs: scala.collection.TraversableOnce[_ParHashMap__K]) -> scala.collection.generic.Shrinkable[_ParHashMap__K]: ...
    _$plus__U = typing.TypeVar('_$plus__U')  # <U>
    def $plus(self, kv: scala.Tuple2[_ParHashMap__K, _.plus__U]) -> 'ParMap'[_ParHashMap__K, _.plus__U]: ...
    @typing.overload
    def $plus$eq(self, elem1: typing.Any, elem2: typing.Any, elems: scala.collection.Seq) -> scala.collection.generic.Growable: ...
    @typing.overload
    def $plus$eq(self, kv: scala.Tuple2[_ParHashMap__K, _ParHashMap__V]) -> 'ParHashMap'[_ParHashMap__K, _ParHashMap__V]: ...
    _$plus$plus__U = typing.TypeVar('_$plus$plus__U')  # <U>
    _$plus$plus__That = typing.TypeVar('_$plus$plus__That')  # <That>
    def $plus$plus(self, that: scala.collection.GenTraversableOnce[_.plus.plus__U], bf: scala.collection.generic.CanBuildFrom['ParHashMap'[_ParHashMap__K, _ParHashMap__V], _.plus.plus__U, _.plus.plus__That]) -> _.plus.plus__That: ...
    def $plus$plus$eq(self, xs: scala.collection.TraversableOnce[scala.Tuple2[_ParHashMap__K, _ParHashMap__V]]) -> scala.collection.generic.Growable[scala.Tuple2[_ParHashMap__K, _ParHashMap__V]]: ...
    def ScanLeaf(self) -> scala.collection.parallel.ParIterableLike.ScanLeaf.: ...
    def ScanNode(self) -> scala.collection.parallel.ParIterableLike.ScanNode.: ...
    def _loadFactor(self) -> int: ...
    def _loadFactor_$eq(self, x$1: int) -> None: ...
    def addEntry(self, e: scala.collection.mutable.HashEntry) -> None: ...
    _aggregate__S = typing.TypeVar('_aggregate__S')  # <S>
    def aggregate(self, z: scala.Function0[_aggregate__S], seqop: scala.Function2[_aggregate__S, scala.Tuple2[_ParHashMap__K, _ParHashMap__V], _aggregate__S], combop: scala.Function2[_aggregate__S, _aggregate__S, _aggregate__S]) -> _aggregate__S: ...
    def alwaysInitSizeMap(self) -> bool: ...
    def apply(self, key: _ParHashMap__K) -> _ParHashMap__V: ...
    _bf2seq__S = typing.TypeVar('_bf2seq__S')  # <S>
    _bf2seq__That = typing.TypeVar('_bf2seq__That')  # <That>
    def bf2seq(self, bf: scala.collection.generic.CanBuildFrom['ParHashMap'[_ParHashMap__K, _ParHashMap__V], _bf2seq__S, _bf2seq__That]) -> scala.collection.generic.CanBuildFrom[scala.collection.mutable.HashMap[_ParHashMap__K, _ParHashMap__V], _bf2seq__S, _bf2seq__That]: ...
    def brokenInvariants(self) -> scala.collection.Seq[str]: ...
    _builder2ops__Elem = typing.TypeVar('_builder2ops__Elem')  # <Elem>
    _builder2ops__To = typing.TypeVar('_builder2ops__To')  # <To>
    def builder2ops(self, cb: scala.collection.mutable.Builder[_builder2ops__Elem, _builder2ops__To]) -> scala.collection.parallel.ParIterableLike.BuilderOps[_builder2ops__Elem, _builder2ops__To]: ...
    def calcSizeMapSize(self, tableLength: int) -> int: ...
    _canBuildFrom__K = typing.TypeVar('_canBuildFrom__K')  # <K>
    _canBuildFrom__V = typing.TypeVar('_canBuildFrom__V')  # <V>
    @staticmethod
    def canBuildFrom() -> scala.collection.generic.CanCombineFrom['ParHashMap'[typing.Any, typing.Any], scala.Tuple2[_canBuildFrom__K, _canBuildFrom__V], 'ParHashMap'[_canBuildFrom__K, _canBuildFrom__V]]: ...
    def canEqual(self, other: typing.Any) -> bool: ...
    def clear(self) -> None: ...
    def clearTable(self) -> None: ...
    def clone(self) -> typing.Any: ...
    _collect__S = typing.TypeVar('_collect__S')  # <S>
    _collect__That = typing.TypeVar('_collect__That')  # <That>
    def collect(self, pf: scala.PartialFunction[scala.Tuple2[_ParHashMap__K, _ParHashMap__V], _collect__S], bf: scala.collection.generic.CanBuildFrom['ParHashMap'[_ParHashMap__K, _ParHashMap__V], _collect__S, _collect__That]) -> _collect__That: ...
    _combinerFactory_1__S = typing.TypeVar('_combinerFactory_1__S')  # <S>
    _combinerFactory_1__That = typing.TypeVar('_combinerFactory_1__That')  # <That>
    @typing.overload
    def combinerFactory(self) -> scala.collection.parallel.CombinerFactory[scala.Tuple2[_ParHashMap__K, _ParHashMap__V], 'ParHashMap'[_ParHashMap__K, _ParHashMap__V]]: ...
    @typing.overload
    def combinerFactory(self, cbf: scala.Function0[scala.collection.parallel.Combiner[_combinerFactory_1__S, _combinerFactory_1__That]]) -> scala.collection.parallel.CombinerFactory[_combinerFactory_1__S, _combinerFactory_1__That]: ...
    def companion(self) -> scala.collection.generic.GenericCompanion[ParIterable]: ...
    def contains(self, key: _ParHashMap__K) -> bool: ...
    _copyToArray_0__U = typing.TypeVar('_copyToArray_0__U')  # <U>
    _copyToArray_1__U = typing.TypeVar('_copyToArray_1__U')  # <U>
    _copyToArray_2__U = typing.TypeVar('_copyToArray_2__U')  # <U>
    @typing.overload
    def copyToArray(self, xs: typing.Any) -> None: ...
    @typing.overload
    def copyToArray(self, xs: typing.Any, start: int) -> None: ...
    @typing.overload
    def copyToArray(self, xs: typing.Any, start: int, len: int) -> None: ...
    def count(self, p: scala.Function1[scala.Tuple2[_ParHashMap__K, _ParHashMap__V], typing.Any]) -> int: ...
    _createNewEntry__V1 = typing.TypeVar('_createNewEntry__V1')  # <V1>
    def createNewEntry(self, key: _ParHashMap__K, value: _createNewEntry__V1) -> scala.collection.mutable.DefaultEntry[_ParHashMap__K, _ParHashMap__V]: ...
    def debugBuffer(self) -> scala.collection.mutable.ArrayBuffer[str]: ...
    def debugInformation(self) -> str: ...
    def debugclear(self) -> None: ...
    def debuglog(self, s: str) -> scala.collection.mutable.ArrayBuffer[str]: ...
    def default(self, key: _ParHashMap__K) -> _ParHashMap__V: ...
    _delegatedSignalling2ops__PI = typing.TypeVar('_delegatedSignalling2ops__PI', bound=scala.collection.generic.DelegatedSignalling)  # <PI>
    def delegatedSignalling2ops(self, it: _delegatedSignalling2ops__PI) -> scala.collection.parallel.ParIterableLike.SignallingOps[_delegatedSignalling2ops__PI]: ...
    def drop(self, n: int) -> scala.collection.parallel.ParIterable: ...
    def dropWhile(self, pred: scala.Function1) -> scala.collection.parallel.ParIterable: ...
    def elemEquals(self, key1: _ParHashMap__K, key2: _ParHashMap__K) -> bool: ...
    def elemHashCode(self, key: _ParHashMap__K) -> int: ...
    def empty(self) -> 'ParHashMap'[_ParHashMap__K, _ParHashMap__V]: ...
    def entriesIterator(self) -> scala.collection.Iterator[scala.collection.mutable.DefaultEntry[_ParHashMap__K, _ParHashMap__V]]: ...
    def equals(self, that: typing.Any) -> bool: ...
    def exists(self, p: scala.Function1[scala.Tuple2[_ParHashMap__K, _ParHashMap__V], typing.Any]) -> bool: ...
    def filter(self, pred: scala.Function1) -> scala.collection.parallel.ParIterable: ...
    def filterKeys(self, p: scala.Function1[_ParHashMap__K, typing.Any]) -> scala.collection.parallel.ParMap[_ParHashMap__K, _ParHashMap__V]: ...
    def filterNot(self, pred: scala.Function1) -> scala.collection.parallel.ParIterable: ...
    def find(self, p: scala.Function1[scala.Tuple2[_ParHashMap__K, _ParHashMap__V], typing.Any]) -> scala.Option[scala.Tuple2[_ParHashMap__K, _ParHashMap__V]]: ...
    def findEntry(self, key: typing.Any) -> scala.collection.mutable.HashEntry: ...
    def findOrAddEntry(self, key: typing.Any, value: typing.Any) -> scala.collection.mutable.HashEntry: ...
    _flatMap__S = typing.TypeVar('_flatMap__S')  # <S>
    _flatMap__That = typing.TypeVar('_flatMap__That')  # <That>
    def flatMap(self, f: scala.Function1[scala.Tuple2[_ParHashMap__K, _ParHashMap__V], scala.collection.GenTraversableOnce[_flatMap__S]], bf: scala.collection.generic.CanBuildFrom['ParHashMap'[_ParHashMap__K, _ParHashMap__V], _flatMap__S, _flatMap__That]) -> _flatMap__That: ...
    def flatten(self, asTraversable: scala.Function1) -> scala.collection.GenTraversable: ...
    _fold__U = typing.TypeVar('_fold__U')  # <U>
    def fold(self, z: _fold__U, op: scala.Function2[_fold__U, _fold__U, _fold__U]) -> _fold__U: ...
    _foldLeft__S = typing.TypeVar('_foldLeft__S')  # <S>
    def foldLeft(self, z: _foldLeft__S, op: scala.Function2[_foldLeft__S, scala.Tuple2[_ParHashMap__K, _ParHashMap__V], _foldLeft__S]) -> _foldLeft__S: ...
    _foldRight__S = typing.TypeVar('_foldRight__S')  # <S>
    def foldRight(self, z: _foldRight__S, op: scala.Function2[scala.Tuple2[_ParHashMap__K, _ParHashMap__V], _foldRight__S, _foldRight__S]) -> _foldRight__S: ...
    def forall(self, p: scala.Function1[scala.Tuple2[_ParHashMap__K, _ParHashMap__V], typing.Any]) -> bool: ...
    _foreach__U = typing.TypeVar('_foreach__U')  # <U>
    def foreach(self, f: scala.Function1[scala.Tuple2[_ParHashMap__K, _ParHashMap__V], _foreach__U]) -> None: ...
    _foreachEntry__U = typing.TypeVar('_foreachEntry__U')  # <U>
    def foreachEntry(self, f: scala.Function1[scala.collection.mutable.DefaultEntry[_ParHashMap__K, _ParHashMap__V], _foreachEntry__U]) -> None: ...
    _genericBuilder__B = typing.TypeVar('_genericBuilder__B')  # <B>
    def genericBuilder(self) -> scala.collection.parallel.Combiner[_genericBuilder__B, ParIterable[_genericBuilder__B]]: ...
    _genericCombiner__B = typing.TypeVar('_genericCombiner__B')  # <B>
    def genericCombiner(self) -> scala.collection.parallel.Combiner[_genericCombiner__B, ParIterable[_genericCombiner__B]]: ...
    _genericMapCombiner__P = typing.TypeVar('_genericMapCombiner__P')  # <P>
    _genericMapCombiner__Q = typing.TypeVar('_genericMapCombiner__Q')  # <Q>
    def genericMapCombiner(self) -> scala.collection.parallel.Combiner[scala.Tuple2[_genericMapCombiner__P, _genericMapCombiner__Q], 'ParHashMap'[_genericMapCombiner__P, _genericMapCombiner__Q]]: ...
    def get(self, key: _ParHashMap__K) -> scala.Option[_ParHashMap__V]: ...
    _getOrElse__U = typing.TypeVar('_getOrElse__U')  # <U>
    def getOrElse(self, key: _ParHashMap__K, default: scala.Function0[_getOrElse__U]) -> _getOrElse__U: ...
    _groupBy__K = typing.TypeVar('_groupBy__K')  # <K>
    def groupBy(self, f: scala.Function1[scala.Tuple2[typing.Any, _ParHashMap__V], typing.Any]) -> scala.collection.parallel.immutable.ParMap[typing.Any, 'ParHashMap'[typing.Any, _ParHashMap__V]]: ...
    def hasDefiniteSize(self) -> bool: ...
    def hashCode(self) -> int: ...
    def hashTableContents(self) -> scala.collection.mutable.HashTable.Contents[_ParHashMap__K, scala.collection.mutable.DefaultEntry[_ParHashMap__K, _ParHashMap__V]]: ...
    def head(self) -> typing.Any: ...
    def headOption(self) -> scala.Option[scala.Tuple2[_ParHashMap__K, _ParHashMap__V]]: ...
    def improve(self, hcode: int, seed: int) -> int: ...
    def index(self, hcode: int) -> int: ...
    @typing.overload
    def init(self) -> scala.collection.parallel.ParIterable: ...
    @typing.overload
    def init(self, in_: java.io.ObjectInputStream, readEntry: scala.Function0[scala.collection.mutable.DefaultEntry[_ParHashMap__K, _ParHashMap__V]]) -> None: ...
    def initTaskSupport(self) -> None: ...
    def initWithContents(self, c: scala.collection.mutable.HashTable.Contents[_ParHashMap__K, scala.collection.mutable.DefaultEntry[_ParHashMap__K, _ParHashMap__V]]) -> None: ...
    def initialSize(self) -> int: ...
    def isDefinedAt(self, key: _ParHashMap__K) -> bool: ...
    def isEmpty(self) -> bool: ...
    def isSizeMapDefined(self) -> bool: ...
    def isStrictSplitterCollection(self) -> bool: ...
    def isTraversableAgain(self) -> bool: ...
    def iterator(self) -> scala.collection.parallel.Splitter[scala.Tuple2[_ParHashMap__K, _ParHashMap__V]]: ...
    @staticmethod
    def iters() -> int: ...
    @staticmethod
    def iters_$eq(x$1: int) -> None: ...
    def keySet(self) -> scala.collection.parallel.ParSet[_ParHashMap__K]: ...
    def keys(self) -> scala.collection.parallel.ParIterable[_ParHashMap__K]: ...
    def keysIterator(self) -> scala.collection.parallel.IterableSplitter[_ParHashMap__K]: ...
    def last(self) -> typing.Any: ...
    def lastOption(self) -> scala.Option[scala.Tuple2[_ParHashMap__K, _ParHashMap__V]]: ...
    _map__S = typing.TypeVar('_map__S')  # <S>
    _map__That = typing.TypeVar('_map__That')  # <That>
    def map(self, f: scala.Function1[scala.Tuple2[_ParHashMap__K, _ParHashMap__V], _map__S], bf: scala.collection.generic.CanBuildFrom['ParHashMap'[_ParHashMap__K, _ParHashMap__V], _map__S, _map__That]) -> _map__That: ...
    def mapCompanion(self) -> scala.collection.generic.GenericParMapCompanion['ParHashMap']: ...
    _mapValues__S = typing.TypeVar('_mapValues__S')  # <S>
    def mapValues(self, f: scala.Function1[_ParHashMap__V, _mapValues__S]) -> scala.collection.parallel.ParMap[_ParHashMap__K, _mapValues__S]: ...
    def max(self, ord: scala.math.Ordering) -> typing.Any: ...
    def maxBy(self, f: scala.Function1, cmp: scala.math.Ordering) -> typing.Any: ...
    def min(self, ord: scala.math.Ordering) -> typing.Any: ...
    def minBy(self, f: scala.Function1, cmp: scala.math.Ordering) -> typing.Any: ...
    @typing.overload
    def mkString(self) -> str: ...
    @typing.overload
    def mkString(self, sep: str) -> str: ...
    @typing.overload
    def mkString(self, start: str, sep: str, end: str) -> str: ...
    def newBuilder(self) -> scala.collection.mutable.Builder[scala.Tuple2[_ParHashMap__K, _ParHashMap__V], ParIterable[scala.Tuple2[_ParHashMap__K, _ParHashMap__V]]]: ...
    def newCombiner(self) -> ParHashMapCombiner[_ParHashMap__K, _ParHashMap__V]: ...
    def nnSizeMapAdd(self, h: int) -> None: ...
    def nnSizeMapRemove(self, h: int) -> None: ...
    def nnSizeMapReset(self, tableLength: int) -> None: ...
    def nonEmpty(self) -> bool: ...
    def par(self) -> scala.collection.parallel.ParIterable: ...
    def parCombiner(self) -> scala.collection.parallel.Combiner[scala.Tuple2[_ParHashMap__K, _ParHashMap__V], 'ParHashMap'[_ParHashMap__K, _ParHashMap__V]]: ...
    def partition(self, pred: scala.Function1[scala.Tuple2[_ParHashMap__K, _ParHashMap__V], typing.Any]) -> scala.Tuple2['ParHashMap'[_ParHashMap__K, _ParHashMap__V], 'ParHashMap'[_ParHashMap__K, _ParHashMap__V]]: ...
    def printDebugBuffer(self) -> None: ...
    def printSizeMap(self) -> None: ...
    _product__U = typing.TypeVar('_product__U')  # <U>
    def product(self, num: scala.math.Numeric[_product__U]) -> _product__U: ...
    def put(self, key: _ParHashMap__K, value: _ParHashMap__V) -> scala.Option[_ParHashMap__V]: ...
    _reduce__U = typing.TypeVar('_reduce__U')  # <U>
    def reduce(self, op: scala.Function2[_reduce__U, _reduce__U, _reduce__U]) -> _reduce__U: ...
    _reduceLeft__U = typing.TypeVar('_reduceLeft__U')  # <U>
    def reduceLeft(self, op: scala.Function2[_reduceLeft__U, scala.Tuple2[_ParHashMap__K, _ParHashMap__V], _reduceLeft__U]) -> _reduceLeft__U: ...
    _reduceLeftOption__U = typing.TypeVar('_reduceLeftOption__U')  # <U>
    def reduceLeftOption(self, op: scala.Function2[_reduceLeftOption__U, scala.Tuple2[_ParHashMap__K, _ParHashMap__V], _reduceLeftOption__U]) -> scala.Option[_reduceLeftOption__U]: ...
    _reduceOption__U = typing.TypeVar('_reduceOption__U')  # <U>
    def reduceOption(self, op: scala.Function2[_reduceOption__U, _reduceOption__U, _reduceOption__U]) -> scala.Option[_reduceOption__U]: ...
    _reduceRight__U = typing.TypeVar('_reduceRight__U')  # <U>
    def reduceRight(self, op: scala.Function2[scala.Tuple2[_ParHashMap__K, _ParHashMap__V], _reduceRight__U, _reduceRight__U]) -> _reduceRight__U: ...
    _reduceRightOption__U = typing.TypeVar('_reduceRightOption__U')  # <U>
    def reduceRightOption(self, op: scala.Function2[scala.Tuple2[_ParHashMap__K, _ParHashMap__V], _reduceRightOption__U, _reduceRightOption__U]) -> scala.Option[_reduceRightOption__U]: ...
    def remove(self, key: _ParHashMap__K) -> scala.Option[_ParHashMap__V]: ...
    def removeEntry(self, key: typing.Any) -> scala.collection.mutable.HashEntry: ...
    def repr(self) -> scala.collection.parallel.ParIterable: ...
    _reuse__S = typing.TypeVar('_reuse__S')  # <S>
    _reuse__That = typing.TypeVar('_reuse__That')  # <That>
    def reuse(self, oldc: scala.Option[scala.collection.parallel.Combiner[_reuse__S, _reuse__That]], newc: scala.collection.parallel.Combiner[_reuse__S, _reuse__That]) -> scala.collection.parallel.Combiner[_reuse__S, _reuse__That]: ...
    _sameElements__U = typing.TypeVar('_sameElements__U')  # <U>
    def sameElements(self, that: scala.collection.GenIterable[_sameElements__U]) -> bool: ...
    def scala$collection$parallel$ParIterableLike$$_tasksupport(self) -> scala.collection.parallel.TaskSupport: ...
    def scala$collection$parallel$ParIterableLike$$_tasksupport_$eq(self, x$1: scala.collection.parallel.TaskSupport) -> None: ...
    _scan__U = typing.TypeVar('_scan__U')  # <U>
    _scan__That = typing.TypeVar('_scan__That')  # <That>
    def scan(self, z: _scan__U, op: scala.Function2[_scan__U, _scan__U, _scan__U], bf: scala.collection.generic.CanBuildFrom['ParHashMap'[_ParHashMap__K, _ParHashMap__V], _scan__U, _scan__That]) -> _scan__That: ...
    def scanBlockSize(self) -> int: ...
    _scanLeft__S = typing.TypeVar('_scanLeft__S')  # <S>
    _scanLeft__That = typing.TypeVar('_scanLeft__That')  # <That>
    def scanLeft(self, z: _scanLeft__S, op: scala.Function2[_scanLeft__S, scala.Tuple2[_ParHashMap__K, _ParHashMap__V], _scanLeft__S], bf: scala.collection.generic.CanBuildFrom['ParHashMap'[_ParHashMap__K, _ParHashMap__V], _scanLeft__S, _scanLeft__That]) -> _scanLeft__That: ...
    _scanRight__S = typing.TypeVar('_scanRight__S')  # <S>
    _scanRight__That = typing.TypeVar('_scanRight__That')  # <That>
    def scanRight(self, z: _scanRight__S, op: scala.Function2[scala.Tuple2[_ParHashMap__K, _ParHashMap__V], _scanRight__S, _scanRight__S], bf: scala.collection.generic.CanBuildFrom['ParHashMap'[_ParHashMap__K, _ParHashMap__V], _scanRight__S, _scanRight__That]) -> _scanRight__That: ...
    def seedvalue(self) -> int: ...
    def seedvalue_$eq(self, x$1: int) -> None: ...
    def seq(self) -> scala.collection.mutable.HashMap[_ParHashMap__K, _ParHashMap__V]: ...
    def sequentially(self, b: scala.Function1) -> scala.collection.parallel.ParIterable: ...
    def serializeTo(self, out: java.io.ObjectOutputStream, writeEntry: scala.Function1[scala.collection.mutable.DefaultEntry[_ParHashMap__K, _ParHashMap__V], scala.runtime.BoxedUnit]) -> None: ...
    def size(self) -> int: ...
    def sizeHintIfCheap(self) -> int: ...
    def sizeMapBucketBitSize(self) -> int: ...
    def sizeMapBucketSize(self) -> int: ...
    def sizeMapDisable(self) -> None: ...
    def sizeMapInit(self, tableLength: int) -> None: ...
    def sizeMapInitAndRebuild(self) -> None: ...
    def sizemap(self) -> typing.List[int]: ...
    def sizemap_$eq(self, x$1: typing.List[int]) -> None: ...
    def slice(self, unc_from: int, unc_until: int) -> scala.collection.parallel.ParIterable: ...
    def span(self, pred: scala.Function1[scala.Tuple2[_ParHashMap__K, _ParHashMap__V], typing.Any]) -> scala.Tuple2['ParHashMap'[_ParHashMap__K, _ParHashMap__V], 'ParHashMap'[_ParHashMap__K, _ParHashMap__V]]: ...
    def splitAt(self, n: int) -> scala.Tuple2['ParHashMap'[_ParHashMap__K, _ParHashMap__V], 'ParHashMap'[_ParHashMap__K, _ParHashMap__V]]: ...
    def splitter(self) -> 'ParHashMap.ParHashMapIterator': ...
    def stringPrefix(self) -> str: ...
    _sum__U = typing.TypeVar('_sum__U')  # <U>
    def sum(self, num: scala.math.Numeric[_sum__U]) -> _sum__U: ...
    def table(self) -> typing.List[scala.collection.mutable.HashEntry[_ParHashMap__K, scala.collection.mutable.DefaultEntry[_ParHashMap__K, _ParHashMap__V]]]: ...
    def tableSize(self) -> int: ...
    def tableSizeSeed(self) -> int: ...
    def tableSize_$eq(self, x$1: int) -> None: ...
    def table_$eq(self, x$1: typing.List[scala.collection.mutable.HashEntry[_ParHashMap__K, scala.collection.mutable.DefaultEntry[_ParHashMap__K, _ParHashMap__V]]]) -> None: ...
    def tail(self) -> scala.collection.parallel.ParIterable: ...
    def take(self, n: int) -> scala.collection.parallel.ParIterable: ...
    def takeWhile(self, pred: scala.Function1) -> scala.collection.parallel.ParIterable: ...
    _task2ops__R = typing.TypeVar('_task2ops__R')  # <R>
    _task2ops__Tp = typing.TypeVar('_task2ops__Tp')  # <Tp>
    def task2ops(self, tsk: scala.collection.parallel.ParIterableLike.StrictSplitterCheckTask[_task2ops__R, _task2ops__Tp]) -> scala.collection.parallel.ParIterableLike.TaskOps[_task2ops__R, _task2ops__Tp]: ...
    def tasksupport(self) -> scala.collection.parallel.TaskSupport: ...
    def tasksupport_$eq(self, ts: scala.collection.parallel.TaskSupport) -> None: ...
    def threshold(self) -> int: ...
    def threshold_$eq(self, x$1: int) -> None: ...
    _to__Col = typing.TypeVar('_to__Col')  # <Col>
    def to(self, cbf: scala.collection.generic.CanBuildFrom[scala.runtime.Nothing., scala.Tuple2[_ParHashMap__K, _ParHashMap__V], _to__Col]) -> _to__Col: ...
    _toArray__U = typing.TypeVar('_toArray__U')  # <U>
    def toArray(self, evidence$1: scala.reflect.ClassTag[_toArray__U]) -> typing.Any: ...
    _toBuffer__U = typing.TypeVar('_toBuffer__U')  # <U>
    def toBuffer(self) -> scala.collection.mutable.Buffer[_toBuffer__U]: ...
    def toIndexedSeq(self) -> scala.collection.immutable.IndexedSeq[scala.Tuple2[_ParHashMap__K, _ParHashMap__V]]: ...
    def toIterable(self) -> ParIterable[scala.Tuple2[_ParHashMap__K, _ParHashMap__V]]: ...
    def toIterator(self) -> scala.collection.Iterator[scala.Tuple2[_ParHashMap__K, _ParHashMap__V]]: ...
    def toList(self) -> scala.collection.immutable.List[scala.Tuple2[_ParHashMap__K, _ParHashMap__V]]: ...
    _toMap__K = typing.TypeVar('_toMap__K')  # <K>
    _toMap__V = typing.TypeVar('_toMap__V')  # <V>
    def toMap(self, ev: scala.Predef..less.colon.less[scala.Tuple2[typing.Any, typing.Any], scala.Tuple2[typing.Any, typing.Any]]) -> scala.collection.parallel.immutable.ParMap[typing.Any, typing.Any]: ...
    _toParCollection__U = typing.TypeVar('_toParCollection__U')  # <U>
    _toParCollection__That = typing.TypeVar('_toParCollection__That')  # <That>
    def toParCollection(self, cbf: scala.Function0[scala.collection.parallel.Combiner[_toParCollection__U, _toParCollection__That]]) -> _toParCollection__That: ...
    _toParMap__K = typing.TypeVar('_toParMap__K')  # <K>
    _toParMap__V = typing.TypeVar('_toParMap__V')  # <V>
    _toParMap__That = typing.TypeVar('_toParMap__That')  # <That>
    def toParMap(self, cbf: scala.Function0[scala.collection.parallel.Combiner[scala.Tuple2[typing.Any, typing.Any], _toParMap__That]], ev: scala.Predef..less.colon.less[scala.Tuple2[typing.Any, typing.Any], scala.Tuple2[typing.Any, typing.Any]]) -> _toParMap__That: ...
    def toSeq(self) -> ParSeq[scala.Tuple2[_ParHashMap__K, _ParHashMap__V]]: ...
    _toSet__U = typing.TypeVar('_toSet__U')  # <U>
    def toSet(self) -> scala.collection.parallel.immutable.ParSet[_toSet__U]: ...
    def toStream(self) -> scala.collection.immutable.Stream[scala.Tuple2[_ParHashMap__K, _ParHashMap__V]]: ...
    def toString(self) -> str: ...
    def toTraversable(self) -> scala.collection.GenTraversable[scala.Tuple2[_ParHashMap__K, _ParHashMap__V]]: ...
    def toVector(self) -> scala.collection.immutable.Vector[scala.Tuple2[_ParHashMap__K, _ParHashMap__V]]: ...
    def totalSizeMapBuckets(self) -> int: ...
    def transpose(self, asTraversable: scala.Function1) -> scala.collection.GenTraversable: ...
    _unzip__A1 = typing.TypeVar('_unzip__A1')  # <A1>
    _unzip__A2 = typing.TypeVar('_unzip__A2')  # <A2>
    def unzip(self, asPair: scala.Function1[scala.Tuple2[_ParHashMap__K, _ParHashMap__V], scala.Tuple2[_unzip__A1, _unzip__A2]]) -> scala.Tuple2[ParIterable[_unzip__A1], ParIterable[_unzip__A2]]: ...
    _unzip3__A1 = typing.TypeVar('_unzip3__A1')  # <A1>
    _unzip3__A2 = typing.TypeVar('_unzip3__A2')  # <A2>
    _unzip3__A3 = typing.TypeVar('_unzip3__A3')  # <A3>
    def unzip3(self, asTriple: scala.Function1[scala.Tuple2[_ParHashMap__K, _ParHashMap__V], scala.Tuple3[_unzip3__A1, _unzip3__A2, _unzip3__A3]]) -> scala.Tuple3[ParIterable[_unzip3__A1], ParIterable[_unzip3__A2], ParIterable[_unzip3__A3]]: ...
    def update(self, key: _ParHashMap__K, value: _ParHashMap__V) -> None: ...
    _updated__U = typing.TypeVar('_updated__U')  # <U>
    def updated(self, key: _ParHashMap__K, value: _updated__U) -> 'ParMap'[_ParHashMap__K, _updated__U]: ...
    def values(self) -> scala.collection.parallel.ParIterable[_ParHashMap__V]: ...
    def valuesIterator(self) -> scala.collection.parallel.IterableSplitter[_ParHashMap__V]: ...
    def view(self) -> scala.collection.IterableView[scala.Tuple2[_ParHashMap__K, _ParHashMap__V], scala.collection.mutable.HashMap[_ParHashMap__K, _ParHashMap__V]]: ...
    def withDefault(self, d: scala.Function1[_ParHashMap__K, _ParHashMap__V]) -> 'ParMap'[_ParHashMap__K, _ParHashMap__V]: ...
    def withDefaultValue(self, d: _ParHashMap__V) -> 'ParMap'[_ParHashMap__K, _ParHashMap__V]: ...
    def withFilter(self, pred: scala.Function1) -> scala.collection.parallel.ParIterable: ...
    _wrap__R = typing.TypeVar('_wrap__R')  # <R>
    def wrap(self, body: scala.Function0[_wrap__R]) -> scala.collection.parallel.ParIterableLike.NonDivisible[_wrap__R]: ...
    _zip__U = typing.TypeVar('_zip__U')  # <U>
    _zip__S = typing.TypeVar('_zip__S')  # <S>
    _zip__That = typing.TypeVar('_zip__That')  # <That>
    def zip(self, that: scala.collection.GenIterable[_zip__S], bf: scala.collection.generic.CanBuildFrom['ParHashMap'[_ParHashMap__K, _ParHashMap__V], scala.Tuple2[_zip__U, _zip__S], _zip__That]) -> _zip__That: ...
    _zipAll__S = typing.TypeVar('_zipAll__S')  # <S>
    _zipAll__U = typing.TypeVar('_zipAll__U')  # <U>
    _zipAll__That = typing.TypeVar('_zipAll__That')  # <That>
    def zipAll(self, that: scala.collection.GenIterable[_zipAll__S], thisElem: _zipAll__U, thatElem: _zipAll__S, bf: scala.collection.generic.CanBuildFrom['ParHashMap'[_ParHashMap__K, _ParHashMap__V], scala.Tuple2[_zipAll__U, _zipAll__S], _zipAll__That]) -> _zipAll__That: ...
    _zipWithIndex__U = typing.TypeVar('_zipWithIndex__U')  # <U>
    _zipWithIndex__That = typing.TypeVar('_zipWithIndex__That')  # <That>
    def zipWithIndex(self, bf: scala.collection.generic.CanBuildFrom['ParHashMap'[_ParHashMap__K, _ParHashMap__V], scala.Tuple2[_zipWithIndex__U, typing.Any], _zipWithIndex__That]) -> _zipWithIndex__That: ...
    class ParHashMapIterator(ParHashTable.EntryIterator[scala.Tuple2[_ParHashMap__K, _ParHashMap__V], 'ParHashMap.ParHashMapIterator']):
        def __init__(self, $outer: 'ParHashMap', start: int, untilIdx: int, totalSize: int, e: scala.collection.mutable.DefaultEntry[_ParHashMap__K, _ParHashMap__V]): ...
        def entry2item(self, entry: scala.collection.mutable.DefaultEntry[_ParHashMap__K, _ParHashMap__V]) -> scala.Tuple2[_ParHashMap__K, _ParHashMap__V]: ...
        def newIterator(self, idxFrom: int, idxUntil: int, totalSz: int, es: scala.collection.mutable.DefaultEntry[_ParHashMap__K, _ParHashMap__V]) -> 'ParHashMap.ParHashMapIterator': ...

_ParMap__WithDefault__K = typing.TypeVar('_ParMap__WithDefault__K')  # <K>
_ParMap__WithDefault__V = typing.TypeVar('_ParMap__WithDefault__V')  # <V>
_ParMap__K = typing.TypeVar('_ParMap__K')  # <K>
_ParMap__V = typing.TypeVar('_ParMap__V')  # <V>
class ParMap(scala.collection.parallel.ParMap[_ParMap__K, _ParMap__V], ParIterable[scala.Tuple2[_ParMap__K, _ParMap__V]], ParMapLike[_ParMap__K, _ParMap__V, 'ParMap'[_ParMap__K, _ParMap__V], scala.collection.mutable.Map[_ParMap__K, _ParMap__V]], typing.Generic[_ParMap__K, _ParMap__V]):
    @staticmethod
    def $init$($this: 'ParMap') -> None: ...
    _canBuildFrom__K = typing.TypeVar('_canBuildFrom__K')  # <K>
    _canBuildFrom__V = typing.TypeVar('_canBuildFrom__V')  # <V>
    @staticmethod
    def canBuildFrom() -> scala.collection.generic.CanCombineFrom['ParMap'[typing.Any, typing.Any], scala.Tuple2[_canBuildFrom__K, _canBuildFrom__V], 'ParMap'[_canBuildFrom__K, _canBuildFrom__V]]: ...
    @typing.overload
    def empty(self) -> scala.collection.parallel.ParMap[_ParMap__K, _ParMap__V]: ...
    @typing.overload
    def empty(self) -> 'ParMap'[_ParMap__K, _ParMap__V]: ...
    def equals(self, that: typing.Any) -> bool: ...
    def hashCode(self) -> int: ...
    def mapCompanion(self) -> scala.collection.generic.GenericParMapCompanion['ParMap']: ...
    def newCombiner(self) -> scala.collection.parallel.Combiner[scala.Tuple2[_ParMap__K, _ParMap__V], 'ParMap'[_ParMap__K, _ParMap__V]]: ...
    @typing.overload
    def seq(self) -> scala.collection.Iterable[typing.Any]: ...
    @typing.overload
    def seq(self) -> scala.collection.Iterable: ...
    @typing.overload
    def seq(self) -> scala.collection.Map[_ParMap__K, _ParMap__V]: ...
    @typing.overload
    def seq(self) -> scala.collection.Traversable[typing.Any]: ...
    @typing.overload
    def seq(self) -> scala.collection.TraversableOnce[typing.Any]: ...
    @typing.overload
    def seq(self) -> scala.collection.TraversableOnce[typing.Any]: ...
    @typing.overload
    def seq(self) -> scala.collection.mutable.Iterable[typing.Any]: ...
    @typing.overload
    def seq(self) -> scala.collection.mutable.Map[_ParMap__K, _ParMap__V]: ...
    def toString(self) -> str: ...
    _updated_0__V1 = typing.TypeVar('_updated_0__V1')  # <V1>
    _updated_1__U = typing.TypeVar('_updated_1__U')  # <U>
    _updated_2__U = typing.TypeVar('_updated_2__U')  # <U>
    @typing.overload
    def updated(self, key: _ParMap__K, value: _updated_0__V1) -> scala.collection.GenMap[_ParMap__K, _updated_0__V1]: ...
    @typing.overload
    def updated(self, key: _ParMap__K, value: _updated_1__U) -> scala.collection.parallel.ParMap[_ParMap__K, _updated_1__U]: ...
    @typing.overload
    def updated(self, key: _ParMap__K, value: _updated_2__U) -> 'ParMap'[_ParMap__K, _updated_2__U]: ...
    def withDefault(self, d: scala.Function1[_ParMap__K, _ParMap__V]) -> 'ParMap'[_ParMap__K, _ParMap__V]: ...
    def withDefaultValue(self, d: _ParMap__V) -> 'ParMap'[_ParMap__K, _ParMap__V]: ...
    class WithDefault(scala.collection.parallel.ParMap.WithDefault[_ParMap__WithDefault__K, _ParMap__WithDefault__V], scala.collection.parallel.mutable.ParMap[_ParMap__WithDefault__K, _ParMap__WithDefault__V], typing.Generic[_ParMap__WithDefault__K, _ParMap__WithDefault__V]):
        def __init__(self, underlying: 'ParMap'[_ParMap__WithDefault__K, _ParMap__WithDefault__V], d: scala.Function1[_ParMap__WithDefault__K, _ParMap__WithDefault__V]): ...
        def $minus(self, key: _ParMap__WithDefault__K) -> 'ParMap.WithDefault'[_ParMap__WithDefault__K, _ParMap__WithDefault__V]: ...
        @typing.overload
        def $minus$eq(self, elem1: _ParMap__WithDefault__K, elem2: _ParMap__WithDefault__K, elems: scala.collection.Seq[_ParMap__WithDefault__K]) -> scala.collection.generic.Shrinkable[_ParMap__WithDefault__K]: ...
        @typing.overload
        def $minus$eq(self, key: _ParMap__WithDefault__K) -> 'ParMap.WithDefault'[_ParMap__WithDefault__K, _ParMap__WithDefault__V]: ...
        def $minus$minus$eq(self, xs: scala.collection.TraversableOnce[_ParMap__WithDefault__K]) -> scala.collection.generic.Shrinkable[_ParMap__WithDefault__K]: ...
        _$plus__U = typing.TypeVar('_$plus__U')  # <U>
        def $plus(self, kv: scala.Tuple2[_ParMap__WithDefault__K, _.plus__U]) -> 'ParMap.WithDefault'[_ParMap__WithDefault__K, _.plus__U]: ...
        @typing.overload
        def $plus$eq(self, elem1: typing.Any, elem2: typing.Any, elems: scala.collection.Seq) -> scala.collection.generic.Growable: ...
        @typing.overload
        def $plus$eq(self, kv: scala.Tuple2[_ParMap__WithDefault__K, _ParMap__WithDefault__V]) -> 'ParMap.WithDefault'[_ParMap__WithDefault__K, _ParMap__WithDefault__V]: ...
        def $plus$plus$eq(self, xs: scala.collection.TraversableOnce[scala.Tuple2[_ParMap__WithDefault__K, _ParMap__WithDefault__V]]) -> scala.collection.generic.Growable[scala.Tuple2[_ParMap__WithDefault__K, _ParMap__WithDefault__V]]: ...
        def clear(self) -> None: ...
        def clone(self) -> typing.Any: ...
        def companion(self) -> scala.collection.generic.GenericCompanion[ParIterable]: ...
        def drop(self, n: int) -> scala.collection.parallel.ParIterable: ...
        def dropWhile(self, pred: scala.Function1) -> scala.collection.parallel.ParIterable: ...
        def empty(self) -> 'ParMap.WithDefault'[_ParMap__WithDefault__K, _ParMap__WithDefault__V]: ...
        def filter(self, pred: scala.Function1) -> scala.collection.parallel.ParIterable: ...
        def filterKeys(self, p: scala.Function1[typing.Any, typing.Any]) -> scala.collection.parallel.ParMap[typing.Any, typing.Any]: ...
        def filterNot(self, pred: scala.Function1) -> scala.collection.parallel.ParIterable: ...
        _genericBuilder__B = typing.TypeVar('_genericBuilder__B')  # <B>
        def genericBuilder(self) -> scala.collection.parallel.Combiner[_genericBuilder__B, scala.collection.parallel.ParIterable[_genericBuilder__B]]: ...
        _groupBy__K = typing.TypeVar('_groupBy__K')  # <K>
        def groupBy(self, f: scala.Function1[scala.Tuple2[typing.Any, typing.Any], typing.Any]) -> scala.collection.parallel.immutable.ParMap[typing.Any, scala.collection.parallel.ParMap[typing.Any, typing.Any]]: ...
        def init(self) -> scala.collection.parallel.ParIterable: ...
        def iterator(self) -> scala.collection.parallel.Splitter[scala.Tuple2[typing.Any, typing.Any]]: ...
        def keySet(self) -> scala.collection.parallel.ParSet[typing.Any]: ...
        def keys(self) -> scala.collection.parallel.ParIterable[typing.Any]: ...
        def keysIterator(self) -> scala.collection.parallel.IterableSplitter[typing.Any]: ...
        def mapCompanion(self) -> scala.collection.generic.GenericParMapCompanion['ParMap']: ...
        _mapValues__S = typing.TypeVar('_mapValues__S')  # <S>
        def mapValues(self, f: scala.Function1[typing.Any, _mapValues__S]) -> scala.collection.parallel.ParMap[typing.Any, _mapValues__S]: ...
        def newCombiner(self) -> scala.collection.parallel.Combiner[scala.Tuple2[_ParMap__WithDefault__K, _ParMap__WithDefault__V], 'ParMap'[_ParMap__WithDefault__K, _ParMap__WithDefault__V]]: ...
        def par(self) -> scala.collection.parallel.ParIterable: ...
        def put(self, key: _ParMap__WithDefault__K, value: _ParMap__WithDefault__V) -> scala.Option[_ParMap__WithDefault__V]: ...
        def repr(self) -> scala.collection.parallel.ParIterable: ...
        def seq(self) -> scala.collection.mutable.Map[_ParMap__WithDefault__K, _ParMap__WithDefault__V]: ...
        def slice(self, unc_from: int, unc_until: int) -> scala.collection.parallel.ParIterable: ...
        def tail(self) -> scala.collection.parallel.ParIterable: ...
        def take(self, n: int) -> scala.collection.parallel.ParIterable: ...
        def takeWhile(self, pred: scala.Function1) -> scala.collection.parallel.ParIterable: ...
        def toIterable(self) -> ParIterable[scala.Tuple2[_ParMap__WithDefault__K, _ParMap__WithDefault__V]]: ...
        _toMap__K = typing.TypeVar('_toMap__K')  # <K>
        _toMap__V = typing.TypeVar('_toMap__V')  # <V>
        def toMap(self, ev: scala.Predef..less.colon.less[scala.Tuple2[typing.Any, typing.Any], scala.Tuple2[typing.Any, typing.Any]]) -> scala.collection.parallel.immutable.ParMap[typing.Any, typing.Any]: ...
        def toSeq(self) -> ParSeq[scala.Tuple2[_ParMap__WithDefault__K, _ParMap__WithDefault__V]]: ...
        _toSet__U = typing.TypeVar('_toSet__U')  # <U>
        def toSet(self) -> scala.collection.parallel.immutable.ParSet[_toSet__U]: ...
        _updated__U = typing.TypeVar('_updated__U')  # <U>
        def updated(self, key: _ParMap__WithDefault__K, value: _updated__U) -> 'ParMap.WithDefault'[_ParMap__WithDefault__K, _updated__U]: ...
        def values(self) -> scala.collection.parallel.ParIterable[typing.Any]: ...
        def valuesIterator(self) -> scala.collection.parallel.IterableSplitter[typing.Any]: ...
        def withDefault(self, d: scala.Function1[_ParMap__WithDefault__K, _ParMap__WithDefault__V]) -> 'ParMap'[_ParMap__WithDefault__K, _ParMap__WithDefault__V]: ...
        def withDefaultValue(self, d: _ParMap__WithDefault__V) -> 'ParMap'[_ParMap__WithDefault__K, _ParMap__WithDefault__V]: ...

_ParTrieMap__K = typing.TypeVar('_ParTrieMap__K')  # <K>
_ParTrieMap__V = typing.TypeVar('_ParTrieMap__V')  # <V>
class ParTrieMap(ParMap[_ParTrieMap__K, _ParTrieMap__V], ParTrieMapCombiner[_ParTrieMap__K, _ParTrieMap__V], scala.Serializable, typing.Generic[_ParTrieMap__K, _ParTrieMap__V]):
    @typing.overload
    def __init__(self): ...
    @typing.overload
    def __init__(self, ctrie: scala.collection.concurrent.TrieMap[_ParTrieMap__K, _ParTrieMap__V]): ...
    _$colon$bslash__S = typing.TypeVar('_$colon$bslash__S')  # <S>
    def $colon$bslash(self, z: _.colon.bslash__S, op: scala.Function2[scala.Tuple2[_ParTrieMap__K, _ParTrieMap__V], _.colon.bslash__S, _.colon.bslash__S]) -> _.colon.bslash__S: ...
    _$div$colon__S = typing.TypeVar('_$div$colon__S')  # <S>
    def $div$colon(self, z: _.div.colon__S, op: scala.Function2[_.div.colon__S, scala.Tuple2[_ParTrieMap__K, _ParTrieMap__V], _.div.colon__S]) -> _.div.colon__S: ...
    def $minus(self, key: typing.Any) -> ParMap: ...
    @typing.overload
    def $minus$eq(self, elem1: _ParTrieMap__K, elem2: _ParTrieMap__K, elems: scala.collection.Seq[_ParTrieMap__K]) -> scala.collection.generic.Shrinkable[_ParTrieMap__K]: ...
    @typing.overload
    def $minus$eq(self, key: _ParTrieMap__K) -> 'ParTrieMap'[_ParTrieMap__K, _ParTrieMap__V]: ...
    def $minus$minus$eq(self, xs: scala.collection.TraversableOnce[_ParTrieMap__K]) -> scala.collection.generic.Shrinkable[_ParTrieMap__K]: ...
    _$plus__U = typing.TypeVar('_$plus__U')  # <U>
    def $plus(self, kv: scala.Tuple2[_ParTrieMap__K, _.plus__U]) -> ParMap[_ParTrieMap__K, _.plus__U]: ...
    @typing.overload
    def $plus$eq(self, elem1: typing.Any, elem2: typing.Any, elems: scala.collection.Seq) -> scala.collection.generic.Growable: ...
    @typing.overload
    def $plus$eq(self, kv: scala.Tuple2[_ParTrieMap__K, _ParTrieMap__V]) -> 'ParTrieMap'[_ParTrieMap__K, _ParTrieMap__V]: ...
    _$plus$plus__U = typing.TypeVar('_$plus$plus__U')  # <U>
    _$plus$plus__That = typing.TypeVar('_$plus$plus__That')  # <That>
    def $plus$plus(self, that: scala.collection.GenTraversableOnce[_.plus.plus__U], bf: scala.collection.generic.CanBuildFrom['ParTrieMap'[_ParTrieMap__K, _ParTrieMap__V], _.plus.plus__U, _.plus.plus__That]) -> _.plus.plus__That: ...
    def $plus$plus$eq(self, xs: scala.collection.TraversableOnce[scala.Tuple2[_ParTrieMap__K, _ParTrieMap__V]]) -> scala.collection.generic.Growable[scala.Tuple2[_ParTrieMap__K, _ParTrieMap__V]]: ...
    def ScanLeaf(self) -> scala.collection.parallel.ParIterableLike.ScanLeaf.: ...
    def ScanNode(self) -> scala.collection.parallel.ParIterableLike.ScanNode.: ...
    def _combinerTaskSupport(self) -> scala.collection.parallel.TaskSupport: ...
    def _combinerTaskSupport_$eq(self, x$1: scala.collection.parallel.TaskSupport) -> None: ...
    _aggregate__S = typing.TypeVar('_aggregate__S')  # <S>
    def aggregate(self, z: scala.Function0[_aggregate__S], seqop: scala.Function2[_aggregate__S, scala.Tuple2[_ParTrieMap__K, _ParTrieMap__V], _aggregate__S], combop: scala.Function2[_aggregate__S, _aggregate__S, _aggregate__S]) -> _aggregate__S: ...
    def apply(self, key: _ParTrieMap__K) -> _ParTrieMap__V: ...
    _bf2seq__S = typing.TypeVar('_bf2seq__S')  # <S>
    _bf2seq__That = typing.TypeVar('_bf2seq__That')  # <That>
    def bf2seq(self, bf: scala.collection.generic.CanBuildFrom['ParTrieMap'[_ParTrieMap__K, _ParTrieMap__V], _bf2seq__S, _bf2seq__That]) -> scala.collection.generic.CanBuildFrom[scala.collection.concurrent.TrieMap[_ParTrieMap__K, _ParTrieMap__V], _bf2seq__S, _bf2seq__That]: ...
    def brokenInvariants(self) -> scala.collection.Seq[str]: ...
    _builder2ops__Elem = typing.TypeVar('_builder2ops__Elem')  # <Elem>
    _builder2ops__To = typing.TypeVar('_builder2ops__To')  # <To>
    def builder2ops(self, cb: scala.collection.mutable.Builder[_builder2ops__Elem, _builder2ops__To]) -> scala.collection.parallel.ParIterableLike.BuilderOps[_builder2ops__Elem, _builder2ops__To]: ...
    def canBeShared(self) -> bool: ...
    _canBuildFrom__K = typing.TypeVar('_canBuildFrom__K')  # <K>
    _canBuildFrom__V = typing.TypeVar('_canBuildFrom__V')  # <V>
    @staticmethod
    def canBuildFrom() -> scala.collection.generic.CanCombineFrom['ParTrieMap'[typing.Any, typing.Any], scala.Tuple2[_canBuildFrom__K, _canBuildFrom__V], 'ParTrieMap'[_canBuildFrom__K, _canBuildFrom__V]]: ...
    def canEqual(self, other: typing.Any) -> bool: ...
    def clear(self) -> None: ...
    def clone(self) -> typing.Any: ...
    _collect__S = typing.TypeVar('_collect__S')  # <S>
    _collect__That = typing.TypeVar('_collect__That')  # <That>
    def collect(self, pf: scala.PartialFunction[scala.Tuple2[_ParTrieMap__K, _ParTrieMap__V], _collect__S], bf: scala.collection.generic.CanBuildFrom['ParTrieMap'[_ParTrieMap__K, _ParTrieMap__V], _collect__S, _collect__That]) -> _collect__That: ...
    _combine__N = typing.TypeVar('_combine__N', bound=scala.Tuple2)  # <N>
    _combine__NewTo = typing.TypeVar('_combine__NewTo')  # <NewTo>
    def combine(self, other: scala.collection.parallel.Combiner[_combine__N, _combine__NewTo]) -> scala.collection.parallel.Combiner[_combine__N, _combine__NewTo]: ...
    _combinerFactory_1__S = typing.TypeVar('_combinerFactory_1__S')  # <S>
    _combinerFactory_1__That = typing.TypeVar('_combinerFactory_1__That')  # <That>
    @typing.overload
    def combinerFactory(self) -> scala.collection.parallel.CombinerFactory[scala.Tuple2[_ParTrieMap__K, _ParTrieMap__V], 'ParTrieMap'[_ParTrieMap__K, _ParTrieMap__V]]: ...
    @typing.overload
    def combinerFactory(self, cbf: scala.Function0[scala.collection.parallel.Combiner[_combinerFactory_1__S, _combinerFactory_1__That]]) -> scala.collection.parallel.CombinerFactory[_combinerFactory_1__S, _combinerFactory_1__That]: ...
    def combinerTaskSupport(self) -> scala.collection.parallel.TaskSupport: ...
    def combinerTaskSupport_$eq(self, cts: scala.collection.parallel.TaskSupport) -> None: ...
    def companion(self) -> scala.collection.generic.GenericCompanion[ParIterable]: ...
    def contains(self, key: _ParTrieMap__K) -> bool: ...
    _copyToArray_0__U = typing.TypeVar('_copyToArray_0__U')  # <U>
    _copyToArray_1__U = typing.TypeVar('_copyToArray_1__U')  # <U>
    _copyToArray_2__U = typing.TypeVar('_copyToArray_2__U')  # <U>
    @typing.overload
    def copyToArray(self, xs: typing.Any) -> None: ...
    @typing.overload
    def copyToArray(self, xs: typing.Any, start: int) -> None: ...
    @typing.overload
    def copyToArray(self, xs: typing.Any, start: int, len: int) -> None: ...
    def count(self, p: scala.Function1[scala.Tuple2[_ParTrieMap__K, _ParTrieMap__V], typing.Any]) -> int: ...
    def debugBuffer(self) -> scala.collection.mutable.ArrayBuffer[str]: ...
    def debugInformation(self) -> str: ...
    def debugclear(self) -> None: ...
    def debuglog(self, s: str) -> scala.collection.mutable.ArrayBuffer[str]: ...
    def default(self, key: _ParTrieMap__K) -> _ParTrieMap__V: ...
    _delegatedSignalling2ops__PI = typing.TypeVar('_delegatedSignalling2ops__PI', bound=scala.collection.generic.DelegatedSignalling)  # <PI>
    def delegatedSignalling2ops(self, it: _delegatedSignalling2ops__PI) -> scala.collection.parallel.ParIterableLike.SignallingOps[_delegatedSignalling2ops__PI]: ...
    def drop(self, n: int) -> scala.collection.parallel.ParIterable: ...
    def dropWhile(self, pred: scala.Function1) -> scala.collection.parallel.ParIterable: ...
    def empty(self) -> 'ParTrieMap'[_ParTrieMap__K, _ParTrieMap__V]: ...
    def equals(self, that: typing.Any) -> bool: ...
    def exists(self, p: scala.Function1[scala.Tuple2[_ParTrieMap__K, _ParTrieMap__V], typing.Any]) -> bool: ...
    def filter(self, pred: scala.Function1) -> scala.collection.parallel.ParIterable: ...
    def filterKeys(self, p: scala.Function1[_ParTrieMap__K, typing.Any]) -> scala.collection.parallel.ParMap[_ParTrieMap__K, _ParTrieMap__V]: ...
    def filterNot(self, pred: scala.Function1) -> scala.collection.parallel.ParIterable: ...
    def find(self, p: scala.Function1[scala.Tuple2[_ParTrieMap__K, _ParTrieMap__V], typing.Any]) -> scala.Option[scala.Tuple2[_ParTrieMap__K, _ParTrieMap__V]]: ...
    _flatMap__S = typing.TypeVar('_flatMap__S')  # <S>
    _flatMap__That = typing.TypeVar('_flatMap__That')  # <That>
    def flatMap(self, f: scala.Function1[scala.Tuple2[_ParTrieMap__K, _ParTrieMap__V], scala.collection.GenTraversableOnce[_flatMap__S]], bf: scala.collection.generic.CanBuildFrom['ParTrieMap'[_ParTrieMap__K, _ParTrieMap__V], _flatMap__S, _flatMap__That]) -> _flatMap__That: ...
    def flatten(self, asTraversable: scala.Function1) -> scala.collection.GenTraversable: ...
    _fold__U = typing.TypeVar('_fold__U')  # <U>
    def fold(self, z: _fold__U, op: scala.Function2[_fold__U, _fold__U, _fold__U]) -> _fold__U: ...
    _foldLeft__S = typing.TypeVar('_foldLeft__S')  # <S>
    def foldLeft(self, z: _foldLeft__S, op: scala.Function2[_foldLeft__S, scala.Tuple2[_ParTrieMap__K, _ParTrieMap__V], _foldLeft__S]) -> _foldLeft__S: ...
    _foldRight__S = typing.TypeVar('_foldRight__S')  # <S>
    def foldRight(self, z: _foldRight__S, op: scala.Function2[scala.Tuple2[_ParTrieMap__K, _ParTrieMap__V], _foldRight__S, _foldRight__S]) -> _foldRight__S: ...
    def forall(self, p: scala.Function1[scala.Tuple2[_ParTrieMap__K, _ParTrieMap__V], typing.Any]) -> bool: ...
    _foreach__U = typing.TypeVar('_foreach__U')  # <U>
    def foreach(self, f: scala.Function1[scala.Tuple2[_ParTrieMap__K, _ParTrieMap__V], _foreach__U]) -> None: ...
    _genericBuilder__B = typing.TypeVar('_genericBuilder__B')  # <B>
    def genericBuilder(self) -> scala.collection.parallel.Combiner[_genericBuilder__B, ParIterable[_genericBuilder__B]]: ...
    _genericCombiner__B = typing.TypeVar('_genericCombiner__B')  # <B>
    def genericCombiner(self) -> scala.collection.parallel.Combiner[_genericCombiner__B, ParIterable[_genericCombiner__B]]: ...
    _genericMapCombiner__P = typing.TypeVar('_genericMapCombiner__P')  # <P>
    _genericMapCombiner__Q = typing.TypeVar('_genericMapCombiner__Q')  # <Q>
    def genericMapCombiner(self) -> scala.collection.parallel.Combiner[scala.Tuple2[_genericMapCombiner__P, _genericMapCombiner__Q], 'ParTrieMap'[_genericMapCombiner__P, _genericMapCombiner__Q]]: ...
    def get(self, key: _ParTrieMap__K) -> scala.Option[_ParTrieMap__V]: ...
    _getOrElse__U = typing.TypeVar('_getOrElse__U')  # <U>
    def getOrElse(self, key: _ParTrieMap__K, default: scala.Function0[_getOrElse__U]) -> _getOrElse__U: ...
    _groupBy__K = typing.TypeVar('_groupBy__K')  # <K>
    def groupBy(self, f: scala.Function1[scala.Tuple2[typing.Any, _ParTrieMap__V], typing.Any]) -> scala.collection.parallel.immutable.ParMap[typing.Any, 'ParTrieMap'[typing.Any, _ParTrieMap__V]]: ...
    def hasDefiniteSize(self) -> bool: ...
    def hashCode(self) -> int: ...
    def head(self) -> typing.Any: ...
    def headOption(self) -> scala.Option[scala.Tuple2[_ParTrieMap__K, _ParTrieMap__V]]: ...
    def init(self) -> scala.collection.parallel.ParIterable: ...
    def initTaskSupport(self) -> None: ...
    def isDefinedAt(self, key: _ParTrieMap__K) -> bool: ...
    def isEmpty(self) -> bool: ...
    def isStrictSplitterCollection(self) -> bool: ...
    def isTraversableAgain(self) -> bool: ...
    def iterator(self) -> scala.collection.parallel.Splitter[scala.Tuple2[_ParTrieMap__K, _ParTrieMap__V]]: ...
    def keySet(self) -> scala.collection.parallel.ParSet[_ParTrieMap__K]: ...
    def keys(self) -> scala.collection.parallel.ParIterable[_ParTrieMap__K]: ...
    def keysIterator(self) -> scala.collection.parallel.IterableSplitter[_ParTrieMap__K]: ...
    def last(self) -> typing.Any: ...
    def lastOption(self) -> scala.Option[scala.Tuple2[_ParTrieMap__K, _ParTrieMap__V]]: ...
    _map__S = typing.TypeVar('_map__S')  # <S>
    _map__That = typing.TypeVar('_map__That')  # <That>
    def map(self, f: scala.Function1[scala.Tuple2[_ParTrieMap__K, _ParTrieMap__V], _map__S], bf: scala.collection.generic.CanBuildFrom['ParTrieMap'[_ParTrieMap__K, _ParTrieMap__V], _map__S, _map__That]) -> _map__That: ...
    def mapCompanion(self) -> scala.collection.generic.GenericParMapCompanion['ParTrieMap']: ...
    _mapResult__NewTo = typing.TypeVar('_mapResult__NewTo')  # <NewTo>
    def mapResult(self, f: scala.Function1['ParTrieMap'[_ParTrieMap__K, _ParTrieMap__V], _mapResult__NewTo]) -> scala.collection.mutable.Builder[scala.Tuple2[_ParTrieMap__K, _ParTrieMap__V], _mapResult__NewTo]: ...
    _mapValues__S = typing.TypeVar('_mapValues__S')  # <S>
    def mapValues(self, f: scala.Function1[_ParTrieMap__V, _mapValues__S]) -> scala.collection.parallel.ParMap[_ParTrieMap__K, _mapValues__S]: ...
    def max(self, ord: scala.math.Ordering) -> typing.Any: ...
    def maxBy(self, f: scala.Function1, cmp: scala.math.Ordering) -> typing.Any: ...
    def min(self, ord: scala.math.Ordering) -> typing.Any: ...
    def minBy(self, f: scala.Function1, cmp: scala.math.Ordering) -> typing.Any: ...
    @typing.overload
    def mkString(self) -> str: ...
    @typing.overload
    def mkString(self, sep: str) -> str: ...
    @typing.overload
    def mkString(self, start: str, sep: str, end: str) -> str: ...
    def newBuilder(self) -> scala.collection.mutable.Builder[scala.Tuple2[_ParTrieMap__K, _ParTrieMap__V], ParIterable[scala.Tuple2[_ParTrieMap__K, _ParTrieMap__V]]]: ...
    def newCombiner(self) -> scala.collection.parallel.Combiner[scala.Tuple2[_ParTrieMap__K, _ParTrieMap__V], 'ParTrieMap'[_ParTrieMap__K, _ParTrieMap__V]]: ...
    def nonEmpty(self) -> bool: ...
    def par(self) -> scala.collection.parallel.ParIterable: ...
    def parCombiner(self) -> scala.collection.parallel.Combiner[scala.Tuple2[_ParTrieMap__K, _ParTrieMap__V], 'ParTrieMap'[_ParTrieMap__K, _ParTrieMap__V]]: ...
    def partition(self, pred: scala.Function1[scala.Tuple2[_ParTrieMap__K, _ParTrieMap__V], typing.Any]) -> scala.Tuple2['ParTrieMap'[_ParTrieMap__K, _ParTrieMap__V], 'ParTrieMap'[_ParTrieMap__K, _ParTrieMap__V]]: ...
    def printDebugBuffer(self) -> None: ...
    _product__U = typing.TypeVar('_product__U')  # <U>
    def product(self, num: scala.math.Numeric[_product__U]) -> _product__U: ...
    def put(self, key: _ParTrieMap__K, value: _ParTrieMap__V) -> scala.Option[_ParTrieMap__V]: ...
    _reduce__U = typing.TypeVar('_reduce__U')  # <U>
    def reduce(self, op: scala.Function2[_reduce__U, _reduce__U, _reduce__U]) -> _reduce__U: ...
    _reduceLeft__U = typing.TypeVar('_reduceLeft__U')  # <U>
    def reduceLeft(self, op: scala.Function2[_reduceLeft__U, scala.Tuple2[_ParTrieMap__K, _ParTrieMap__V], _reduceLeft__U]) -> _reduceLeft__U: ...
    _reduceLeftOption__U = typing.TypeVar('_reduceLeftOption__U')  # <U>
    def reduceLeftOption(self, op: scala.Function2[_reduceLeftOption__U, scala.Tuple2[_ParTrieMap__K, _ParTrieMap__V], _reduceLeftOption__U]) -> scala.Option[_reduceLeftOption__U]: ...
    _reduceOption__U = typing.TypeVar('_reduceOption__U')  # <U>
    def reduceOption(self, op: scala.Function2[_reduceOption__U, _reduceOption__U, _reduceOption__U]) -> scala.Option[_reduceOption__U]: ...
    _reduceRight__U = typing.TypeVar('_reduceRight__U')  # <U>
    def reduceRight(self, op: scala.Function2[scala.Tuple2[_ParTrieMap__K, _ParTrieMap__V], _reduceRight__U, _reduceRight__U]) -> _reduceRight__U: ...
    _reduceRightOption__U = typing.TypeVar('_reduceRightOption__U')  # <U>
    def reduceRightOption(self, op: scala.Function2[scala.Tuple2[_ParTrieMap__K, _ParTrieMap__V], _reduceRightOption__U, _reduceRightOption__U]) -> scala.Option[_reduceRightOption__U]: ...
    def remove(self, key: _ParTrieMap__K) -> scala.Option[_ParTrieMap__V]: ...
    def repr(self) -> scala.collection.parallel.ParIterable: ...
    def result(self) -> 'ParTrieMap'[_ParTrieMap__K, _ParTrieMap__V]: ...
    def resultWithTaskSupport(self) -> typing.Any: ...
    _reuse__S = typing.TypeVar('_reuse__S')  # <S>
    _reuse__That = typing.TypeVar('_reuse__That')  # <That>
    def reuse(self, oldc: scala.Option[scala.collection.parallel.Combiner[_reuse__S, _reuse__That]], newc: scala.collection.parallel.Combiner[_reuse__S, _reuse__That]) -> scala.collection.parallel.Combiner[_reuse__S, _reuse__That]: ...
    _sameElements__U = typing.TypeVar('_sameElements__U')  # <U>
    def sameElements(self, that: scala.collection.GenIterable[_sameElements__U]) -> bool: ...
    def scala$collection$parallel$ParIterableLike$$_tasksupport(self) -> scala.collection.parallel.TaskSupport: ...
    def scala$collection$parallel$ParIterableLike$$_tasksupport_$eq(self, x$1: scala.collection.parallel.TaskSupport) -> None: ...
    def scala$collection$parallel$mutable$ParTrieMap$$ctrie(self) -> scala.collection.concurrent.TrieMap[_ParTrieMap__K, _ParTrieMap__V]: ...
    _scan__U = typing.TypeVar('_scan__U')  # <U>
    _scan__That = typing.TypeVar('_scan__That')  # <That>
    def scan(self, z: _scan__U, op: scala.Function2[_scan__U, _scan__U, _scan__U], bf: scala.collection.generic.CanBuildFrom['ParTrieMap'[_ParTrieMap__K, _ParTrieMap__V], _scan__U, _scan__That]) -> _scan__That: ...
    def scanBlockSize(self) -> int: ...
    _scanLeft__S = typing.TypeVar('_scanLeft__S')  # <S>
    _scanLeft__That = typing.TypeVar('_scanLeft__That')  # <That>
    def scanLeft(self, z: _scanLeft__S, op: scala.Function2[_scanLeft__S, scala.Tuple2[_ParTrieMap__K, _ParTrieMap__V], _scanLeft__S], bf: scala.collection.generic.CanBuildFrom['ParTrieMap'[_ParTrieMap__K, _ParTrieMap__V], _scanLeft__S, _scanLeft__That]) -> _scanLeft__That: ...
    _scanRight__S = typing.TypeVar('_scanRight__S')  # <S>
    _scanRight__That = typing.TypeVar('_scanRight__That')  # <That>
    def scanRight(self, z: _scanRight__S, op: scala.Function2[scala.Tuple2[_ParTrieMap__K, _ParTrieMap__V], _scanRight__S, _scanRight__S], bf: scala.collection.generic.CanBuildFrom['ParTrieMap'[_ParTrieMap__K, _ParTrieMap__V], _scanRight__S, _scanRight__That]) -> _scanRight__That: ...
    def seq(self) -> scala.collection.concurrent.TrieMap[_ParTrieMap__K, _ParTrieMap__V]: ...
    def sequentially(self, b: scala.Function1) -> scala.collection.parallel.ParIterable: ...
    def size(self) -> int: ...
    @typing.overload
    def sizeHint(self, size: int) -> None: ...
    @typing.overload
    def sizeHint(self, coll: scala.collection.TraversableLike[typing.Any, typing.Any]) -> None: ...
    @typing.overload
    def sizeHint(self, coll: scala.collection.TraversableLike[typing.Any, typing.Any], delta: int) -> None: ...
    def sizeHintBounded(self, size: int, boundingColl: scala.collection.TraversableLike[typing.Any, typing.Any]) -> None: ...
    def sizeHintIfCheap(self) -> int: ...
    def slice(self, unc_from: int, unc_until: int) -> scala.collection.parallel.ParIterable: ...
    def span(self, pred: scala.Function1[scala.Tuple2[_ParTrieMap__K, _ParTrieMap__V], typing.Any]) -> scala.Tuple2['ParTrieMap'[_ParTrieMap__K, _ParTrieMap__V], 'ParTrieMap'[_ParTrieMap__K, _ParTrieMap__V]]: ...
    def splitAt(self, n: int) -> scala.Tuple2['ParTrieMap'[_ParTrieMap__K, _ParTrieMap__V], 'ParTrieMap'[_ParTrieMap__K, _ParTrieMap__V]]: ...
    def splitter(self) -> ParTrieMapSplitter[_ParTrieMap__K, _ParTrieMap__V]: ...
    def stringPrefix(self) -> str: ...
    _sum__U = typing.TypeVar('_sum__U')  # <U>
    def sum(self, num: scala.math.Numeric[_sum__U]) -> _sum__U: ...
    def tail(self) -> scala.collection.parallel.ParIterable: ...
    def take(self, n: int) -> scala.collection.parallel.ParIterable: ...
    def takeWhile(self, pred: scala.Function1) -> scala.collection.parallel.ParIterable: ...
    _task2ops__R = typing.TypeVar('_task2ops__R')  # <R>
    _task2ops__Tp = typing.TypeVar('_task2ops__Tp')  # <Tp>
    def task2ops(self, tsk: scala.collection.parallel.ParIterableLike.StrictSplitterCheckTask[_task2ops__R, _task2ops__Tp]) -> scala.collection.parallel.ParIterableLike.TaskOps[_task2ops__R, _task2ops__Tp]: ...
    def tasksupport(self) -> scala.collection.parallel.TaskSupport: ...
    def tasksupport_$eq(self, ts: scala.collection.parallel.TaskSupport) -> None: ...
    _to__Col = typing.TypeVar('_to__Col')  # <Col>
    def to(self, cbf: scala.collection.generic.CanBuildFrom[scala.runtime.Nothing., scala.Tuple2[_ParTrieMap__K, _ParTrieMap__V], _to__Col]) -> _to__Col: ...
    _toArray__U = typing.TypeVar('_toArray__U')  # <U>
    def toArray(self, evidence$1: scala.reflect.ClassTag[_toArray__U]) -> typing.Any: ...
    _toBuffer__U = typing.TypeVar('_toBuffer__U')  # <U>
    def toBuffer(self) -> scala.collection.mutable.Buffer[_toBuffer__U]: ...
    def toIndexedSeq(self) -> scala.collection.immutable.IndexedSeq[scala.Tuple2[_ParTrieMap__K, _ParTrieMap__V]]: ...
    def toIterable(self) -> ParIterable[scala.Tuple2[_ParTrieMap__K, _ParTrieMap__V]]: ...
    def toIterator(self) -> scala.collection.Iterator[scala.Tuple2[_ParTrieMap__K, _ParTrieMap__V]]: ...
    def toList(self) -> scala.collection.immutable.List[scala.Tuple2[_ParTrieMap__K, _ParTrieMap__V]]: ...
    _toMap__K = typing.TypeVar('_toMap__K')  # <K>
    _toMap__V = typing.TypeVar('_toMap__V')  # <V>
    def toMap(self, ev: scala.Predef..less.colon.less[scala.Tuple2[typing.Any, typing.Any], scala.Tuple2[typing.Any, typing.Any]]) -> scala.collection.parallel.immutable.ParMap[typing.Any, typing.Any]: ...
    _toParCollection__U = typing.TypeVar('_toParCollection__U')  # <U>
    _toParCollection__That = typing.TypeVar('_toParCollection__That')  # <That>
    def toParCollection(self, cbf: scala.Function0[scala.collection.parallel.Combiner[_toParCollection__U, _toParCollection__That]]) -> _toParCollection__That: ...
    _toParMap__K = typing.TypeVar('_toParMap__K')  # <K>
    _toParMap__V = typing.TypeVar('_toParMap__V')  # <V>
    _toParMap__That = typing.TypeVar('_toParMap__That')  # <That>
    def toParMap(self, cbf: scala.Function0[scala.collection.parallel.Combiner[scala.Tuple2[typing.Any, typing.Any], _toParMap__That]], ev: scala.Predef..less.colon.less[scala.Tuple2[typing.Any, typing.Any], scala.Tuple2[typing.Any, typing.Any]]) -> _toParMap__That: ...
    def toSeq(self) -> ParSeq[scala.Tuple2[_ParTrieMap__K, _ParTrieMap__V]]: ...
    _toSet__U = typing.TypeVar('_toSet__U')  # <U>
    def toSet(self) -> scala.collection.parallel.immutable.ParSet[_toSet__U]: ...
    def toStream(self) -> scala.collection.immutable.Stream[scala.Tuple2[_ParTrieMap__K, _ParTrieMap__V]]: ...
    def toString(self) -> str: ...
    def toTraversable(self) -> scala.collection.GenTraversable[scala.Tuple2[_ParTrieMap__K, _ParTrieMap__V]]: ...
    def toVector(self) -> scala.collection.immutable.Vector[scala.Tuple2[_ParTrieMap__K, _ParTrieMap__V]]: ...
    def transpose(self, asTraversable: scala.Function1) -> scala.collection.GenTraversable: ...
    _unzip__A1 = typing.TypeVar('_unzip__A1')  # <A1>
    _unzip__A2 = typing.TypeVar('_unzip__A2')  # <A2>
    def unzip(self, asPair: scala.Function1[scala.Tuple2[_ParTrieMap__K, _ParTrieMap__V], scala.Tuple2[_unzip__A1, _unzip__A2]]) -> scala.Tuple2[ParIterable[_unzip__A1], ParIterable[_unzip__A2]]: ...
    _unzip3__A1 = typing.TypeVar('_unzip3__A1')  # <A1>
    _unzip3__A2 = typing.TypeVar('_unzip3__A2')  # <A2>
    _unzip3__A3 = typing.TypeVar('_unzip3__A3')  # <A3>
    def unzip3(self, asTriple: scala.Function1[scala.Tuple2[_ParTrieMap__K, _ParTrieMap__V], scala.Tuple3[_unzip3__A1, _unzip3__A2, _unzip3__A3]]) -> scala.Tuple3[ParIterable[_unzip3__A1], ParIterable[_unzip3__A2], ParIterable[_unzip3__A3]]: ...
    def update(self, key: _ParTrieMap__K, value: _ParTrieMap__V) -> None: ...
    _updated__U = typing.TypeVar('_updated__U')  # <U>
    def updated(self, key: _ParTrieMap__K, value: _updated__U) -> ParMap[_ParTrieMap__K, _updated__U]: ...
    def values(self) -> scala.collection.parallel.ParIterable[_ParTrieMap__V]: ...
    def valuesIterator(self) -> scala.collection.parallel.IterableSplitter[_ParTrieMap__V]: ...
    def view(self) -> scala.collection.IterableView[scala.Tuple2[_ParTrieMap__K, _ParTrieMap__V], scala.collection.concurrent.TrieMap[_ParTrieMap__K, _ParTrieMap__V]]: ...
    def withDefault(self, d: scala.Function1[_ParTrieMap__K, _ParTrieMap__V]) -> ParMap[_ParTrieMap__K, _ParTrieMap__V]: ...
    def withDefaultValue(self, d: _ParTrieMap__V) -> ParMap[_ParTrieMap__K, _ParTrieMap__V]: ...
    def withFilter(self, pred: scala.Function1) -> scala.collection.parallel.ParIterable: ...
    _wrap__R = typing.TypeVar('_wrap__R')  # <R>
    def wrap(self, body: scala.Function0[_wrap__R]) -> scala.collection.parallel.ParIterableLike.NonDivisible[_wrap__R]: ...
    _zip__U = typing.TypeVar('_zip__U')  # <U>
    _zip__S = typing.TypeVar('_zip__S')  # <S>
    _zip__That = typing.TypeVar('_zip__That')  # <That>
    def zip(self, that: scala.collection.GenIterable[_zip__S], bf: scala.collection.generic.CanBuildFrom['ParTrieMap'[_ParTrieMap__K, _ParTrieMap__V], scala.Tuple2[_zip__U, _zip__S], _zip__That]) -> _zip__That: ...
    _zipAll__S = typing.TypeVar('_zipAll__S')  # <S>
    _zipAll__U = typing.TypeVar('_zipAll__U')  # <U>
    _zipAll__That = typing.TypeVar('_zipAll__That')  # <That>
    def zipAll(self, that: scala.collection.GenIterable[_zipAll__S], thisElem: _zipAll__U, thatElem: _zipAll__S, bf: scala.collection.generic.CanBuildFrom['ParTrieMap'[_ParTrieMap__K, _ParTrieMap__V], scala.Tuple2[_zipAll__U, _zipAll__S], _zipAll__That]) -> _zipAll__That: ...
    _zipWithIndex__U = typing.TypeVar('_zipWithIndex__U')  # <U>
    _zipWithIndex__That = typing.TypeVar('_zipWithIndex__That')  # <That>
    def zipWithIndex(self, bf: scala.collection.generic.CanBuildFrom['ParTrieMap'[_ParTrieMap__K, _ParTrieMap__V], scala.Tuple2[_zipWithIndex__U, typing.Any], _zipWithIndex__That]) -> _zipWithIndex__That: ...
    class Size(scala.collection.parallel.Task[typing.Any, 'ParTrieMap.Size']):
        $outer: 'ParTrieMap' = ...
        def __init__(self, $outer: 'ParTrieMap', offset: int, howmany: int, array: typing.List[scala.collection.concurrent.BasicNode]): ...
        def forwardThrowable(self) -> None: ...
        def leaf(self, prev: scala.Option[typing.Any]) -> None: ...
        def merge(self, that: 'ParTrieMap.Size') -> None: ...
        def mergeThrowables(self, that: scala.collection.parallel.Task[typing.Any, typing.Any]) -> None: ...
        def repr(self) -> typing.Any: ...
        def result(self) -> int: ...
        def result_$eq(self, x$1: int) -> None: ...
        def shouldSplitFurther(self) -> bool: ...
        def signalAbort(self) -> None: ...
        def split(self) -> scala.collection.Seq['ParTrieMap.Size']: ...
        def throwable(self) -> java.lang.Throwable: ...
        def throwable_$eq(self, x$1: java.lang.Throwable) -> None: ...
        def tryLeaf(self, lastres: scala.Option[typing.Any]) -> None: ...
        def tryMerge(self, t: typing.Any) -> None: ...


class __module_protocol__(typing.Protocol):
    # A module protocol which reflects the result of ``jp.JPackage("scala.collection.parallel.mutable")``.

    ExposedArrayBuffer: typing.Type[ExposedArrayBuffer]
    ExposedArraySeq: typing.Type[ExposedArraySeq]
    LazyCombiner: typing.Type[LazyCombiner]
    ParArray: typing.Type[ParArray]
    ParFlatHashTable: typing.Type[ParFlatHashTable]
    ParHashMap: typing.Type[ParHashMap]
    ParHashMapCombiner: typing.Type[ParHashMapCombiner]
    ParHashSet: typing.Type[ParHashSet]
    ParHashSetCombiner: typing.Type[ParHashSetCombiner]
    ParHashTable: typing.Type[ParHashTable]
    ParIterable: typing.Type[ParIterable]
    ParMap: typing.Type[ParMap]
    ParMapLike: typing.Type[ParMapLike]
    ParSeq: typing.Type[ParSeq]
    ParSet: typing.Type[ParSet]
    ParSetLike: typing.Type[ParSetLike]
    ParTrieMap: typing.Type[ParTrieMap]
    ParTrieMapCombiner: typing.Type[ParTrieMapCombiner]
    ParTrieMapSplitter: typing.Type[ParTrieMapSplitter]
    ResizableParArrayCombiner: typing.Type[ResizableParArrayCombiner]
    SizeMapUtils: typing.Type[SizeMapUtils]
    UnrolledParArrayCombiner: typing.Type[UnrolledParArrayCombiner]
    package: typing.Type[package]
