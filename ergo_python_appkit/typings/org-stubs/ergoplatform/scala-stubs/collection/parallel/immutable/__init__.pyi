import java.lang
import java.util.concurrent.atomic
import scala
import scala.collection
import scala.collection.generic
import scala.collection.immutable
import scala.collection.mutable
import scala.collection.parallel
import scala.math
import scala.reflect
import scala.runtime
import typing



_HashMapCombiner__CreateGroupedTrie__Repr = typing.TypeVar('_HashMapCombiner__CreateGroupedTrie__Repr')  # <Repr>
_HashMapCombiner__K = typing.TypeVar('_HashMapCombiner__K')  # <K>
_HashMapCombiner__V = typing.TypeVar('_HashMapCombiner__V')  # <V>
class HashMapCombiner(scala.collection.parallel.BucketCombiner[scala.Tuple2[_HashMapCombiner__K, _HashMapCombiner__V], 'ParHashMap'[_HashMapCombiner__K, _HashMapCombiner__V], scala.Tuple2[_HashMapCombiner__K, _HashMapCombiner__V], 'HashMapCombiner'[_HashMapCombiner__K, _HashMapCombiner__V]], typing.Generic[_HashMapCombiner__K, _HashMapCombiner__V]):
    def __init__(self): ...
    @typing.overload
    def $plus$eq(self, elem1: typing.Any, elem2: typing.Any, elems: scala.collection.Seq[typing.Any]) -> scala.collection.generic.Growable[typing.Any]: ...
    @typing.overload
    def $plus$eq(self, elem: scala.Tuple2[_HashMapCombiner__K, _HashMapCombiner__V]) -> 'HashMapCombiner'[_HashMapCombiner__K, _HashMapCombiner__V]: ...
    _apply__K = typing.TypeVar('_apply__K')  # <K>
    _apply__V = typing.TypeVar('_apply__V')  # <V>
    @staticmethod
    def apply() -> 'HashMapCombiner'[_apply__K, _apply__V]: ...
    def emptyTrie(self) -> scala.collection.immutable.HashMap[_HashMapCombiner__K, _HashMapCombiner__V]: ...
    _groupByKey__Repr = typing.TypeVar('_groupByKey__Repr')  # <Repr>
    def groupByKey(self, cbf: scala.Function0[scala.collection.parallel.Combiner[_HashMapCombiner__V, _groupByKey__Repr]]) -> 'ParHashMap'[_HashMapCombiner__K, _groupByKey__Repr]: ...
    def result(self) -> 'ParHashMap'[_HashMapCombiner__K, _HashMapCombiner__V]: ...
    def toString(self) -> java.lang.String: ...
    class CreateGroupedTrie(scala.collection.parallel.Task[scala.runtime.BoxedUnit, 'HashMapCombiner.CreateGroupedTrie'[_HashMapCombiner__CreateGroupedTrie__Repr]], typing.Generic[_HashMapCombiner__CreateGroupedTrie__Repr]):
        $outer: 'HashMapCombiner' = ...
        def __init__(self, $outer: 'HashMapCombiner', cbf: scala.Function0[scala.collection.parallel.Combiner[_HashMapCombiner__V, _HashMapCombiner__CreateGroupedTrie__Repr]], bucks: typing.List[scala.collection.mutable.UnrolledBuffer.Unrolled[scala.Tuple2[_HashMapCombiner__K, _HashMapCombiner__V]]], root: typing.List[scala.collection.immutable.HashMap[_HashMapCombiner__K, typing.Any]], offset: int, howmany: int): ...
        def forwardThrowable(self) -> None: ...
        def leaf(self, prev: scala.Option[scala.runtime.BoxedUnit]) -> None: ...
        def merge(self, that: typing.Any) -> None: ...
        def mergeThrowables(self, that: scala.collection.parallel.Task[typing.Any, typing.Any]) -> None: ...
        def repr(self) -> typing.Any: ...
        def result(self) -> None: ...
        def result_$eq(self, x$1: scala.runtime.BoxedUnit) -> None: ...
        def shouldSplitFurther(self) -> bool: ...
        def signalAbort(self) -> None: ...
        def split(self) -> scala.collection.immutable.List['HashMapCombiner.CreateGroupedTrie'[_HashMapCombiner__CreateGroupedTrie__Repr]]: ...
        def throwable(self) -> java.lang.Throwable: ...
        def throwable_$eq(self, x$1: java.lang.Throwable) -> None: ...
        def tryLeaf(self, lastres: scala.Option[scala.runtime.BoxedUnit]) -> None: ...
        def tryMerge(self, t: typing.Any) -> None: ...
    class CreateTrie(scala.collection.parallel.Task[scala.runtime.BoxedUnit, 'HashMapCombiner.CreateTrie']):
        $outer: 'HashMapCombiner' = ...
        def __init__(self, $outer: 'HashMapCombiner', bucks: typing.List[scala.collection.mutable.UnrolledBuffer.Unrolled[scala.Tuple2[_HashMapCombiner__K, _HashMapCombiner__V]]], root: typing.List[scala.collection.immutable.HashMap[_HashMapCombiner__K, _HashMapCombiner__V]], offset: int, howmany: int): ...
        def forwardThrowable(self) -> None: ...
        def leaf(self, prev: scala.Option[scala.runtime.BoxedUnit]) -> None: ...
        def merge(self, that: typing.Any) -> None: ...
        def mergeThrowables(self, that: scala.collection.parallel.Task[typing.Any, typing.Any]) -> None: ...
        def repr(self) -> typing.Any: ...
        def result(self) -> None: ...
        def result_$eq(self, x$1: scala.runtime.BoxedUnit) -> None: ...
        def shouldSplitFurther(self) -> bool: ...
        def signalAbort(self) -> None: ...
        def split(self) -> scala.collection.immutable.List['HashMapCombiner.CreateTrie']: ...
        def throwable(self) -> java.lang.Throwable: ...
        def throwable_$eq(self, x$1: java.lang.Throwable) -> None: ...
        def tryLeaf(self, lastres: scala.Option[scala.runtime.BoxedUnit]) -> None: ...
        def tryMerge(self, t: typing.Any) -> None: ...

_HashSetCombiner__T = typing.TypeVar('_HashSetCombiner__T')  # <T>
class HashSetCombiner(scala.collection.parallel.BucketCombiner[_HashSetCombiner__T, 'ParHashSet'[_HashSetCombiner__T], typing.Any, 'HashSetCombiner'[_HashSetCombiner__T]], typing.Generic[_HashSetCombiner__T]):
    def __init__(self): ...
    @typing.overload
    def $plus$eq(self, elem1: typing.Any, elem2: typing.Any, elems: scala.collection.Seq[typing.Any]) -> scala.collection.generic.Growable[typing.Any]: ...
    @typing.overload
    def $plus$eq(self, elem: _HashSetCombiner__T) -> 'HashSetCombiner'[_HashSetCombiner__T]: ...
    _apply__T = typing.TypeVar('_apply__T')  # <T>
    @staticmethod
    def apply() -> 'HashSetCombiner'[_apply__T]: ...
    def emptyTrie(self) -> scala.collection.immutable.HashSet[_HashSetCombiner__T]: ...
    def result(self) -> 'ParHashSet'[_HashSetCombiner__T]: ...
    class CreateTrie(scala.collection.parallel.Task[scala.runtime.BoxedUnit, 'HashSetCombiner.CreateTrie']):
        $outer: 'HashSetCombiner' = ...
        def __init__(self, $outer: 'HashSetCombiner', bucks: typing.List[scala.collection.mutable.UnrolledBuffer.Unrolled[typing.Any]], root: typing.List[scala.collection.immutable.HashSet[_HashSetCombiner__T]], offset: int, howmany: int): ...
        def forwardThrowable(self) -> None: ...
        def leaf(self, prev: scala.Option[scala.runtime.BoxedUnit]) -> None: ...
        def merge(self, that: typing.Any) -> None: ...
        def mergeThrowables(self, that: scala.collection.parallel.Task[typing.Any, typing.Any]) -> None: ...
        def repr(self) -> typing.Any: ...
        def result(self) -> None: ...
        def result_$eq(self, x$1: scala.runtime.BoxedUnit) -> None: ...
        def shouldSplitFurther(self) -> bool: ...
        def signalAbort(self) -> None: ...
        def split(self) -> scala.collection.immutable.List['HashSetCombiner.CreateTrie']: ...
        def throwable(self) -> java.lang.Throwable: ...
        def throwable_$eq(self, x$1: java.lang.Throwable) -> None: ...
        def tryLeaf(self, lastres: scala.Option[scala.runtime.BoxedUnit]) -> None: ...
        def tryMerge(self, t: typing.Any) -> None: ...

_LazyParVectorCombiner__T = typing.TypeVar('_LazyParVectorCombiner__T')  # <T>
class LazyParVectorCombiner(scala.collection.parallel.Combiner[_LazyParVectorCombiner__T, 'ParVector'[_LazyParVectorCombiner__T]], typing.Generic[_LazyParVectorCombiner__T]):
    def __init__(self): ...
    @typing.overload
    def $plus$eq(self, elem1: _LazyParVectorCombiner__T, elem2: _LazyParVectorCombiner__T, elems: scala.collection.Seq[_LazyParVectorCombiner__T]) -> scala.collection.generic.Growable[_LazyParVectorCombiner__T]: ...
    @typing.overload
    def $plus$eq(self, elem: _LazyParVectorCombiner__T) -> 'LazyParVectorCombiner'[_LazyParVectorCombiner__T]: ...
    def $plus$plus$eq(self, xs: scala.collection.TraversableOnce[_LazyParVectorCombiner__T]) -> scala.collection.generic.Growable[_LazyParVectorCombiner__T]: ...
    def _combinerTaskSupport(self) -> scala.collection.parallel.TaskSupport: ...
    def _combinerTaskSupport_$eq(self, x$1: scala.collection.parallel.TaskSupport) -> None: ...
    def canBeShared(self) -> bool: ...
    def clear(self) -> None: ...
    _combine__U = typing.TypeVar('_combine__U')  # <U>
    _combine__NewTo = typing.TypeVar('_combine__NewTo')  # <NewTo>
    def combine(self, other: scala.collection.parallel.Combiner[_combine__U, _combine__NewTo]) -> scala.collection.parallel.Combiner[_combine__U, _combine__NewTo]: ...
    def combinerTaskSupport(self) -> scala.collection.parallel.TaskSupport: ...
    def combinerTaskSupport_$eq(self, cts: scala.collection.parallel.TaskSupport) -> None: ...
    _mapResult__NewTo = typing.TypeVar('_mapResult__NewTo')  # <NewTo>
    def mapResult(self, f: scala.Function1['ParVector'[_LazyParVectorCombiner__T], _mapResult__NewTo]) -> scala.collection.mutable.Builder[_LazyParVectorCombiner__T, _mapResult__NewTo]: ...
    def result(self) -> 'ParVector'[_LazyParVectorCombiner__T]: ...
    def resultWithTaskSupport(self) -> typing.Any: ...
    def size(self) -> int: ...
    @typing.overload
    def sizeHint(self, size: int) -> None: ...
    @typing.overload
    def sizeHint(self, coll: scala.collection.TraversableLike[typing.Any, typing.Any]) -> None: ...
    @typing.overload
    def sizeHint(self, coll: scala.collection.TraversableLike[typing.Any, typing.Any], delta: int) -> None: ...
    def sizeHintBounded(self, size: int, boundingColl: scala.collection.TraversableLike[typing.Any, typing.Any]) -> None: ...
    def sz(self) -> int: ...
    def sz_$eq(self, x$1: int) -> None: ...
    def vectors(self) -> scala.collection.mutable.ArrayBuffer[scala.collection.immutable.VectorBuilder[_LazyParVectorCombiner__T]]: ...

_ParIterable__T = typing.TypeVar('_ParIterable__T')  # <T>
class ParIterable(scala.collection.parallel.ParIterable[_ParIterable__T], scala.Immutable, typing.Generic[_ParIterable__T]):
    @staticmethod
    def $init$($this: 'ParIterable') -> None: ...
    @staticmethod
    def ReusableCBF() -> scala.collection.generic.GenTraversableFactory.GenericCanBuildFrom[scala.runtime.Nothing.]: ...
    @staticmethod
    def apply(elems: scala.collection.Seq) -> scala.collection.GenTraversable: ...
    _canBuildFrom__T = typing.TypeVar('_canBuildFrom__T')  # <T>
    @staticmethod
    def canBuildFrom() -> scala.collection.generic.CanCombineFrom['ParIterable'[typing.Any], _canBuildFrom__T, 'ParIterable'[_canBuildFrom__T]]: ...
    def companion(self) -> scala.collection.generic.GenericCompanion['ParIterable']: ...
    @staticmethod
    def concat(xss: scala.collection.Seq) -> scala.collection.GenTraversable: ...
    @staticmethod
    def empty() -> scala.collection.GenTraversable: ...
    @typing.overload
    @staticmethod
    def fill(n1: int, n2: int, n3: int, n4: int, n5: int, elem: scala.Function0) -> scala.collection.GenTraversable: ...
    @typing.overload
    @staticmethod
    def fill(n1: int, n2: int, n3: int, n4: int, elem: scala.Function0) -> scala.collection.GenTraversable: ...
    @typing.overload
    @staticmethod
    def fill(n1: int, n2: int, n3: int, elem: scala.Function0) -> scala.collection.GenTraversable: ...
    @typing.overload
    @staticmethod
    def fill(n1: int, n2: int, elem: scala.Function0) -> scala.collection.GenTraversable: ...
    @typing.overload
    @staticmethod
    def fill(n: int, elem: scala.Function0) -> scala.collection.GenTraversable: ...
    @staticmethod
    def iterate(start: typing.Any, len: int, f: scala.Function1) -> scala.collection.GenTraversable: ...
    @typing.overload
    @staticmethod
    def range(start: typing.Any, end: typing.Any, step: typing.Any, evidence$2: scala.math.Integral) -> scala.collection.GenTraversable: ...
    @typing.overload
    @staticmethod
    def range(start: typing.Any, end: typing.Any, evidence$1: scala.math.Integral) -> scala.collection.GenTraversable: ...
    @typing.overload
    @staticmethod
    def tabulate(n1: int, n2: int, n3: int, n4: int, n5: int, f: scala.Function5) -> scala.collection.GenTraversable: ...
    @typing.overload
    @staticmethod
    def tabulate(n1: int, n2: int, n3: int, n4: int, f: scala.Function4) -> scala.collection.GenTraversable: ...
    @typing.overload
    @staticmethod
    def tabulate(n1: int, n2: int, n3: int, f: scala.Function3) -> scala.collection.GenTraversable: ...
    @typing.overload
    @staticmethod
    def tabulate(n1: int, n2: int, f: scala.Function2) -> scala.collection.GenTraversable: ...
    @typing.overload
    @staticmethod
    def tabulate(n: int, f: scala.Function1) -> scala.collection.GenTraversable: ...
    @typing.overload
    def toIterable(self) -> scala.collection.GenIterable[typing.Any]: ...
    @typing.overload
    def toIterable(self) -> scala.collection.parallel.ParIterable[_ParIterable__T]: ...
    @typing.overload
    def toIterable(self) -> 'ParIterable'[_ParIterable__T]: ...
    @typing.overload
    def toSeq(self) -> scala.collection.GenSeq[typing.Any]: ...
    @typing.overload
    def toSeq(self) -> scala.collection.parallel.ParSeq[_ParIterable__T]: ...
    @typing.overload
    def toSeq(self) -> 'ParSeq'[_ParIterable__T]: ...
    def toString(self) -> java.lang.String: ...

class package:
    _repetition__T = typing.TypeVar('_repetition__T')  # <T>
    @staticmethod
    def repetition(elem: _repetition__T, len: int) -> 'Repetition'[_repetition__T]: ...

_ParSeq__T = typing.TypeVar('_ParSeq__T')  # <T>
class ParSeq(scala.collection.parallel.ParSeq[_ParSeq__T], ParIterable[_ParSeq__T], typing.Generic[_ParSeq__T]):
    @staticmethod
    def $init$($this: 'ParSeq') -> None: ...
    @staticmethod
    def ReusableCBF() -> scala.collection.generic.GenTraversableFactory.GenericCanBuildFrom[scala.runtime.Nothing.]: ...
    _canBuildFrom__T = typing.TypeVar('_canBuildFrom__T')  # <T>
    @staticmethod
    def canBuildFrom() -> scala.collection.generic.CanCombineFrom['ParSeq'[typing.Any], _canBuildFrom__T, 'ParSeq'[_canBuildFrom__T]]: ...
    def companion(self) -> scala.collection.generic.GenericCompanion['ParSeq']: ...
    @staticmethod
    def concat(xss: scala.collection.Seq) -> scala.collection.GenTraversable: ...
    @staticmethod
    def empty() -> scala.collection.GenTraversable: ...
    def equals(self, that: typing.Any) -> bool: ...
    @typing.overload
    @staticmethod
    def fill(n1: int, n2: int, n3: int, n4: int, n5: int, elem: scala.Function0) -> scala.collection.GenTraversable: ...
    @typing.overload
    @staticmethod
    def fill(n1: int, n2: int, n3: int, n4: int, elem: scala.Function0) -> scala.collection.GenTraversable: ...
    @typing.overload
    @staticmethod
    def fill(n1: int, n2: int, n3: int, elem: scala.Function0) -> scala.collection.GenTraversable: ...
    @typing.overload
    @staticmethod
    def fill(n1: int, n2: int, elem: scala.Function0) -> scala.collection.GenTraversable: ...
    @typing.overload
    @staticmethod
    def fill(n: int, elem: scala.Function0) -> scala.collection.GenTraversable: ...
    def hashCode(self) -> int: ...
    @staticmethod
    def iterate(start: typing.Any, len: int, f: scala.Function1) -> scala.collection.GenTraversable: ...
    @typing.overload
    @staticmethod
    def range(start: typing.Any, end: typing.Any, step: typing.Any, evidence$2: scala.math.Integral) -> scala.collection.GenTraversable: ...
    @typing.overload
    @staticmethod
    def range(start: typing.Any, end: typing.Any, evidence$1: scala.math.Integral) -> scala.collection.GenTraversable: ...
    @typing.overload
    @staticmethod
    def tabulate(n1: int, n2: int, n3: int, n4: int, n5: int, f: scala.Function5) -> scala.collection.GenTraversable: ...
    @typing.overload
    @staticmethod
    def tabulate(n1: int, n2: int, n3: int, n4: int, f: scala.Function4) -> scala.collection.GenTraversable: ...
    @typing.overload
    @staticmethod
    def tabulate(n1: int, n2: int, n3: int, f: scala.Function3) -> scala.collection.GenTraversable: ...
    @typing.overload
    @staticmethod
    def tabulate(n1: int, n2: int, f: scala.Function2) -> scala.collection.GenTraversable: ...
    @typing.overload
    @staticmethod
    def tabulate(n: int, f: scala.Function1) -> scala.collection.GenTraversable: ...
    @typing.overload
    def toSeq(self) -> scala.collection.GenSeq[typing.Any]: ...
    @typing.overload
    def toSeq(self) -> scala.collection.parallel.ParSeq[_ParSeq__T]: ...
    @typing.overload
    def toSeq(self) -> 'ParSeq'[_ParSeq__T]: ...
    def toString(self) -> java.lang.String: ...

_ParSet__T = typing.TypeVar('_ParSet__T')  # <T>
class ParSet(scala.collection.parallel.ParSet[_ParSet__T], ParIterable[_ParSet__T], typing.Generic[_ParSet__T]):
    @staticmethod
    def $init$($this: 'ParSet') -> None: ...
    _canBuildFrom__T = typing.TypeVar('_canBuildFrom__T')  # <T>
    @staticmethod
    def canBuildFrom() -> scala.collection.generic.CanCombineFrom['ParSet'[typing.Any], _canBuildFrom__T, 'ParSet'[_canBuildFrom__T]]: ...
    def companion(self) -> scala.collection.generic.GenericCompanion['ParSet']: ...
    @typing.overload
    def empty(self) -> scala.collection.GenSet: ...
    @typing.overload
    def empty(self) -> scala.collection.parallel.ParSet[_ParSet__T]: ...
    @typing.overload
    def empty(self) -> 'ParSet'[_ParSet__T]: ...
    def equals(self, that: typing.Any) -> bool: ...
    def hashCode(self) -> int: ...
    _setCanBuildFrom__A = typing.TypeVar('_setCanBuildFrom__A')  # <A>
    @staticmethod
    def setCanBuildFrom() -> scala.collection.generic.CanBuildFrom['ParSet'[typing.Any], _setCanBuildFrom__A, 'ParSet'[_setCanBuildFrom__A]]: ...
    def stringPrefix(self) -> java.lang.String: ...
    _toSet_0__A1 = typing.TypeVar('_toSet_0__A1')  # <A1>
    _toSet_1__U = typing.TypeVar('_toSet_1__U')  # <U>
    @typing.overload
    def toSet(self) -> scala.collection.GenSet[_toSet_0__A1]: ...
    @typing.overload
    def toSet(self) -> 'ParSet'[_toSet_1__U]: ...
    @typing.overload
    def toString(self) -> java.lang.String: ...
    @typing.overload
    def toString(self) -> java.lang.String: ...

_ParHashSet__T = typing.TypeVar('_ParHashSet__T')  # <T>
class ParHashSet(ParSet[_ParHashSet__T], scala.Serializable, typing.Generic[_ParHashSet__T]):
    serialVersionUID: typing.ClassVar[int] = ...
    @typing.overload
    def __init__(self): ...
    @typing.overload
    def __init__(self, trie: scala.collection.immutable.HashSet[_ParHashSet__T]): ...
    def $amp(self, that: scala.collection.GenSet) -> typing.Any: ...
    def $amp$tilde(self, that: scala.collection.GenSet) -> typing.Any: ...
    def $bar(self, that: scala.collection.GenSet) -> typing.Any: ...
    _$colon$bslash__S = typing.TypeVar('_$colon$bslash__S')  # <S>
    def $colon$bslash(self, z: _.colon.bslash__S, op: scala.Function2[_ParHashSet__T, _.colon.bslash__S, _.colon.bslash__S]) -> _.colon.bslash__S: ...
    _$div$colon__S = typing.TypeVar('_$div$colon__S')  # <S>
    def $div$colon(self, z: _.div.colon__S, op: scala.Function2[_.div.colon__S, _ParHashSet__T, _.div.colon__S]) -> _.div.colon__S: ...
    def $minus(self, e: _ParHashSet__T) -> 'ParHashSet'[_ParHashSet__T]: ...
    def $plus(self, e: _ParHashSet__T) -> 'ParHashSet'[_ParHashSet__T]: ...
    _$plus$plus__U = typing.TypeVar('_$plus$plus__U')  # <U>
    _$plus$plus__That = typing.TypeVar('_$plus$plus__That')  # <That>
    def $plus$plus(self, that: scala.collection.GenTraversableOnce[_.plus.plus__U], bf: scala.collection.generic.CanBuildFrom['ParHashSet'[_ParHashSet__T], _.plus.plus__U, _.plus.plus__That]) -> _.plus.plus__That: ...
    def ScanLeaf(self) -> scala.collection.parallel.ParIterableLike.ScanLeaf.: ...
    def ScanNode(self) -> scala.collection.parallel.ParIterableLike.ScanNode.: ...
    _aggregate__S = typing.TypeVar('_aggregate__S')  # <S>
    def aggregate(self, z: scala.Function0[_aggregate__S], seqop: scala.Function2[_aggregate__S, _ParHashSet__T, _aggregate__S], combop: scala.Function2[_aggregate__S, _aggregate__S, _aggregate__S]) -> _aggregate__S: ...
    _andThen__A = typing.TypeVar('_andThen__A')  # <A>
    def andThen(self, g: scala.Function1[typing.Any, _andThen__A]) -> scala.Function1[_ParHashSet__T, _andThen__A]: ...
    def apply(self, elem: _ParHashSet__T) -> bool: ...
    def apply$mcDD$sp(self, v1: float) -> float: ...
    def apply$mcDF$sp(self, v1: float) -> float: ...
    def apply$mcDI$sp(self, v1: int) -> float: ...
    def apply$mcDJ$sp(self, v1: int) -> float: ...
    def apply$mcFD$sp(self, v1: float) -> float: ...
    def apply$mcFF$sp(self, v1: float) -> float: ...
    def apply$mcFI$sp(self, v1: int) -> float: ...
    def apply$mcFJ$sp(self, v1: int) -> float: ...
    def apply$mcID$sp(self, v1: float) -> int: ...
    def apply$mcIF$sp(self, v1: float) -> int: ...
    def apply$mcII$sp(self, v1: int) -> int: ...
    def apply$mcIJ$sp(self, v1: int) -> int: ...
    def apply$mcJD$sp(self, v1: float) -> int: ...
    def apply$mcJF$sp(self, v1: float) -> int: ...
    def apply$mcJI$sp(self, v1: int) -> int: ...
    def apply$mcJJ$sp(self, v1: int) -> int: ...
    def apply$mcVD$sp(self, v1: float) -> None: ...
    def apply$mcVF$sp(self, v1: float) -> None: ...
    def apply$mcVI$sp(self, v1: int) -> None: ...
    def apply$mcVJ$sp(self, v1: int) -> None: ...
    def apply$mcZD$sp(self, v1: float) -> bool: ...
    def apply$mcZF$sp(self, v1: float) -> bool: ...
    def apply$mcZI$sp(self, v1: int) -> bool: ...
    def apply$mcZJ$sp(self, v1: int) -> bool: ...
    _bf2seq__S = typing.TypeVar('_bf2seq__S')  # <S>
    _bf2seq__That = typing.TypeVar('_bf2seq__That')  # <That>
    def bf2seq(self, bf: scala.collection.generic.CanBuildFrom['ParHashSet'[_ParHashSet__T], _bf2seq__S, _bf2seq__That]) -> scala.collection.generic.CanBuildFrom[scala.collection.immutable.HashSet[_ParHashSet__T], _bf2seq__S, _bf2seq__That]: ...
    def brokenInvariants(self) -> scala.collection.Seq[java.lang.String]: ...
    _builder2ops__Elem = typing.TypeVar('_builder2ops__Elem')  # <Elem>
    _builder2ops__To = typing.TypeVar('_builder2ops__To')  # <To>
    def builder2ops(self, cb: scala.collection.mutable.Builder[_builder2ops__Elem, _builder2ops__To]) -> scala.collection.parallel.ParIterableLike.BuilderOps[_builder2ops__Elem, _builder2ops__To]: ...
    _canBuildFrom__T = typing.TypeVar('_canBuildFrom__T')  # <T>
    @staticmethod
    def canBuildFrom() -> scala.collection.generic.CanCombineFrom['ParHashSet'[typing.Any], _canBuildFrom__T, 'ParHashSet'[_canBuildFrom__T]]: ...
    def canEqual(self, other: typing.Any) -> bool: ...
    _collect__S = typing.TypeVar('_collect__S')  # <S>
    _collect__That = typing.TypeVar('_collect__That')  # <That>
    def collect(self, pf: scala.PartialFunction[_ParHashSet__T, _collect__S], bf: scala.collection.generic.CanBuildFrom['ParHashSet'[_ParHashSet__T], _collect__S, _collect__That]) -> _collect__That: ...
    _combinerFactory_1__S = typing.TypeVar('_combinerFactory_1__S')  # <S>
    _combinerFactory_1__That = typing.TypeVar('_combinerFactory_1__That')  # <That>
    @typing.overload
    def combinerFactory(self) -> scala.collection.parallel.CombinerFactory[_ParHashSet__T, 'ParHashSet'[_ParHashSet__T]]: ...
    @typing.overload
    def combinerFactory(self, cbf: scala.Function0[scala.collection.parallel.Combiner[_combinerFactory_1__S, _combinerFactory_1__That]]) -> scala.collection.parallel.CombinerFactory[_combinerFactory_1__S, _combinerFactory_1__That]: ...
    def companion(self) -> scala.collection.generic.GenericCompanion['ParHashSet']: ...
    _compose__A = typing.TypeVar('_compose__A')  # <A>
    def compose(self, g: scala.Function1[_compose__A, _ParHashSet__T]) -> scala.Function1[_compose__A, typing.Any]: ...
    def contains(self, e: _ParHashSet__T) -> bool: ...
    _copyToArray_0__U = typing.TypeVar('_copyToArray_0__U')  # <U>
    _copyToArray_1__U = typing.TypeVar('_copyToArray_1__U')  # <U>
    _copyToArray_2__U = typing.TypeVar('_copyToArray_2__U')  # <U>
    @typing.overload
    def copyToArray(self, xs: typing.Any) -> None: ...
    @typing.overload
    def copyToArray(self, xs: typing.Any, start: int) -> None: ...
    @typing.overload
    def copyToArray(self, xs: typing.Any, start: int, len: int) -> None: ...
    def count(self, p: scala.Function1[_ParHashSet__T, typing.Any]) -> int: ...
    def debugBuffer(self) -> scala.collection.mutable.ArrayBuffer[java.lang.String]: ...
    def debugInformation(self) -> java.lang.String: ...
    def debugclear(self) -> None: ...
    def debuglog(self, s: typing.Union[java.lang.String, str]) -> scala.collection.mutable.ArrayBuffer[java.lang.String]: ...
    _delegatedSignalling2ops__PI = typing.TypeVar('_delegatedSignalling2ops__PI', bound=scala.collection.generic.DelegatedSignalling)  # <PI>
    def delegatedSignalling2ops(self, it: _delegatedSignalling2ops__PI) -> scala.collection.parallel.ParIterableLike.SignallingOps[_delegatedSignalling2ops__PI]: ...
    def diff(self, that: scala.collection.GenSet) -> scala.collection.parallel.ParSet: ...
    def drop(self, n: int) -> scala.collection.parallel.ParIterable: ...
    def dropWhile(self, pred: scala.Function1) -> scala.collection.parallel.ParIterable: ...
    def empty(self) -> 'ParHashSet'[_ParHashSet__T]: ...
    def equals(self, that: typing.Any) -> bool: ...
    def exists(self, p: scala.Function1[_ParHashSet__T, typing.Any]) -> bool: ...
    def filter(self, pred: scala.Function1) -> scala.collection.parallel.ParIterable: ...
    def filterNot(self, pred: scala.Function1) -> scala.collection.parallel.ParIterable: ...
    def find(self, p: scala.Function1[_ParHashSet__T, typing.Any]) -> scala.Option[_ParHashSet__T]: ...
    _flatMap__S = typing.TypeVar('_flatMap__S')  # <S>
    _flatMap__That = typing.TypeVar('_flatMap__That')  # <That>
    def flatMap(self, f: scala.Function1[_ParHashSet__T, scala.collection.GenTraversableOnce[_flatMap__S]], bf: scala.collection.generic.CanBuildFrom['ParHashSet'[_ParHashSet__T], _flatMap__S, _flatMap__That]) -> _flatMap__That: ...
    def flatten(self, asTraversable: scala.Function1) -> scala.collection.GenTraversable: ...
    _fold__U = typing.TypeVar('_fold__U')  # <U>
    def fold(self, z: _fold__U, op: scala.Function2[_fold__U, _fold__U, _fold__U]) -> _fold__U: ...
    _foldLeft__S = typing.TypeVar('_foldLeft__S')  # <S>
    def foldLeft(self, z: _foldLeft__S, op: scala.Function2[_foldLeft__S, _ParHashSet__T, _foldLeft__S]) -> _foldLeft__S: ...
    _foldRight__S = typing.TypeVar('_foldRight__S')  # <S>
    def foldRight(self, z: _foldRight__S, op: scala.Function2[_ParHashSet__T, _foldRight__S, _foldRight__S]) -> _foldRight__S: ...
    def forall(self, p: scala.Function1[_ParHashSet__T, typing.Any]) -> bool: ...
    _foreach__U = typing.TypeVar('_foreach__U')  # <U>
    def foreach(self, f: scala.Function1[_ParHashSet__T, _foreach__U]) -> None: ...
    _fromTrie__T = typing.TypeVar('_fromTrie__T')  # <T>
    @staticmethod
    def fromTrie(t: scala.collection.immutable.HashSet[_fromTrie__T]) -> 'ParHashSet'[_fromTrie__T]: ...
    _genericBuilder__B = typing.TypeVar('_genericBuilder__B')  # <B>
    def genericBuilder(self) -> scala.collection.parallel.Combiner[_genericBuilder__B, 'ParHashSet'[_genericBuilder__B]]: ...
    _genericCombiner__B = typing.TypeVar('_genericCombiner__B')  # <B>
    def genericCombiner(self) -> scala.collection.parallel.Combiner[_genericCombiner__B, 'ParHashSet'[_genericCombiner__B]]: ...
    _groupBy__K = typing.TypeVar('_groupBy__K')  # <K>
    def groupBy(self, f: scala.Function1[_ParHashSet__T, _groupBy__K]) -> 'ParMap'[_groupBy__K, 'ParHashSet'[_ParHashSet__T]]: ...
    def hasDefiniteSize(self) -> bool: ...
    def hashCode(self) -> int: ...
    def head(self) -> _ParHashSet__T: ...
    def headOption(self) -> scala.Option[_ParHashSet__T]: ...
    def init(self) -> scala.collection.parallel.ParIterable: ...
    def initTaskSupport(self) -> None: ...
    def intersect(self, that: scala.collection.GenSet) -> typing.Any: ...
    def isEmpty(self) -> bool: ...
    def isStrictSplitterCollection(self) -> bool: ...
    def isTraversableAgain(self) -> bool: ...
    def iterator(self) -> scala.collection.parallel.Splitter[_ParHashSet__T]: ...
    def last(self) -> _ParHashSet__T: ...
    def lastOption(self) -> scala.Option[_ParHashSet__T]: ...
    _map__S = typing.TypeVar('_map__S')  # <S>
    _map__That = typing.TypeVar('_map__That')  # <That>
    def map(self, f: scala.Function1[_ParHashSet__T, _map__S], bf: scala.collection.generic.CanBuildFrom['ParHashSet'[_ParHashSet__T], _map__S, _map__That]) -> _map__That: ...
    _max__U = typing.TypeVar('_max__U')  # <U>
    def max(self, ord: scala.math.Ordering[_max__U]) -> _ParHashSet__T: ...
    _maxBy__S = typing.TypeVar('_maxBy__S')  # <S>
    def maxBy(self, f: scala.Function1[_ParHashSet__T, _maxBy__S], cmp: scala.math.Ordering[_maxBy__S]) -> _ParHashSet__T: ...
    _min__U = typing.TypeVar('_min__U')  # <U>
    def min(self, ord: scala.math.Ordering[_min__U]) -> _ParHashSet__T: ...
    _minBy__S = typing.TypeVar('_minBy__S')  # <S>
    def minBy(self, f: scala.Function1[_ParHashSet__T, _minBy__S], cmp: scala.math.Ordering[_minBy__S]) -> _ParHashSet__T: ...
    @typing.overload
    def mkString(self) -> java.lang.String: ...
    @typing.overload
    def mkString(self, sep: typing.Union[java.lang.String, str]) -> java.lang.String: ...
    @typing.overload
    def mkString(self, start: typing.Union[java.lang.String, str], sep: typing.Union[java.lang.String, str], end: typing.Union[java.lang.String, str]) -> java.lang.String: ...
    def newBuilder(self) -> scala.collection.mutable.Builder[_ParHashSet__T, 'ParHashSet'[_ParHashSet__T]]: ...
    def newCombiner(self) -> scala.collection.parallel.Combiner[_ParHashSet__T, 'ParHashSet'[_ParHashSet__T]]: ...
    def nonEmpty(self) -> bool: ...
    def par(self) -> scala.collection.parallel.ParIterable: ...
    def parCombiner(self) -> scala.collection.parallel.Combiner[_ParHashSet__T, 'ParHashSet'[_ParHashSet__T]]: ...
    def partition(self, pred: scala.Function1[_ParHashSet__T, typing.Any]) -> scala.Tuple2['ParHashSet'[_ParHashSet__T], 'ParHashSet'[_ParHashSet__T]]: ...
    def printDebugBuffer(self) -> None: ...
    _product__U = typing.TypeVar('_product__U')  # <U>
    def product(self, num: scala.math.Numeric[_product__U]) -> _product__U: ...
    _reduce__U = typing.TypeVar('_reduce__U')  # <U>
    def reduce(self, op: scala.Function2[_reduce__U, _reduce__U, _reduce__U]) -> _reduce__U: ...
    _reduceLeft__U = typing.TypeVar('_reduceLeft__U')  # <U>
    def reduceLeft(self, op: scala.Function2[_reduceLeft__U, _ParHashSet__T, _reduceLeft__U]) -> _reduceLeft__U: ...
    _reduceLeftOption__U = typing.TypeVar('_reduceLeftOption__U')  # <U>
    def reduceLeftOption(self, op: scala.Function2[_reduceLeftOption__U, _ParHashSet__T, _reduceLeftOption__U]) -> scala.Option[_reduceLeftOption__U]: ...
    _reduceOption__U = typing.TypeVar('_reduceOption__U')  # <U>
    def reduceOption(self, op: scala.Function2[_reduceOption__U, _reduceOption__U, _reduceOption__U]) -> scala.Option[_reduceOption__U]: ...
    _reduceRight__U = typing.TypeVar('_reduceRight__U')  # <U>
    def reduceRight(self, op: scala.Function2[_ParHashSet__T, _reduceRight__U, _reduceRight__U]) -> _reduceRight__U: ...
    _reduceRightOption__U = typing.TypeVar('_reduceRightOption__U')  # <U>
    def reduceRightOption(self, op: scala.Function2[_ParHashSet__T, _reduceRightOption__U, _reduceRightOption__U]) -> scala.Option[_reduceRightOption__U]: ...
    def repr(self) -> scala.collection.parallel.ParIterable: ...
    _reuse__S = typing.TypeVar('_reuse__S')  # <S>
    _reuse__That = typing.TypeVar('_reuse__That')  # <That>
    def reuse(self, oldc: scala.Option[scala.collection.parallel.Combiner[_reuse__S, _reuse__That]], newc: scala.collection.parallel.Combiner[_reuse__S, _reuse__That]) -> scala.collection.parallel.Combiner[_reuse__S, _reuse__That]: ...
    _sameElements__U = typing.TypeVar('_sameElements__U')  # <U>
    def sameElements(self, that: scala.collection.GenIterable[_sameElements__U]) -> bool: ...
    def scala$collection$parallel$ParIterableLike$$_tasksupport(self) -> scala.collection.parallel.TaskSupport: ...
    def scala$collection$parallel$ParIterableLike$$_tasksupport_$eq(self, x$1: scala.collection.parallel.TaskSupport) -> None: ...
    _scan__U = typing.TypeVar('_scan__U')  # <U>
    _scan__That = typing.TypeVar('_scan__That')  # <That>
    def scan(self, z: _scan__U, op: scala.Function2[_scan__U, _scan__U, _scan__U], bf: scala.collection.generic.CanBuildFrom['ParHashSet'[_ParHashSet__T], _scan__U, _scan__That]) -> _scan__That: ...
    def scanBlockSize(self) -> int: ...
    _scanLeft__S = typing.TypeVar('_scanLeft__S')  # <S>
    _scanLeft__That = typing.TypeVar('_scanLeft__That')  # <That>
    def scanLeft(self, z: _scanLeft__S, op: scala.Function2[_scanLeft__S, _ParHashSet__T, _scanLeft__S], bf: scala.collection.generic.CanBuildFrom['ParHashSet'[_ParHashSet__T], _scanLeft__S, _scanLeft__That]) -> _scanLeft__That: ...
    _scanRight__S = typing.TypeVar('_scanRight__S')  # <S>
    _scanRight__That = typing.TypeVar('_scanRight__That')  # <That>
    def scanRight(self, z: _scanRight__S, op: scala.Function2[_ParHashSet__T, _scanRight__S, _scanRight__S], bf: scala.collection.generic.CanBuildFrom['ParHashSet'[_ParHashSet__T], _scanRight__S, _scanRight__That]) -> _scanRight__That: ...
    def seq(self) -> scala.collection.immutable.HashSet[_ParHashSet__T]: ...
    def sequentially(self, b: scala.Function1) -> scala.collection.parallel.ParIterable: ...
    _setCanBuildFrom__A = typing.TypeVar('_setCanBuildFrom__A')  # <A>
    @staticmethod
    def setCanBuildFrom() -> scala.collection.generic.CanBuildFrom['ParHashSet'[typing.Any], _setCanBuildFrom__A, 'ParHashSet'[_setCanBuildFrom__A]]: ...
    def size(self) -> int: ...
    def sizeHintIfCheap(self) -> int: ...
    def slice(self, unc_from: int, unc_until: int) -> scala.collection.parallel.ParIterable: ...
    def span(self, pred: scala.Function1[_ParHashSet__T, typing.Any]) -> scala.Tuple2['ParHashSet'[_ParHashSet__T], 'ParHashSet'[_ParHashSet__T]]: ...
    def splitAt(self, n: int) -> scala.Tuple2['ParHashSet'[_ParHashSet__T], 'ParHashSet'[_ParHashSet__T]]: ...
    def splitter(self) -> scala.collection.parallel.IterableSplitter[_ParHashSet__T]: ...
    def stringPrefix(self) -> java.lang.String: ...
    def subsetOf(self, that: scala.collection.GenSet[_ParHashSet__T]) -> bool: ...
    _sum__U = typing.TypeVar('_sum__U')  # <U>
    def sum(self, num: scala.math.Numeric[_sum__U]) -> _sum__U: ...
    def tail(self) -> scala.collection.parallel.ParIterable: ...
    def take(self, n: int) -> scala.collection.parallel.ParIterable: ...
    def takeWhile(self, pred: scala.Function1) -> scala.collection.parallel.ParIterable: ...
    _task2ops__R = typing.TypeVar('_task2ops__R')  # <R>
    _task2ops__Tp = typing.TypeVar('_task2ops__Tp')  # <Tp>
    def task2ops(self, tsk: scala.collection.parallel.ParIterableLike.StrictSplitterCheckTask[_task2ops__R, _task2ops__Tp]) -> scala.collection.parallel.ParIterableLike.TaskOps[_task2ops__R, _task2ops__Tp]: ...
    def tasksupport(self) -> scala.collection.parallel.TaskSupport: ...
    def tasksupport_$eq(self, ts: scala.collection.parallel.TaskSupport) -> None: ...
    _to__Col = typing.TypeVar('_to__Col')  # <Col>
    def to(self, cbf: scala.collection.generic.CanBuildFrom[scala.runtime.Nothing., _ParHashSet__T, _to__Col]) -> _to__Col: ...
    _toArray__U = typing.TypeVar('_toArray__U')  # <U>
    def toArray(self, evidence$1: scala.reflect.ClassTag[_toArray__U]) -> typing.Any: ...
    _toBuffer__U = typing.TypeVar('_toBuffer__U')  # <U>
    def toBuffer(self) -> scala.collection.mutable.Buffer[_toBuffer__U]: ...
    def toIndexedSeq(self) -> scala.collection.immutable.IndexedSeq[_ParHashSet__T]: ...
    def toIterable(self) -> ParIterable[_ParHashSet__T]: ...
    def toIterator(self) -> scala.collection.Iterator[_ParHashSet__T]: ...
    def toList(self) -> scala.collection.immutable.List[_ParHashSet__T]: ...
    _toMap__K = typing.TypeVar('_toMap__K')  # <K>
    _toMap__V = typing.TypeVar('_toMap__V')  # <V>
    def toMap(self, ev: scala.Predef..less.colon.less[_ParHashSet__T, scala.Tuple2[_toMap__K, _toMap__V]]) -> 'ParMap'[_toMap__K, _toMap__V]: ...
    _toParCollection__U = typing.TypeVar('_toParCollection__U')  # <U>
    _toParCollection__That = typing.TypeVar('_toParCollection__That')  # <That>
    def toParCollection(self, cbf: scala.Function0[scala.collection.parallel.Combiner[_toParCollection__U, _toParCollection__That]]) -> _toParCollection__That: ...
    _toParMap__K = typing.TypeVar('_toParMap__K')  # <K>
    _toParMap__V = typing.TypeVar('_toParMap__V')  # <V>
    _toParMap__That = typing.TypeVar('_toParMap__That')  # <That>
    def toParMap(self, cbf: scala.Function0[scala.collection.parallel.Combiner[scala.Tuple2[_toParMap__K, _toParMap__V], _toParMap__That]], ev: scala.Predef..less.colon.less[_ParHashSet__T, scala.Tuple2[_toParMap__K, _toParMap__V]]) -> _toParMap__That: ...
    def toSeq(self) -> ParSeq[_ParHashSet__T]: ...
    _toSet__U = typing.TypeVar('_toSet__U')  # <U>
    def toSet(self) -> ParSet[_toSet__U]: ...
    def toStream(self) -> scala.collection.immutable.Stream[_ParHashSet__T]: ...
    def toString(self) -> java.lang.String: ...
    def toTraversable(self) -> scala.collection.GenTraversable[_ParHashSet__T]: ...
    def toVector(self) -> scala.collection.immutable.Vector[_ParHashSet__T]: ...
    def transpose(self, asTraversable: scala.Function1) -> scala.collection.GenTraversable: ...
    def union(self, that: scala.collection.GenSet) -> scala.collection.parallel.ParSet: ...
    _unzip__A1 = typing.TypeVar('_unzip__A1')  # <A1>
    _unzip__A2 = typing.TypeVar('_unzip__A2')  # <A2>
    def unzip(self, asPair: scala.Function1[_ParHashSet__T, scala.Tuple2[_unzip__A1, _unzip__A2]]) -> scala.Tuple2['ParHashSet'[_unzip__A1], 'ParHashSet'[_unzip__A2]]: ...
    _unzip3__A1 = typing.TypeVar('_unzip3__A1')  # <A1>
    _unzip3__A2 = typing.TypeVar('_unzip3__A2')  # <A2>
    _unzip3__A3 = typing.TypeVar('_unzip3__A3')  # <A3>
    def unzip3(self, asTriple: scala.Function1[_ParHashSet__T, scala.Tuple3[_unzip3__A1, _unzip3__A2, _unzip3__A3]]) -> scala.Tuple3['ParHashSet'[_unzip3__A1], 'ParHashSet'[_unzip3__A2], 'ParHashSet'[_unzip3__A3]]: ...
    def view(self) -> scala.collection.IterableView[_ParHashSet__T, scala.collection.immutable.HashSet[_ParHashSet__T]]: ...
    def withFilter(self, pred: scala.Function1) -> scala.collection.parallel.ParIterable: ...
    _wrap__R = typing.TypeVar('_wrap__R')  # <R>
    def wrap(self, body: scala.Function0[_wrap__R]) -> scala.collection.parallel.ParIterableLike.NonDivisible[_wrap__R]: ...
    _zip__U = typing.TypeVar('_zip__U')  # <U>
    _zip__S = typing.TypeVar('_zip__S')  # <S>
    _zip__That = typing.TypeVar('_zip__That')  # <That>
    def zip(self, that: scala.collection.GenIterable[_zip__S], bf: scala.collection.generic.CanBuildFrom['ParHashSet'[_ParHashSet__T], scala.Tuple2[_zip__U, _zip__S], _zip__That]) -> _zip__That: ...
    _zipAll__S = typing.TypeVar('_zipAll__S')  # <S>
    _zipAll__U = typing.TypeVar('_zipAll__U')  # <U>
    _zipAll__That = typing.TypeVar('_zipAll__That')  # <That>
    def zipAll(self, that: scala.collection.GenIterable[_zipAll__S], thisElem: _zipAll__U, thatElem: _zipAll__S, bf: scala.collection.generic.CanBuildFrom['ParHashSet'[_ParHashSet__T], scala.Tuple2[_zipAll__U, _zipAll__S], _zipAll__That]) -> _zipAll__That: ...
    _zipWithIndex__U = typing.TypeVar('_zipWithIndex__U')  # <U>
    _zipWithIndex__That = typing.TypeVar('_zipWithIndex__That')  # <That>
    def zipWithIndex(self, bf: scala.collection.generic.CanBuildFrom['ParHashSet'[_ParHashSet__T], scala.Tuple2[_zipWithIndex__U, typing.Any], _zipWithIndex__That]) -> _zipWithIndex__That: ...
    class ParHashSetIterator(scala.collection.parallel.IterableSplitter[_ParHashSet__T]):
        $outer: 'ParHashSet' = ...
        def __init__(self, $outer: 'ParHashSet', triter: scala.collection.Iterator[_ParHashSet__T], sz: int): ...
        _$colon$bslash__B = typing.TypeVar('_$colon$bslash__B')  # <B>
        def $colon$bslash(self, z: _.colon.bslash__B, op: scala.Function2[_ParHashSet__T, _.colon.bslash__B, _.colon.bslash__B]) -> _.colon.bslash__B: ...
        _$div$colon__B = typing.TypeVar('_$div$colon__B')  # <B>
        def $div$colon(self, z: _.div.colon__B, op: scala.Function2[_.div.colon__B, _ParHashSet__T, _.div.colon__B]) -> _.div.colon__B: ...
        _$plus$plus__B = typing.TypeVar('_$plus$plus__B')  # <B>
        def $plus$plus(self, that: scala.Function0[scala.collection.GenTraversableOnce[_.plus.plus__B]]) -> scala.collection.Iterator[_.plus.plus__B]: ...
        def abort(self) -> None: ...
        @typing.overload
        def addString(self, b: scala.collection.mutable.StringBuilder) -> scala.collection.mutable.StringBuilder: ...
        @typing.overload
        def addString(self, b: scala.collection.mutable.StringBuilder, sep: typing.Union[java.lang.String, str]) -> scala.collection.mutable.StringBuilder: ...
        @typing.overload
        def addString(self, b: scala.collection.mutable.StringBuilder, start: typing.Union[java.lang.String, str], sep: typing.Union[java.lang.String, str], end: typing.Union[java.lang.String, str]) -> scala.collection.mutable.StringBuilder: ...
        _aggregate__B = typing.TypeVar('_aggregate__B')  # <B>
        def aggregate(self, z: scala.Function0[_aggregate__B], seqop: scala.Function2[_aggregate__B, _ParHashSet__T, _aggregate__B], combop: scala.Function2[_aggregate__B, _aggregate__B, _aggregate__B]) -> _aggregate__B: ...
        _appendParIterable__U = typing.TypeVar('_appendParIterable__U')  # <U>
        _appendParIterable__PI = typing.TypeVar('_appendParIterable__PI', bound=scala.collection.parallel.IterableSplitter)  # <PI>
        def appendParIterable(self, that: _appendParIterable__PI) -> scala.collection.parallel.IterableSplitter.Appended[_appendParIterable__U, _appendParIterable__PI]: ...
        def buffered(self) -> scala.collection.BufferedIterator[_ParHashSet__T]: ...
        def buildString(self, closure: scala.Function1[scala.Function1[typing.Union[java.lang.String, str], scala.runtime.BoxedUnit], scala.runtime.BoxedUnit]) -> java.lang.String: ...
        _collect__B = typing.TypeVar('_collect__B')  # <B>
        def collect(self, pf: scala.PartialFunction[_ParHashSet__T, _collect__B]) -> scala.collection.Iterator[_collect__B]: ...
        _collect2combiner__S = typing.TypeVar('_collect2combiner__S')  # <S>
        _collect2combiner__That = typing.TypeVar('_collect2combiner__That')  # <That>
        def collect2combiner(self, pf: scala.PartialFunction[_ParHashSet__T, _collect2combiner__S], cb: scala.collection.parallel.Combiner[_collect2combiner__S, _collect2combiner__That]) -> scala.collection.parallel.Combiner[_collect2combiner__S, _collect2combiner__That]: ...
        _collectFirst__B = typing.TypeVar('_collectFirst__B')  # <B>
        def collectFirst(self, pf: scala.PartialFunction[_ParHashSet__T, _collectFirst__B]) -> scala.Option[_collectFirst__B]: ...
        def contains(self, elem: typing.Any) -> bool: ...
        _copy2builder__U = typing.TypeVar('_copy2builder__U')  # <U>
        _copy2builder__Coll = typing.TypeVar('_copy2builder__Coll')  # <Coll>
        _copy2builder__Bld = typing.TypeVar('_copy2builder__Bld', bound=scala.collection.mutable.Builder)  # <Bld>
        def copy2builder(self, b: _copy2builder__Bld) -> _copy2builder__Bld: ...
        _copyToArray_0__B = typing.TypeVar('_copyToArray_0__B')  # <B>
        _copyToArray_1__B = typing.TypeVar('_copyToArray_1__B')  # <B>
        _copyToArray_2__U = typing.TypeVar('_copyToArray_2__U')  # <U>
        @typing.overload
        def copyToArray(self, xs: typing.Any) -> None: ...
        @typing.overload
        def copyToArray(self, xs: typing.Any, start: int) -> None: ...
        @typing.overload
        def copyToArray(self, array: typing.Any, from_: int, len: int) -> None: ...
        _copyToBuffer__B = typing.TypeVar('_copyToBuffer__B')  # <B>
        def copyToBuffer(self, dest: scala.collection.mutable.Buffer[_copyToBuffer__B]) -> None: ...
        _corresponds__B = typing.TypeVar('_corresponds__B')  # <B>
        def corresponds(self, that: scala.collection.GenTraversableOnce[_corresponds__B], p: scala.Function2[_ParHashSet__T, _corresponds__B, typing.Any]) -> bool: ...
        def count(self, p: scala.Function1[_ParHashSet__T, typing.Any]) -> int: ...
        def debugInformation(self) -> java.lang.String: ...
        def drop(self, n: int) -> scala.collection.parallel.IterableSplitter[_ParHashSet__T]: ...
        _drop2combiner__U = typing.TypeVar('_drop2combiner__U')  # <U>
        _drop2combiner__This = typing.TypeVar('_drop2combiner__This')  # <This>
        def drop2combiner(self, n: int, cb: scala.collection.parallel.Combiner[_drop2combiner__U, _drop2combiner__This]) -> scala.collection.parallel.Combiner[_drop2combiner__U, _drop2combiner__This]: ...
        def dropWhile(self, p: scala.Function1[_ParHashSet__T, typing.Any]) -> scala.collection.Iterator[_ParHashSet__T]: ...
        def dup(self) -> scala.collection.parallel.IterableSplitter[_ParHashSet__T]: ...
        def duplicate(self) -> scala.Tuple2[scala.collection.Iterator[_ParHashSet__T], scala.collection.Iterator[_ParHashSet__T]]: ...
        def exists(self, p: scala.Function1[_ParHashSet__T, typing.Any]) -> bool: ...
        def filter(self, p: scala.Function1[_ParHashSet__T, typing.Any]) -> scala.collection.Iterator[_ParHashSet__T]: ...
        _filter2combiner__U = typing.TypeVar('_filter2combiner__U')  # <U>
        _filter2combiner__This = typing.TypeVar('_filter2combiner__This')  # <This>
        def filter2combiner(self, pred: scala.Function1[_ParHashSet__T, typing.Any], cb: scala.collection.parallel.Combiner[_filter2combiner__U, _filter2combiner__This]) -> scala.collection.parallel.Combiner[_filter2combiner__U, _filter2combiner__This]: ...
        def filterNot(self, p: scala.Function1[_ParHashSet__T, typing.Any]) -> scala.collection.Iterator[_ParHashSet__T]: ...
        _filterNot2combiner__U = typing.TypeVar('_filterNot2combiner__U')  # <U>
        _filterNot2combiner__This = typing.TypeVar('_filterNot2combiner__This')  # <This>
        def filterNot2combiner(self, pred: scala.Function1[_ParHashSet__T, typing.Any], cb: scala.collection.parallel.Combiner[_filterNot2combiner__U, _filterNot2combiner__This]) -> scala.collection.parallel.Combiner[_filterNot2combiner__U, _filterNot2combiner__This]: ...
        def find(self, p: scala.Function1[_ParHashSet__T, typing.Any]) -> scala.Option[_ParHashSet__T]: ...
        _flatMap__B = typing.TypeVar('_flatMap__B')  # <B>
        def flatMap(self, f: scala.Function1[_ParHashSet__T, scala.collection.GenTraversableOnce[_flatMap__B]]) -> scala.collection.Iterator[_flatMap__B]: ...
        _flatmap2combiner__S = typing.TypeVar('_flatmap2combiner__S')  # <S>
        _flatmap2combiner__That = typing.TypeVar('_flatmap2combiner__That')  # <That>
        def flatmap2combiner(self, f: scala.Function1[_ParHashSet__T, scala.collection.GenTraversableOnce[_flatmap2combiner__S]], cb: scala.collection.parallel.Combiner[_flatmap2combiner__S, _flatmap2combiner__That]) -> scala.collection.parallel.Combiner[_flatmap2combiner__S, _flatmap2combiner__That]: ...
        _fold__U = typing.TypeVar('_fold__U')  # <U>
        def fold(self, z: _fold__U, op: scala.Function2[_fold__U, _fold__U, _fold__U]) -> _fold__U: ...
        _foldLeft__B = typing.TypeVar('_foldLeft__B')  # <B>
        def foldLeft(self, z: _foldLeft__B, op: scala.Function2[_foldLeft__B, _ParHashSet__T, _foldLeft__B]) -> _foldLeft__B: ...
        _foldRight__B = typing.TypeVar('_foldRight__B')  # <B>
        def foldRight(self, z: _foldRight__B, op: scala.Function2[_ParHashSet__T, _foldRight__B, _foldRight__B]) -> _foldRight__B: ...
        def forall(self, p: scala.Function1[_ParHashSet__T, typing.Any]) -> bool: ...
        _foreach__U = typing.TypeVar('_foreach__U')  # <U>
        def foreach(self, f: scala.Function1[_ParHashSet__T, _foreach__U]) -> None: ...
        _grouped__B = typing.TypeVar('_grouped__B')  # <B>
        def grouped(self, size: int) -> scala.collection.Iterator.GroupedIterator[_grouped__B]: ...
        def hasDefiniteSize(self) -> bool: ...
        def hasNext(self) -> bool: ...
        def i(self) -> int: ...
        def i_$eq(self, x$1: int) -> None: ...
        def indexFlag(self) -> int: ...
        _indexOf_0__B = typing.TypeVar('_indexOf_0__B')  # <B>
        _indexOf_1__B = typing.TypeVar('_indexOf_1__B')  # <B>
        @typing.overload
        def indexOf(self, elem: _indexOf_0__B) -> int: ...
        @typing.overload
        def indexOf(self, elem: _indexOf_1__B, from_: int) -> int: ...
        @typing.overload
        def indexWhere(self, p: scala.Function1[_ParHashSet__T, typing.Any]) -> int: ...
        @typing.overload
        def indexWhere(self, p: scala.Function1[_ParHashSet__T, typing.Any], from_: int) -> int: ...
        def isAborted(self) -> bool: ...
        def isEmpty(self) -> bool: ...
        def isRemainingCheap(self) -> bool: ...
        def isTraversableAgain(self) -> bool: ...
        def length(self) -> int: ...
        _map__S = typing.TypeVar('_map__S')  # <S>
        def map(self, f: scala.Function1[_ParHashSet__T, _map__S]) -> scala.collection.parallel.IterableSplitter.Mapped[_map__S]: ...
        _map2combiner__S = typing.TypeVar('_map2combiner__S')  # <S>
        _map2combiner__That = typing.TypeVar('_map2combiner__That')  # <That>
        def map2combiner(self, f: scala.Function1[_ParHashSet__T, _map2combiner__S], cb: scala.collection.parallel.Combiner[_map2combiner__S, _map2combiner__That]) -> scala.collection.parallel.Combiner[_map2combiner__S, _map2combiner__That]: ...
        _max__U = typing.TypeVar('_max__U')  # <U>
        def max(self, ord: scala.math.Ordering[_max__U]) -> _ParHashSet__T: ...
        _maxBy__B = typing.TypeVar('_maxBy__B')  # <B>
        def maxBy(self, f: scala.Function1[_ParHashSet__T, _maxBy__B], cmp: scala.math.Ordering[_maxBy__B]) -> _ParHashSet__T: ...
        _min__U = typing.TypeVar('_min__U')  # <U>
        def min(self, ord: scala.math.Ordering[_min__U]) -> _ParHashSet__T: ...
        _minBy__B = typing.TypeVar('_minBy__B')  # <B>
        def minBy(self, f: scala.Function1[_ParHashSet__T, _minBy__B], cmp: scala.math.Ordering[_minBy__B]) -> _ParHashSet__T: ...
        @typing.overload
        def mkString(self) -> java.lang.String: ...
        @typing.overload
        def mkString(self, sep: typing.Union[java.lang.String, str]) -> java.lang.String: ...
        @typing.overload
        def mkString(self, start: typing.Union[java.lang.String, str], sep: typing.Union[java.lang.String, str], end: typing.Union[java.lang.String, str]) -> java.lang.String: ...
        _newSliceInternal__U = typing.TypeVar('_newSliceInternal__U', bound=scala.collection.parallel.IterableSplitter.Taken)  # <U>
        def newSliceInternal(self, it: _newSliceInternal__U, from1: int) -> _newSliceInternal__U: ...
        def newTaken(self, until: int) -> scala.collection.parallel.IterableSplitter.Taken: ...
        def next(self) -> _ParHashSet__T: ...
        def nonEmpty(self) -> bool: ...
        _padTo__A1 = typing.TypeVar('_padTo__A1')  # <A1>
        def padTo(self, len: int, elem: _padTo__A1) -> scala.collection.Iterator[_padTo__A1]: ...
        def partition(self, p: scala.Function1[_ParHashSet__T, typing.Any]) -> scala.Tuple2[scala.collection.Iterator[_ParHashSet__T], scala.collection.Iterator[_ParHashSet__T]]: ...
        _partition2combiners__U = typing.TypeVar('_partition2combiners__U')  # <U>
        _partition2combiners__This = typing.TypeVar('_partition2combiners__This')  # <This>
        def partition2combiners(self, pred: scala.Function1[_ParHashSet__T, typing.Any], btrue: scala.collection.parallel.Combiner[_partition2combiners__U, _partition2combiners__This], bfalse: scala.collection.parallel.Combiner[_partition2combiners__U, _partition2combiners__This]) -> scala.Tuple2[scala.collection.parallel.Combiner[_partition2combiners__U, _partition2combiners__This], scala.collection.parallel.Combiner[_partition2combiners__U, _partition2combiners__This]]: ...
        _patch__B = typing.TypeVar('_patch__B')  # <B>
        def patch(self, from_: int, patchElems: scala.collection.Iterator[_patch__B], replaced: int) -> scala.collection.Iterator[_patch__B]: ...
        _product__U = typing.TypeVar('_product__U')  # <U>
        def product(self, num: scala.math.Numeric[_product__U]) -> _product__U: ...
        _reduce__U = typing.TypeVar('_reduce__U')  # <U>
        def reduce(self, op: scala.Function2[_reduce__U, _reduce__U, _reduce__U]) -> _reduce__U: ...
        _reduceLeft_0__U = typing.TypeVar('_reduceLeft_0__U')  # <U>
        _reduceLeft_1__B = typing.TypeVar('_reduceLeft_1__B')  # <B>
        @typing.overload
        def reduceLeft(self, howmany: int, op: scala.Function2[_reduceLeft_0__U, _reduceLeft_0__U, _reduceLeft_0__U]) -> _reduceLeft_0__U: ...
        @typing.overload
        def reduceLeft(self, op: scala.Function2[_reduceLeft_1__B, _ParHashSet__T, _reduceLeft_1__B]) -> _reduceLeft_1__B: ...
        _reduceLeftOption__B = typing.TypeVar('_reduceLeftOption__B')  # <B>
        def reduceLeftOption(self, op: scala.Function2[_reduceLeftOption__B, _ParHashSet__T, _reduceLeftOption__B]) -> scala.Option[_reduceLeftOption__B]: ...
        _reduceOption__A1 = typing.TypeVar('_reduceOption__A1')  # <A1>
        def reduceOption(self, op: scala.Function2[_reduceOption__A1, _reduceOption__A1, _reduceOption__A1]) -> scala.Option[_reduceOption__A1]: ...
        _reduceRight__B = typing.TypeVar('_reduceRight__B')  # <B>
        def reduceRight(self, op: scala.Function2[_ParHashSet__T, _reduceRight__B, _reduceRight__B]) -> _reduceRight__B: ...
        _reduceRightOption__B = typing.TypeVar('_reduceRightOption__B')  # <B>
        def reduceRightOption(self, op: scala.Function2[_ParHashSet__T, _reduceRightOption__B, _reduceRightOption__B]) -> scala.Option[_reduceRightOption__B]: ...
        def remaining(self) -> int: ...
        def reversed(self) -> scala.collection.immutable.List[_ParHashSet__T]: ...
        def sameElements(self, that: scala.collection.Iterator[typing.Any]) -> bool: ...
        _scanLeft__B = typing.TypeVar('_scanLeft__B')  # <B>
        def scanLeft(self, z: _scanLeft__B, op: scala.Function2[_scanLeft__B, _ParHashSet__T, _scanLeft__B]) -> scala.collection.Iterator[_scanLeft__B]: ...
        _scanRight__B = typing.TypeVar('_scanRight__B')  # <B>
        def scanRight(self, z: _scanRight__B, op: scala.Function2[_ParHashSet__T, _scanRight__B, _scanRight__B]) -> scala.collection.Iterator[_scanRight__B]: ...
        _scanToArray__U = typing.TypeVar('_scanToArray__U')  # <U>
        _scanToArray__A = typing.TypeVar('_scanToArray__A')  # <A>
        def scanToArray(self, z: _scanToArray__U, op: scala.Function2[_scanToArray__U, _scanToArray__U, _scanToArray__U], array: typing.Any, from_: int) -> None: ...
        _scanToCombiner_0__U = typing.TypeVar('_scanToCombiner_0__U')  # <U>
        _scanToCombiner_0__That = typing.TypeVar('_scanToCombiner_0__That')  # <That>
        _scanToCombiner_1__U = typing.TypeVar('_scanToCombiner_1__U')  # <U>
        _scanToCombiner_1__That = typing.TypeVar('_scanToCombiner_1__That')  # <That>
        @typing.overload
        def scanToCombiner(self, howmany: int, startValue: _scanToCombiner_0__U, op: scala.Function2[_scanToCombiner_0__U, _scanToCombiner_0__U, _scanToCombiner_0__U], cb: scala.collection.parallel.Combiner[_scanToCombiner_0__U, _scanToCombiner_0__That]) -> scala.collection.parallel.Combiner[_scanToCombiner_0__U, _scanToCombiner_0__That]: ...
        @typing.overload
        def scanToCombiner(self, startValue: _scanToCombiner_1__U, op: scala.Function2[_scanToCombiner_1__U, _scanToCombiner_1__U, _scanToCombiner_1__U], cb: scala.collection.parallel.Combiner[_scanToCombiner_1__U, _scanToCombiner_1__That]) -> scala.collection.parallel.Combiner[_scanToCombiner_1__U, _scanToCombiner_1__That]: ...
        def seq(self) -> scala.collection.Iterator[_ParHashSet__T]: ...
        def setIndexFlag(self, f: int) -> None: ...
        def setIndexFlagIfGreater(self, f: int) -> None: ...
        def setIndexFlagIfLesser(self, f: int) -> None: ...
        _shouldSplitFurther__S = typing.TypeVar('_shouldSplitFurther__S')  # <S>
        def shouldSplitFurther(self, coll: scala.collection.parallel.ParIterable[_shouldSplitFurther__S], parallelismLevel: int) -> bool: ...
        def signalDelegate(self) -> scala.collection.generic.Signalling: ...
        def signalDelegate_$eq(self, x$1: scala.collection.generic.Signalling) -> None: ...
        def size(self) -> int: ...
        def sizeHintIfCheap(self) -> int: ...
        def slice(self, from1: int, until1: int) -> scala.collection.parallel.IterableSplitter[_ParHashSet__T]: ...
        _slice2combiner__U = typing.TypeVar('_slice2combiner__U')  # <U>
        _slice2combiner__This = typing.TypeVar('_slice2combiner__This')  # <This>
        def slice2combiner(self, from_: int, until: int, cb: scala.collection.parallel.Combiner[_slice2combiner__U, _slice2combiner__This]) -> scala.collection.parallel.Combiner[_slice2combiner__U, _slice2combiner__This]: ...
        def sliceIterator(self, from_: int, until: int) -> scala.collection.Iterator[_ParHashSet__T]: ...
        _sliding__B = typing.TypeVar('_sliding__B')  # <B>
        def sliding(self, size: int, step: int) -> scala.collection.Iterator.GroupedIterator[_sliding__B]: ...
        _sliding$default$2__B = typing.TypeVar('_sliding$default$2__B')  # <B>
        def sliding$default$2(self) -> int: ...
        def span(self, p: scala.Function1[_ParHashSet__T, typing.Any]) -> scala.Tuple2[scala.collection.Iterator[_ParHashSet__T], scala.collection.Iterator[_ParHashSet__T]]: ...
        _span2combiners__U = typing.TypeVar('_span2combiners__U')  # <U>
        _span2combiners__This = typing.TypeVar('_span2combiners__This')  # <This>
        def span2combiners(self, p: scala.Function1[_ParHashSet__T, typing.Any], before: scala.collection.parallel.Combiner[_span2combiners__U, _span2combiners__This], after: scala.collection.parallel.Combiner[_span2combiners__U, _span2combiners__This]) -> scala.Tuple2[scala.collection.parallel.Combiner[_span2combiners__U, _span2combiners__This], scala.collection.parallel.Combiner[_span2combiners__U, _span2combiners__This]]: ...
        def split(self) -> scala.collection.Seq[scala.collection.parallel.IterableSplitter[_ParHashSet__T]]: ...
        _splitAt2combiners__U = typing.TypeVar('_splitAt2combiners__U')  # <U>
        _splitAt2combiners__This = typing.TypeVar('_splitAt2combiners__This')  # <This>
        def splitAt2combiners(self, at: int, before: scala.collection.parallel.Combiner[_splitAt2combiners__U, _splitAt2combiners__This], after: scala.collection.parallel.Combiner[_splitAt2combiners__U, _splitAt2combiners__This]) -> scala.Tuple2[scala.collection.parallel.Combiner[_splitAt2combiners__U, _splitAt2combiners__This], scala.collection.parallel.Combiner[_splitAt2combiners__U, _splitAt2combiners__This]]: ...
        def splitWithSignalling(self) -> scala.collection.Seq[scala.collection.parallel.IterableSplitter[_ParHashSet__T]]: ...
        _sum__U = typing.TypeVar('_sum__U')  # <U>
        def sum(self, num: scala.math.Numeric[_sum__U]) -> _sum__U: ...
        def sz(self) -> int: ...
        def tag(self) -> int: ...
        def take(self, n: int) -> scala.collection.parallel.IterableSplitter[_ParHashSet__T]: ...
        _take2combiner__U = typing.TypeVar('_take2combiner__U')  # <U>
        _take2combiner__This = typing.TypeVar('_take2combiner__This')  # <This>
        def take2combiner(self, n: int, cb: scala.collection.parallel.Combiner[_take2combiner__U, _take2combiner__This]) -> scala.collection.parallel.Combiner[_take2combiner__U, _take2combiner__This]: ...
        def takeWhile(self, p: scala.Function1[_ParHashSet__T, typing.Any]) -> scala.collection.Iterator[_ParHashSet__T]: ...
        _takeWhile2combiner__U = typing.TypeVar('_takeWhile2combiner__U')  # <U>
        _takeWhile2combiner__This = typing.TypeVar('_takeWhile2combiner__This')  # <This>
        def takeWhile2combiner(self, p: scala.Function1[_ParHashSet__T, typing.Any], cb: scala.collection.parallel.Combiner[_takeWhile2combiner__U, _takeWhile2combiner__This]) -> scala.Tuple2[scala.collection.parallel.Combiner[_takeWhile2combiner__U, _takeWhile2combiner__This], typing.Any]: ...
        _to__Col = typing.TypeVar('_to__Col')  # <Col>
        def to(self, cbf: scala.collection.generic.CanBuildFrom[scala.runtime.Nothing., _ParHashSet__T, _to__Col]) -> _to__Col: ...
        _toArray__B = typing.TypeVar('_toArray__B')  # <B>
        def toArray(self, evidence$1: scala.reflect.ClassTag[_toArray__B]) -> typing.Any: ...
        _toBuffer__B = typing.TypeVar('_toBuffer__B')  # <B>
        def toBuffer(self) -> scala.collection.mutable.Buffer[_toBuffer__B]: ...
        def toIndexedSeq(self) -> scala.collection.immutable.IndexedSeq[_ParHashSet__T]: ...
        def toIterable(self) -> scala.collection.Iterable[_ParHashSet__T]: ...
        def toIterator(self) -> scala.collection.Iterator[_ParHashSet__T]: ...
        def toList(self) -> scala.collection.immutable.List[_ParHashSet__T]: ...
        _toMap__T = typing.TypeVar('_toMap__T')  # <T>
        _toMap__U = typing.TypeVar('_toMap__U')  # <U>
        def toMap(self, ev: scala.Predef..less.colon.less[typing.Any, scala.Tuple2[typing.Any, _toMap__U]]) -> scala.collection.immutable.Map[typing.Any, _toMap__U]: ...
        def toSeq(self) -> scala.collection.Seq[_ParHashSet__T]: ...
        _toSet__B = typing.TypeVar('_toSet__B')  # <B>
        def toSet(self) -> scala.collection.immutable.Set[_toSet__B]: ...
        def toStream(self) -> scala.collection.immutable.Stream[_ParHashSet__T]: ...
        def toString(self) -> java.lang.String: ...
        def toTraversable(self) -> scala.collection.Traversable[_ParHashSet__T]: ...
        def toVector(self) -> scala.collection.immutable.Vector[_ParHashSet__T]: ...
        def triter(self) -> scala.collection.Iterator[_ParHashSet__T]: ...
        def triter_$eq(self, x$1: scala.collection.Iterator[_ParHashSet__T]) -> None: ...
        def withFilter(self, p: scala.Function1[_ParHashSet__T, typing.Any]) -> scala.collection.Iterator[_ParHashSet__T]: ...
        _zip__B = typing.TypeVar('_zip__B')  # <B>
        def zip(self, that: scala.collection.Iterator[_zip__B]) -> scala.collection.Iterator[scala.Tuple2[_ParHashSet__T, _zip__B]]: ...
        _zip2combiner__U = typing.TypeVar('_zip2combiner__U')  # <U>
        _zip2combiner__S = typing.TypeVar('_zip2combiner__S')  # <S>
        _zip2combiner__That = typing.TypeVar('_zip2combiner__That')  # <That>
        def zip2combiner(self, otherpit: scala.collection.parallel.RemainsIterator[_zip2combiner__S], cb: scala.collection.parallel.Combiner[scala.Tuple2[_zip2combiner__U, _zip2combiner__S], _zip2combiner__That]) -> scala.collection.parallel.Combiner[scala.Tuple2[_zip2combiner__U, _zip2combiner__S], _zip2combiner__That]: ...
        _zipAll__B = typing.TypeVar('_zipAll__B')  # <B>
        _zipAll__A1 = typing.TypeVar('_zipAll__A1')  # <A1>
        _zipAll__B1 = typing.TypeVar('_zipAll__B1')  # <B1>
        def zipAll(self, that: scala.collection.Iterator[_zipAll__B], thisElem: _zipAll__A1, thatElem: _zipAll__B1) -> scala.collection.Iterator[scala.Tuple2[_zipAll__A1, _zipAll__B1]]: ...
        _zipAll2combiner__U = typing.TypeVar('_zipAll2combiner__U')  # <U>
        _zipAll2combiner__S = typing.TypeVar('_zipAll2combiner__S')  # <S>
        _zipAll2combiner__That = typing.TypeVar('_zipAll2combiner__That')  # <That>
        def zipAll2combiner(self, that: scala.collection.parallel.RemainsIterator[_zipAll2combiner__S], thiselem: _zipAll2combiner__U, thatelem: _zipAll2combiner__S, cb: scala.collection.parallel.Combiner[scala.Tuple2[_zipAll2combiner__U, _zipAll2combiner__S], _zipAll2combiner__That]) -> scala.collection.parallel.Combiner[scala.Tuple2[_zipAll2combiner__U, _zipAll2combiner__S], _zipAll2combiner__That]: ...
        _zipAllParSeq__S = typing.TypeVar('_zipAllParSeq__S')  # <S>
        _zipAllParSeq__U = typing.TypeVar('_zipAllParSeq__U')  # <U>
        _zipAllParSeq__R = typing.TypeVar('_zipAllParSeq__R')  # <R>
        def zipAllParSeq(self, that: scala.collection.parallel.SeqSplitter[_zipAllParSeq__S], thisElem: _zipAllParSeq__U, thatElem: _zipAllParSeq__R) -> scala.collection.parallel.IterableSplitter.ZippedAll[_zipAllParSeq__U, _zipAllParSeq__R]: ...
        _zipParSeq__S = typing.TypeVar('_zipParSeq__S')  # <S>
        def zipParSeq(self, that: scala.collection.parallel.SeqSplitter[_zipParSeq__S]) -> scala.collection.parallel.IterableSplitter.Zipped[_zipParSeq__S]: ...
        def zipWithIndex(self) -> scala.collection.Iterator[scala.Tuple2[_ParHashSet__T, typing.Any]]: ...

class ParRange(ParSeq[typing.Any], scala.Serializable):
    serialVersionUID: typing.ClassVar[int] = ...
    def __init__(self, range: scala.collection.immutable.Range): ...
    _$colon$bslash__S = typing.TypeVar('_$colon$bslash__S')  # <S>
    def $colon$bslash(self, z: _.colon.bslash__S, op: scala.Function2[typing.Any, _.colon.bslash__S, _.colon.bslash__S]) -> _.colon.bslash__S: ...
    _$colon$plus__U = typing.TypeVar('_$colon$plus__U')  # <U>
    _$colon$plus__That = typing.TypeVar('_$colon$plus__That')  # <That>
    def $colon$plus(self, elem: _.colon.plus__U, bf: scala.collection.generic.CanBuildFrom[ParSeq[typing.Any], _.colon.plus__U, _.colon.plus__That]) -> _.colon.plus__That: ...
    _$div$colon__S = typing.TypeVar('_$div$colon__S')  # <S>
    def $div$colon(self, z: _.div.colon__S, op: scala.Function2[_.div.colon__S, typing.Any, _.div.colon__S]) -> _.div.colon__S: ...
    _$plus$colon__U = typing.TypeVar('_$plus$colon__U')  # <U>
    _$plus$colon__That = typing.TypeVar('_$plus$colon__That')  # <That>
    def $plus$colon(self, elem: _.plus.colon__U, bf: scala.collection.generic.CanBuildFrom[ParSeq[typing.Any], _.plus.colon__U, _.plus.colon__That]) -> _.plus.colon__That: ...
    _$plus$plus__U = typing.TypeVar('_$plus$plus__U')  # <U>
    _$plus$plus__That = typing.TypeVar('_$plus$plus__That')  # <That>
    def $plus$plus(self, that: scala.collection.GenTraversableOnce[_.plus.plus__U], bf: scala.collection.generic.CanBuildFrom[ParSeq[typing.Any], _.plus.plus__U, _.plus.plus__That]) -> _.plus.plus__That: ...
    def ScanLeaf(self) -> scala.collection.parallel.ParIterableLike.ScanLeaf.: ...
    def ScanNode(self) -> scala.collection.parallel.ParIterableLike.ScanNode.: ...
    _aggregate__S = typing.TypeVar('_aggregate__S')  # <S>
    def aggregate(self, z: scala.Function0[_aggregate__S], seqop: scala.Function2[_aggregate__S, typing.Any, _aggregate__S], combop: scala.Function2[_aggregate__S, _aggregate__S, _aggregate__S]) -> _aggregate__S: ...
    def apply(self, idx: int) -> int: ...
    _bf2seq__S = typing.TypeVar('_bf2seq__S')  # <S>
    _bf2seq__That = typing.TypeVar('_bf2seq__That')  # <That>
    def bf2seq(self, bf: scala.collection.generic.CanBuildFrom[ParSeq[typing.Any], _bf2seq__S, _bf2seq__That]) -> scala.collection.generic.CanBuildFrom[scala.collection.immutable.Seq[typing.Any], _bf2seq__S, _bf2seq__That]: ...
    def brokenInvariants(self) -> scala.collection.Seq[java.lang.String]: ...
    _builder2ops__Elem = typing.TypeVar('_builder2ops__Elem')  # <Elem>
    _builder2ops__To = typing.TypeVar('_builder2ops__To')  # <To>
    def builder2ops(self, cb: scala.collection.mutable.Builder[_builder2ops__Elem, _builder2ops__To]) -> scala.collection.parallel.ParIterableLike.BuilderOps[_builder2ops__Elem, _builder2ops__To]: ...
    def canEqual(self, other: typing.Any) -> bool: ...
    _collect__S = typing.TypeVar('_collect__S')  # <S>
    _collect__That = typing.TypeVar('_collect__That')  # <That>
    def collect(self, pf: scala.PartialFunction[typing.Any, _collect__S], bf: scala.collection.generic.CanBuildFrom[ParSeq[typing.Any], _collect__S, _collect__That]) -> _collect__That: ...
    _combinerFactory_1__S = typing.TypeVar('_combinerFactory_1__S')  # <S>
    _combinerFactory_1__That = typing.TypeVar('_combinerFactory_1__That')  # <That>
    @typing.overload
    def combinerFactory(self) -> scala.collection.parallel.CombinerFactory[typing.Any, ParSeq[typing.Any]]: ...
    @typing.overload
    def combinerFactory(self, cbf: scala.Function0[scala.collection.parallel.Combiner[_combinerFactory_1__S, _combinerFactory_1__That]]) -> scala.collection.parallel.CombinerFactory[_combinerFactory_1__S, _combinerFactory_1__That]: ...
    def companion(self) -> scala.collection.generic.GenericCompanion[ParSeq]: ...
    _copyToArray_0__U = typing.TypeVar('_copyToArray_0__U')  # <U>
    _copyToArray_1__U = typing.TypeVar('_copyToArray_1__U')  # <U>
    _copyToArray_2__U = typing.TypeVar('_copyToArray_2__U')  # <U>
    @typing.overload
    def copyToArray(self, xs: typing.Any) -> None: ...
    @typing.overload
    def copyToArray(self, xs: typing.Any, start: int) -> None: ...
    @typing.overload
    def copyToArray(self, xs: typing.Any, start: int, len: int) -> None: ...
    _corresponds__S = typing.TypeVar('_corresponds__S')  # <S>
    def corresponds(self, that: scala.collection.GenSeq[_corresponds__S], p: scala.Function2[typing.Any, _corresponds__S, typing.Any]) -> bool: ...
    def count(self, p: scala.Function1[typing.Any, typing.Any]) -> int: ...
    def debugBuffer(self) -> scala.collection.mutable.ArrayBuffer[java.lang.String]: ...
    def debugInformation(self) -> java.lang.String: ...
    def debugclear(self) -> None: ...
    def debuglog(self, s: typing.Union[java.lang.String, str]) -> scala.collection.mutable.ArrayBuffer[java.lang.String]: ...
    _delegatedSignalling2ops__PI = typing.TypeVar('_delegatedSignalling2ops__PI', bound=scala.collection.generic.DelegatedSignalling)  # <PI>
    def delegatedSignalling2ops(self, it: _delegatedSignalling2ops__PI) -> scala.collection.parallel.ParIterableLike.SignallingOps[_delegatedSignalling2ops__PI]: ...
    def diff(self, that: scala.collection.GenSeq) -> scala.collection.parallel.ParSeq: ...
    def distinct(self) -> scala.collection.parallel.ParSeq: ...
    def down(self, p: scala.collection.parallel.IterableSplitter[typing.Any]) -> scala.collection.parallel.SeqSplitter[typing.Any]: ...
    def drop(self, n: int) -> scala.collection.parallel.ParIterable: ...
    def dropWhile(self, pred: scala.Function1) -> scala.collection.parallel.ParIterable: ...
    _endsWith__S = typing.TypeVar('_endsWith__S')  # <S>
    def endsWith(self, that: scala.collection.GenSeq[_endsWith__S]) -> bool: ...
    def equals(self, that: typing.Any) -> bool: ...
    def exists(self, p: scala.Function1[typing.Any, typing.Any]) -> bool: ...
    def filter(self, pred: scala.Function1) -> scala.collection.parallel.ParIterable: ...
    def filterNot(self, pred: scala.Function1) -> scala.collection.parallel.ParIterable: ...
    def find(self, p: scala.Function1[typing.Any, typing.Any]) -> scala.Option[typing.Any]: ...
    _flatMap__S = typing.TypeVar('_flatMap__S')  # <S>
    _flatMap__That = typing.TypeVar('_flatMap__That')  # <That>
    def flatMap(self, f: scala.Function1[typing.Any, scala.collection.GenTraversableOnce[_flatMap__S]], bf: scala.collection.generic.CanBuildFrom[ParSeq[typing.Any], _flatMap__S, _flatMap__That]) -> _flatMap__That: ...
    def flatten(self, asTraversable: scala.Function1) -> scala.collection.GenTraversable: ...
    _fold__U = typing.TypeVar('_fold__U')  # <U>
    def fold(self, z: _fold__U, op: scala.Function2[_fold__U, _fold__U, _fold__U]) -> _fold__U: ...
    _foldLeft__S = typing.TypeVar('_foldLeft__S')  # <S>
    def foldLeft(self, z: _foldLeft__S, op: scala.Function2[_foldLeft__S, typing.Any, _foldLeft__S]) -> _foldLeft__S: ...
    _foldRight__S = typing.TypeVar('_foldRight__S')  # <S>
    def foldRight(self, z: _foldRight__S, op: scala.Function2[typing.Any, _foldRight__S, _foldRight__S]) -> _foldRight__S: ...
    def forall(self, p: scala.Function1[typing.Any, typing.Any]) -> bool: ...
    _foreach__U = typing.TypeVar('_foreach__U')  # <U>
    def foreach(self, f: scala.Function1[typing.Any, _foreach__U]) -> None: ...
    _genericBuilder__B = typing.TypeVar('_genericBuilder__B')  # <B>
    def genericBuilder(self) -> scala.collection.parallel.Combiner[_genericBuilder__B, ParSeq[_genericBuilder__B]]: ...
    _genericCombiner__B = typing.TypeVar('_genericCombiner__B')  # <B>
    def genericCombiner(self) -> scala.collection.parallel.Combiner[_genericCombiner__B, ParSeq[_genericCombiner__B]]: ...
    _groupBy__K = typing.TypeVar('_groupBy__K')  # <K>
    def groupBy(self, f: scala.Function1[typing.Any, _groupBy__K]) -> 'ParMap'[_groupBy__K, ParSeq[typing.Any]]: ...
    def hasDefiniteSize(self) -> bool: ...
    def hashCode(self) -> int: ...
    def head(self) -> typing.Any: ...
    def headOption(self) -> scala.Option[typing.Any]: ...
    _indexOf_0__B = typing.TypeVar('_indexOf_0__B')  # <B>
    _indexOf_1__B = typing.TypeVar('_indexOf_1__B')  # <B>
    @typing.overload
    def indexOf(self, elem: _indexOf_0__B) -> int: ...
    @typing.overload
    def indexOf(self, elem: _indexOf_1__B, from_: int) -> int: ...
    @typing.overload
    def indexWhere(self, p: scala.Function1[typing.Any, typing.Any]) -> int: ...
    @typing.overload
    def indexWhere(self, p: scala.Function1[typing.Any, typing.Any], from_: int) -> int: ...
    def init(self) -> scala.collection.parallel.ParIterable: ...
    def initTaskSupport(self) -> None: ...
    def intersect(self, that: scala.collection.GenSeq) -> scala.collection.parallel.ParSeq: ...
    def isDefinedAt(self, idx: int) -> bool: ...
    def isEmpty(self) -> bool: ...
    def isStrictSplitterCollection(self) -> bool: ...
    def isTraversableAgain(self) -> bool: ...
    def iterator(self) -> scala.collection.parallel.PreciseSplitter[typing.Any]: ...
    def last(self) -> typing.Any: ...
    _lastIndexOf_0__B = typing.TypeVar('_lastIndexOf_0__B')  # <B>
    _lastIndexOf_1__B = typing.TypeVar('_lastIndexOf_1__B')  # <B>
    @typing.overload
    def lastIndexOf(self, elem: _lastIndexOf_0__B) -> int: ...
    @typing.overload
    def lastIndexOf(self, elem: _lastIndexOf_1__B, end: int) -> int: ...
    @typing.overload
    def lastIndexWhere(self, p: scala.Function1[typing.Any, typing.Any]) -> int: ...
    @typing.overload
    def lastIndexWhere(self, p: scala.Function1[typing.Any, typing.Any], end: int) -> int: ...
    def lastOption(self) -> scala.Option[typing.Any]: ...
    def length(self) -> int: ...
    _map__S = typing.TypeVar('_map__S')  # <S>
    _map__That = typing.TypeVar('_map__That')  # <That>
    def map(self, f: scala.Function1[typing.Any, _map__S], bf: scala.collection.generic.CanBuildFrom[ParSeq[typing.Any], _map__S, _map__That]) -> _map__That: ...
    def max(self, ord: scala.math.Ordering) -> typing.Any: ...
    def maxBy(self, f: scala.Function1, cmp: scala.math.Ordering) -> typing.Any: ...
    def min(self, ord: scala.math.Ordering) -> typing.Any: ...
    def minBy(self, f: scala.Function1, cmp: scala.math.Ordering) -> typing.Any: ...
    @typing.overload
    def mkString(self) -> java.lang.String: ...
    @typing.overload
    def mkString(self, sep: typing.Union[java.lang.String, str]) -> java.lang.String: ...
    @typing.overload
    def mkString(self, start: typing.Union[java.lang.String, str], sep: typing.Union[java.lang.String, str], end: typing.Union[java.lang.String, str]) -> java.lang.String: ...
    def newBuilder(self) -> scala.collection.mutable.Builder[typing.Any, ParSeq[typing.Any]]: ...
    def newCombiner(self) -> scala.collection.parallel.Combiner[typing.Any, ParSeq[typing.Any]]: ...
    def nonEmpty(self) -> bool: ...
    _padTo__U = typing.TypeVar('_padTo__U')  # <U>
    _padTo__That = typing.TypeVar('_padTo__That')  # <That>
    def padTo(self, len: int, elem: _padTo__U, bf: scala.collection.generic.CanBuildFrom[ParSeq[typing.Any], _padTo__U, _padTo__That]) -> _padTo__That: ...
    def par(self) -> scala.collection.parallel.ParIterable: ...
    def parCombiner(self) -> scala.collection.parallel.Combiner[typing.Any, ParSeq[typing.Any]]: ...
    def partition(self, pred: scala.Function1[typing.Any, typing.Any]) -> scala.Tuple2[ParSeq[typing.Any], ParSeq[typing.Any]]: ...
    _patch__U = typing.TypeVar('_patch__U')  # <U>
    _patch__That = typing.TypeVar('_patch__That')  # <That>
    def patch(self, from_: int, patch: scala.collection.GenSeq[_patch__U], replaced: int, bf: scala.collection.generic.CanBuildFrom[ParSeq[typing.Any], _patch__U, _patch__That]) -> _patch__That: ...
    def prefixLength(self, p: scala.Function1[typing.Any, typing.Any]) -> int: ...
    def printDebugBuffer(self) -> None: ...
    _product__U = typing.TypeVar('_product__U')  # <U>
    def product(self, num: scala.math.Numeric[_product__U]) -> _product__U: ...
    def range(self) -> scala.collection.immutable.Range: ...
    _reduce__U = typing.TypeVar('_reduce__U')  # <U>
    def reduce(self, op: scala.Function2[_reduce__U, _reduce__U, _reduce__U]) -> _reduce__U: ...
    _reduceLeft__U = typing.TypeVar('_reduceLeft__U')  # <U>
    def reduceLeft(self, op: scala.Function2[_reduceLeft__U, typing.Any, _reduceLeft__U]) -> _reduceLeft__U: ...
    _reduceLeftOption__U = typing.TypeVar('_reduceLeftOption__U')  # <U>
    def reduceLeftOption(self, op: scala.Function2[_reduceLeftOption__U, typing.Any, _reduceLeftOption__U]) -> scala.Option[_reduceLeftOption__U]: ...
    _reduceOption__U = typing.TypeVar('_reduceOption__U')  # <U>
    def reduceOption(self, op: scala.Function2[_reduceOption__U, _reduceOption__U, _reduceOption__U]) -> scala.Option[_reduceOption__U]: ...
    _reduceRight__U = typing.TypeVar('_reduceRight__U')  # <U>
    def reduceRight(self, op: scala.Function2[typing.Any, _reduceRight__U, _reduceRight__U]) -> _reduceRight__U: ...
    _reduceRightOption__U = typing.TypeVar('_reduceRightOption__U')  # <U>
    def reduceRightOption(self, op: scala.Function2[typing.Any, _reduceRightOption__U, _reduceRightOption__U]) -> scala.Option[_reduceRightOption__U]: ...
    def repr(self) -> scala.collection.parallel.ParIterable: ...
    _reuse__S = typing.TypeVar('_reuse__S')  # <S>
    _reuse__That = typing.TypeVar('_reuse__That')  # <That>
    def reuse(self, oldc: scala.Option[scala.collection.parallel.Combiner[_reuse__S, _reuse__That]], newc: scala.collection.parallel.Combiner[_reuse__S, _reuse__That]) -> scala.collection.parallel.Combiner[_reuse__S, _reuse__That]: ...
    def reverse(self) -> scala.collection.parallel.ParSeq: ...
    _reverseMap__S = typing.TypeVar('_reverseMap__S')  # <S>
    _reverseMap__That = typing.TypeVar('_reverseMap__That')  # <That>
    def reverseMap(self, f: scala.Function1[typing.Any, _reverseMap__S], bf: scala.collection.generic.CanBuildFrom[ParSeq[typing.Any], _reverseMap__S, _reverseMap__That]) -> _reverseMap__That: ...
    _sameElements__U = typing.TypeVar('_sameElements__U')  # <U>
    def sameElements(self, that: scala.collection.GenIterable[_sameElements__U]) -> bool: ...
    def scala$collection$parallel$ParIterableLike$$_tasksupport(self) -> scala.collection.parallel.TaskSupport: ...
    def scala$collection$parallel$ParIterableLike$$_tasksupport_$eq(self, x$1: scala.collection.parallel.TaskSupport) -> None: ...
    _scan__U = typing.TypeVar('_scan__U')  # <U>
    _scan__That = typing.TypeVar('_scan__That')  # <That>
    def scan(self, z: _scan__U, op: scala.Function2[_scan__U, _scan__U, _scan__U], bf: scala.collection.generic.CanBuildFrom[ParSeq[typing.Any], _scan__U, _scan__That]) -> _scan__That: ...
    def scanBlockSize(self) -> int: ...
    _scanLeft__S = typing.TypeVar('_scanLeft__S')  # <S>
    _scanLeft__That = typing.TypeVar('_scanLeft__That')  # <That>
    def scanLeft(self, z: _scanLeft__S, op: scala.Function2[_scanLeft__S, typing.Any, _scanLeft__S], bf: scala.collection.generic.CanBuildFrom[ParSeq[typing.Any], _scanLeft__S, _scanLeft__That]) -> _scanLeft__That: ...
    _scanRight__S = typing.TypeVar('_scanRight__S')  # <S>
    _scanRight__That = typing.TypeVar('_scanRight__That')  # <That>
    def scanRight(self, z: _scanRight__S, op: scala.Function2[typing.Any, _scanRight__S, _scanRight__S], bf: scala.collection.generic.CanBuildFrom[ParSeq[typing.Any], _scanRight__S, _scanRight__That]) -> _scanRight__That: ...
    def segmentLength(self, p: scala.Function1[typing.Any, typing.Any], from_: int) -> int: ...
    def seq(self) -> scala.collection.immutable.Range: ...
    def sequentially(self, b: scala.Function1) -> scala.collection.parallel.ParIterable: ...
    def size(self) -> int: ...
    def sizeHintIfCheap(self) -> int: ...
    def slice(self, unc_from: int, unc_until: int) -> scala.collection.parallel.ParIterable: ...
    def span(self, pred: scala.Function1[typing.Any, typing.Any]) -> scala.Tuple2[ParSeq[typing.Any], ParSeq[typing.Any]]: ...
    def splitAt(self, n: int) -> scala.Tuple2[ParSeq[typing.Any], ParSeq[typing.Any]]: ...
    def splitter(self) -> 'ParRange.ParRangeIterator': ...
    _startsWith_0__B = typing.TypeVar('_startsWith_0__B')  # <B>
    _startsWith_1__S = typing.TypeVar('_startsWith_1__S')  # <S>
    @typing.overload
    def startsWith(self, that: scala.collection.GenSeq[_startsWith_0__B]) -> bool: ...
    @typing.overload
    def startsWith(self, that: scala.collection.GenSeq[_startsWith_1__S], offset: int) -> bool: ...
    def stringPrefix(self) -> java.lang.String: ...
    _sum__U = typing.TypeVar('_sum__U')  # <U>
    def sum(self, num: scala.math.Numeric[_sum__U]) -> _sum__U: ...
    def tail(self) -> scala.collection.parallel.ParIterable: ...
    def take(self, n: int) -> scala.collection.parallel.ParIterable: ...
    def takeWhile(self, pred: scala.Function1) -> scala.collection.parallel.ParIterable: ...
    _task2ops__R = typing.TypeVar('_task2ops__R')  # <R>
    _task2ops__Tp = typing.TypeVar('_task2ops__Tp')  # <Tp>
    def task2ops(self, tsk: scala.collection.parallel.ParIterableLike.StrictSplitterCheckTask[_task2ops__R, _task2ops__Tp]) -> scala.collection.parallel.ParIterableLike.TaskOps[_task2ops__R, _task2ops__Tp]: ...
    def tasksupport(self) -> scala.collection.parallel.TaskSupport: ...
    def tasksupport_$eq(self, ts: scala.collection.parallel.TaskSupport) -> None: ...
    _to__Col = typing.TypeVar('_to__Col')  # <Col>
    def to(self, cbf: scala.collection.generic.CanBuildFrom[scala.runtime.Nothing., typing.Any, _to__Col]) -> _to__Col: ...
    _toArray__U = typing.TypeVar('_toArray__U')  # <U>
    def toArray(self, evidence$1: scala.reflect.ClassTag[_toArray__U]) -> typing.Any: ...
    _toBuffer__U = typing.TypeVar('_toBuffer__U')  # <U>
    def toBuffer(self) -> scala.collection.mutable.Buffer[_toBuffer__U]: ...
    def toIndexedSeq(self) -> scala.collection.immutable.IndexedSeq[typing.Any]: ...
    def toIterable(self) -> ParIterable[typing.Any]: ...
    def toIterator(self) -> scala.collection.Iterator[typing.Any]: ...
    def toList(self) -> scala.collection.immutable.List[typing.Any]: ...
    _toMap__K = typing.TypeVar('_toMap__K')  # <K>
    _toMap__V = typing.TypeVar('_toMap__V')  # <V>
    def toMap(self, ev: scala.Predef..less.colon.less[typing.Any, scala.Tuple2[_toMap__K, _toMap__V]]) -> 'ParMap'[_toMap__K, _toMap__V]: ...
    _toParCollection__U = typing.TypeVar('_toParCollection__U')  # <U>
    _toParCollection__That = typing.TypeVar('_toParCollection__That')  # <That>
    def toParCollection(self, cbf: scala.Function0[scala.collection.parallel.Combiner[_toParCollection__U, _toParCollection__That]]) -> _toParCollection__That: ...
    _toParMap__K = typing.TypeVar('_toParMap__K')  # <K>
    _toParMap__V = typing.TypeVar('_toParMap__V')  # <V>
    _toParMap__That = typing.TypeVar('_toParMap__That')  # <That>
    def toParMap(self, cbf: scala.Function0[scala.collection.parallel.Combiner[scala.Tuple2[_toParMap__K, _toParMap__V], _toParMap__That]], ev: scala.Predef..less.colon.less[typing.Any, scala.Tuple2[_toParMap__K, _toParMap__V]]) -> _toParMap__That: ...
    def toSeq(self) -> ParSeq[typing.Any]: ...
    _toSet__U = typing.TypeVar('_toSet__U')  # <U>
    def toSet(self) -> ParSet[_toSet__U]: ...
    def toStream(self) -> scala.collection.immutable.Stream[typing.Any]: ...
    def toString(self) -> java.lang.String: ...
    def toTraversable(self) -> scala.collection.GenTraversable[typing.Any]: ...
    def toVector(self) -> scala.collection.immutable.Vector[typing.Any]: ...
    def transpose(self, asTraversable: scala.Function1) -> scala.collection.GenTraversable: ...
    _union__B = typing.TypeVar('_union__B')  # <B>
    _union__That = typing.TypeVar('_union__That')  # <That>
    def union(self, that: scala.collection.GenSeq[_union__B], bf: scala.collection.generic.CanBuildFrom[ParSeq[typing.Any], _union__B, _union__That]) -> _union__That: ...
    _unzip__A1 = typing.TypeVar('_unzip__A1')  # <A1>
    _unzip__A2 = typing.TypeVar('_unzip__A2')  # <A2>
    def unzip(self, asPair: scala.Function1[typing.Any, scala.Tuple2[_unzip__A1, _unzip__A2]]) -> scala.Tuple2[ParSeq[_unzip__A1], ParSeq[_unzip__A2]]: ...
    _unzip3__A1 = typing.TypeVar('_unzip3__A1')  # <A1>
    _unzip3__A2 = typing.TypeVar('_unzip3__A2')  # <A2>
    _unzip3__A3 = typing.TypeVar('_unzip3__A3')  # <A3>
    def unzip3(self, asTriple: scala.Function1[typing.Any, scala.Tuple3[_unzip3__A1, _unzip3__A2, _unzip3__A3]]) -> scala.Tuple3[ParSeq[_unzip3__A1], ParSeq[_unzip3__A2], ParSeq[_unzip3__A3]]: ...
    _updated__U = typing.TypeVar('_updated__U')  # <U>
    _updated__That = typing.TypeVar('_updated__That')  # <That>
    def updated(self, index: int, elem: _updated__U, bf: scala.collection.generic.CanBuildFrom[ParSeq[typing.Any], _updated__U, _updated__That]) -> _updated__That: ...
    def view(self) -> scala.collection.SeqView[typing.Any, scala.collection.immutable.Seq[typing.Any]]: ...
    def withFilter(self, pred: scala.Function1) -> scala.collection.parallel.ParIterable: ...
    _wrap__R = typing.TypeVar('_wrap__R')  # <R>
    def wrap(self, body: scala.Function0[_wrap__R]) -> scala.collection.parallel.ParIterableLike.NonDivisible[_wrap__R]: ...
    _zip__U = typing.TypeVar('_zip__U')  # <U>
    _zip__S = typing.TypeVar('_zip__S')  # <S>
    _zip__That = typing.TypeVar('_zip__That')  # <That>
    def zip(self, that: scala.collection.GenIterable[_zip__S], bf: scala.collection.generic.CanBuildFrom[ParSeq[typing.Any], scala.Tuple2[_zip__U, _zip__S], _zip__That]) -> _zip__That: ...
    _zipAll__S = typing.TypeVar('_zipAll__S')  # <S>
    _zipAll__U = typing.TypeVar('_zipAll__U')  # <U>
    _zipAll__That = typing.TypeVar('_zipAll__That')  # <That>
    def zipAll(self, that: scala.collection.GenIterable[_zipAll__S], thisElem: _zipAll__U, thatElem: _zipAll__S, bf: scala.collection.generic.CanBuildFrom[ParSeq[typing.Any], scala.Tuple2[_zipAll__U, _zipAll__S], _zipAll__That]) -> _zipAll__That: ...
    _zipWithIndex__U = typing.TypeVar('_zipWithIndex__U')  # <U>
    _zipWithIndex__That = typing.TypeVar('_zipWithIndex__That')  # <That>
    def zipWithIndex(self, bf: scala.collection.generic.CanBuildFrom[ParSeq[typing.Any], scala.Tuple2[_zipWithIndex__U, typing.Any], _zipWithIndex__That]) -> _zipWithIndex__That: ...
    class ParRangeIterator(scala.collection.parallel.SeqSplitter[typing.Any]):
        $outer: 'ParRange' = ...
        def __init__(self, $outer: 'ParRange', range: scala.collection.immutable.Range): ...
        _$colon$bslash__B = typing.TypeVar('_$colon$bslash__B')  # <B>
        def $colon$bslash(self, z: _.colon.bslash__B, op: scala.Function2[typing.Any, _.colon.bslash__B, _.colon.bslash__B]) -> _.colon.bslash__B: ...
        _$div$colon__B = typing.TypeVar('_$div$colon__B')  # <B>
        def $div$colon(self, z: _.div.colon__B, op: scala.Function2[_.div.colon__B, typing.Any, _.div.colon__B]) -> _.div.colon__B: ...
        _$plus$plus__B = typing.TypeVar('_$plus$plus__B')  # <B>
        def $plus$plus(self, that: scala.Function0[scala.collection.GenTraversableOnce[_.plus.plus__B]]) -> scala.collection.Iterator[_.plus.plus__B]: ...
        def abort(self) -> None: ...
        @typing.overload
        def addString(self, b: scala.collection.mutable.StringBuilder) -> scala.collection.mutable.StringBuilder: ...
        @typing.overload
        def addString(self, b: scala.collection.mutable.StringBuilder, sep: typing.Union[java.lang.String, str]) -> scala.collection.mutable.StringBuilder: ...
        @typing.overload
        def addString(self, b: scala.collection.mutable.StringBuilder, start: typing.Union[java.lang.String, str], sep: typing.Union[java.lang.String, str], end: typing.Union[java.lang.String, str]) -> scala.collection.mutable.StringBuilder: ...
        _aggregate__B = typing.TypeVar('_aggregate__B')  # <B>
        def aggregate(self, z: scala.Function0[_aggregate__B], seqop: scala.Function2[_aggregate__B, typing.Any, _aggregate__B], combop: scala.Function2[_aggregate__B, _aggregate__B, _aggregate__B]) -> _aggregate__B: ...
        _appendParIterable__U = typing.TypeVar('_appendParIterable__U')  # <U>
        _appendParIterable__PI = typing.TypeVar('_appendParIterable__PI', bound=scala.collection.parallel.IterableSplitter)  # <PI>
        def appendParIterable(self, that: _appendParIterable__PI) -> scala.collection.parallel.IterableSplitter.Appended[_appendParIterable__U, _appendParIterable__PI]: ...
        _appendParSeq__U = typing.TypeVar('_appendParSeq__U')  # <U>
        _appendParSeq__PI = typing.TypeVar('_appendParSeq__PI', bound=scala.collection.parallel.SeqSplitter)  # <PI>
        def appendParSeq(self, that: _appendParSeq__PI) -> scala.collection.parallel.SeqSplitter.Appended[_appendParSeq__U, _appendParSeq__PI]: ...
        def buffered(self) -> scala.collection.BufferedIterator[typing.Any]: ...
        def buildString(self, closure: scala.Function1[scala.Function1[typing.Union[java.lang.String, str], scala.runtime.BoxedUnit], scala.runtime.BoxedUnit]) -> java.lang.String: ...
        _collect__B = typing.TypeVar('_collect__B')  # <B>
        def collect(self, pf: scala.PartialFunction[typing.Any, _collect__B]) -> scala.collection.Iterator[_collect__B]: ...
        _collect2combiner__S = typing.TypeVar('_collect2combiner__S')  # <S>
        _collect2combiner__That = typing.TypeVar('_collect2combiner__That')  # <That>
        def collect2combiner(self, pf: scala.PartialFunction[typing.Any, _collect2combiner__S], cb: scala.collection.parallel.Combiner[_collect2combiner__S, _collect2combiner__That]) -> scala.collection.parallel.Combiner[_collect2combiner__S, _collect2combiner__That]: ...
        _collectFirst__B = typing.TypeVar('_collectFirst__B')  # <B>
        def collectFirst(self, pf: scala.PartialFunction[typing.Any, _collectFirst__B]) -> scala.Option[_collectFirst__B]: ...
        def contains(self, elem: typing.Any) -> bool: ...
        _copy2builder__U = typing.TypeVar('_copy2builder__U')  # <U>
        _copy2builder__Coll = typing.TypeVar('_copy2builder__Coll')  # <Coll>
        _copy2builder__Bld = typing.TypeVar('_copy2builder__Bld', bound=scala.collection.mutable.Builder)  # <Bld>
        def copy2builder(self, b: _copy2builder__Bld) -> _copy2builder__Bld: ...
        _copyToArray_0__B = typing.TypeVar('_copyToArray_0__B')  # <B>
        _copyToArray_1__B = typing.TypeVar('_copyToArray_1__B')  # <B>
        _copyToArray_2__U = typing.TypeVar('_copyToArray_2__U')  # <U>
        @typing.overload
        def copyToArray(self, xs: typing.Any) -> None: ...
        @typing.overload
        def copyToArray(self, xs: typing.Any, start: int) -> None: ...
        @typing.overload
        def copyToArray(self, array: typing.Any, from_: int, len: int) -> None: ...
        _copyToBuffer__B = typing.TypeVar('_copyToBuffer__B')  # <B>
        def copyToBuffer(self, dest: scala.collection.mutable.Buffer[_copyToBuffer__B]) -> None: ...
        _corresponds_0__S = typing.TypeVar('_corresponds_0__S')  # <S>
        _corresponds_1__B = typing.TypeVar('_corresponds_1__B')  # <B>
        @typing.overload
        def corresponds(self, corr: scala.Function2[typing.Any, _corresponds_0__S, typing.Any], that: scala.collection.Iterator[_corresponds_0__S]) -> bool: ...
        @typing.overload
        def corresponds(self, that: scala.collection.GenTraversableOnce[_corresponds_1__B], p: scala.Function2[typing.Any, _corresponds_1__B, typing.Any]) -> bool: ...
        def count(self, p: scala.Function1[typing.Any, typing.Any]) -> int: ...
        def debugInformation(self) -> java.lang.String: ...
        def drop(self, n: int) -> scala.collection.parallel.IterableSplitter[typing.Any]: ...
        _drop2combiner__U = typing.TypeVar('_drop2combiner__U')  # <U>
        _drop2combiner__This = typing.TypeVar('_drop2combiner__This')  # <This>
        def drop2combiner(self, n: int, cb: scala.collection.parallel.Combiner[_drop2combiner__U, _drop2combiner__This]) -> scala.collection.parallel.Combiner[_drop2combiner__U, _drop2combiner__This]: ...
        def dropWhile(self, p: scala.Function1[typing.Any, typing.Any]) -> scala.collection.Iterator[typing.Any]: ...
        def dup(self) -> 'ParRange.ParRangeIterator': ...
        def duplicate(self) -> scala.Tuple2[scala.collection.Iterator[typing.Any], scala.collection.Iterator[typing.Any]]: ...
        def exists(self, p: scala.Function1[typing.Any, typing.Any]) -> bool: ...
        def filter(self, p: scala.Function1[typing.Any, typing.Any]) -> scala.collection.Iterator[typing.Any]: ...
        _filter2combiner__U = typing.TypeVar('_filter2combiner__U')  # <U>
        _filter2combiner__This = typing.TypeVar('_filter2combiner__This')  # <This>
        def filter2combiner(self, pred: scala.Function1[typing.Any, typing.Any], cb: scala.collection.parallel.Combiner[_filter2combiner__U, _filter2combiner__This]) -> scala.collection.parallel.Combiner[_filter2combiner__U, _filter2combiner__This]: ...
        def filterNot(self, p: scala.Function1[typing.Any, typing.Any]) -> scala.collection.Iterator[typing.Any]: ...
        _filterNot2combiner__U = typing.TypeVar('_filterNot2combiner__U')  # <U>
        _filterNot2combiner__This = typing.TypeVar('_filterNot2combiner__This')  # <This>
        def filterNot2combiner(self, pred: scala.Function1[typing.Any, typing.Any], cb: scala.collection.parallel.Combiner[_filterNot2combiner__U, _filterNot2combiner__This]) -> scala.collection.parallel.Combiner[_filterNot2combiner__U, _filterNot2combiner__This]: ...
        def find(self, p: scala.Function1[typing.Any, typing.Any]) -> scala.Option[typing.Any]: ...
        _flatMap__B = typing.TypeVar('_flatMap__B')  # <B>
        def flatMap(self, f: scala.Function1[typing.Any, scala.collection.GenTraversableOnce[_flatMap__B]]) -> scala.collection.Iterator[_flatMap__B]: ...
        _flatmap2combiner__S = typing.TypeVar('_flatmap2combiner__S')  # <S>
        _flatmap2combiner__That = typing.TypeVar('_flatmap2combiner__That')  # <That>
        def flatmap2combiner(self, f: scala.Function1[typing.Any, scala.collection.GenTraversableOnce[_flatmap2combiner__S]], cb: scala.collection.parallel.Combiner[_flatmap2combiner__S, _flatmap2combiner__That]) -> scala.collection.parallel.Combiner[_flatmap2combiner__S, _flatmap2combiner__That]: ...
        _fold__U = typing.TypeVar('_fold__U')  # <U>
        def fold(self, z: _fold__U, op: scala.Function2[_fold__U, _fold__U, _fold__U]) -> _fold__U: ...
        _foldLeft__B = typing.TypeVar('_foldLeft__B')  # <B>
        def foldLeft(self, z: _foldLeft__B, op: scala.Function2[_foldLeft__B, typing.Any, _foldLeft__B]) -> _foldLeft__B: ...
        _foldRight__B = typing.TypeVar('_foldRight__B')  # <B>
        def foldRight(self, z: _foldRight__B, op: scala.Function2[typing.Any, _foldRight__B, _foldRight__B]) -> _foldRight__B: ...
        def forall(self, p: scala.Function1[typing.Any, typing.Any]) -> bool: ...
        _foreach__U = typing.TypeVar('_foreach__U')  # <U>
        def foreach(self, f: scala.Function1[typing.Any, _foreach__U]) -> None: ...
        _grouped__B = typing.TypeVar('_grouped__B')  # <B>
        def grouped(self, size: int) -> scala.collection.Iterator.GroupedIterator[_grouped__B]: ...
        def hasDefiniteSize(self) -> bool: ...
        def hasNext(self) -> bool: ...
        def indexFlag(self) -> int: ...
        _indexOf_0__B = typing.TypeVar('_indexOf_0__B')  # <B>
        _indexOf_1__B = typing.TypeVar('_indexOf_1__B')  # <B>
        @typing.overload
        def indexOf(self, elem: _indexOf_0__B) -> int: ...
        @typing.overload
        def indexOf(self, elem: _indexOf_1__B, from_: int) -> int: ...
        @typing.overload
        def indexWhere(self, pred: scala.Function1[typing.Any, typing.Any]) -> int: ...
        @typing.overload
        def indexWhere(self, p: scala.Function1[typing.Any, typing.Any], from_: int) -> int: ...
        def isAborted(self) -> bool: ...
        def isEmpty(self) -> bool: ...
        def isRemainingCheap(self) -> bool: ...
        def isTraversableAgain(self) -> bool: ...
        def lastIndexWhere(self, pred: scala.Function1[typing.Any, typing.Any]) -> int: ...
        def length(self) -> int: ...
        _map__S = typing.TypeVar('_map__S')  # <S>
        def map(self, f: scala.Function1[typing.Any, _map__S]) -> scala.collection.parallel.SeqSplitter.Mapped[_map__S]: ...
        _map2combiner__S = typing.TypeVar('_map2combiner__S')  # <S>
        _map2combiner__That = typing.TypeVar('_map2combiner__That')  # <That>
        def map2combiner(self, f: scala.Function1[typing.Any, _map2combiner__S], cb: scala.collection.parallel.Combiner[_map2combiner__S, _map2combiner__That]) -> scala.collection.parallel.Combiner[_map2combiner__S, _map2combiner__That]: ...
        def max(self, ord: scala.math.Ordering) -> typing.Any: ...
        def maxBy(self, f: scala.Function1, cmp: scala.math.Ordering) -> typing.Any: ...
        def min(self, ord: scala.math.Ordering) -> typing.Any: ...
        def minBy(self, f: scala.Function1, cmp: scala.math.Ordering) -> typing.Any: ...
        @typing.overload
        def mkString(self) -> java.lang.String: ...
        @typing.overload
        def mkString(self, sep: typing.Union[java.lang.String, str]) -> java.lang.String: ...
        @typing.overload
        def mkString(self, start: typing.Union[java.lang.String, str], sep: typing.Union[java.lang.String, str], end: typing.Union[java.lang.String, str]) -> java.lang.String: ...
        _newSliceInternal__U = typing.TypeVar('_newSliceInternal__U', bound=scala.collection.parallel.IterableSplitter.Taken)  # <U>
        def newSliceInternal(self, it: _newSliceInternal__U, from1: int) -> _newSliceInternal__U: ...
        def newTaken(self, until: int) -> scala.collection.parallel.SeqSplitter.Taken: ...
        def next(self) -> int: ...
        def nonEmpty(self) -> bool: ...
        _padTo__A1 = typing.TypeVar('_padTo__A1')  # <A1>
        def padTo(self, len: int, elem: _padTo__A1) -> scala.collection.Iterator[_padTo__A1]: ...
        def partition(self, p: scala.Function1[typing.Any, typing.Any]) -> scala.Tuple2[scala.collection.Iterator[typing.Any], scala.collection.Iterator[typing.Any]]: ...
        _partition2combiners__U = typing.TypeVar('_partition2combiners__U')  # <U>
        _partition2combiners__This = typing.TypeVar('_partition2combiners__This')  # <This>
        def partition2combiners(self, pred: scala.Function1[typing.Any, typing.Any], btrue: scala.collection.parallel.Combiner[_partition2combiners__U, _partition2combiners__This], bfalse: scala.collection.parallel.Combiner[_partition2combiners__U, _partition2combiners__This]) -> scala.Tuple2[scala.collection.parallel.Combiner[_partition2combiners__U, _partition2combiners__This], scala.collection.parallel.Combiner[_partition2combiners__U, _partition2combiners__This]]: ...
        _patch__B = typing.TypeVar('_patch__B')  # <B>
        def patch(self, from_: int, patchElems: scala.collection.Iterator[_patch__B], replaced: int) -> scala.collection.Iterator[_patch__B]: ...
        _patchParSeq__U = typing.TypeVar('_patchParSeq__U')  # <U>
        def patchParSeq(self, from_: int, patchElems: scala.collection.parallel.SeqSplitter[_patchParSeq__U], replaced: int) -> scala.collection.parallel.SeqSplitter.Patched[_patchParSeq__U]: ...
        def prefixLength(self, pred: scala.Function1[typing.Any, typing.Any]) -> int: ...
        _product__U = typing.TypeVar('_product__U')  # <U>
        def product(self, num: scala.math.Numeric[_product__U]) -> _product__U: ...
        def psplit(self, sizes: scala.collection.Seq[typing.Any]) -> scala.collection.Seq[scala.collection.parallel.SeqSplitter[typing.Any]]: ...
        def psplitWithSignalling(self, sizes: scala.collection.Seq[typing.Any]) -> scala.collection.Seq[scala.collection.parallel.SeqSplitter[typing.Any]]: ...
        _reduce__U = typing.TypeVar('_reduce__U')  # <U>
        def reduce(self, op: scala.Function2[_reduce__U, _reduce__U, _reduce__U]) -> _reduce__U: ...
        _reduceLeft_0__U = typing.TypeVar('_reduceLeft_0__U')  # <U>
        _reduceLeft_1__B = typing.TypeVar('_reduceLeft_1__B')  # <B>
        @typing.overload
        def reduceLeft(self, howmany: int, op: scala.Function2[_reduceLeft_0__U, _reduceLeft_0__U, _reduceLeft_0__U]) -> _reduceLeft_0__U: ...
        @typing.overload
        def reduceLeft(self, op: scala.Function2[_reduceLeft_1__B, typing.Any, _reduceLeft_1__B]) -> _reduceLeft_1__B: ...
        _reduceLeftOption__B = typing.TypeVar('_reduceLeftOption__B')  # <B>
        def reduceLeftOption(self, op: scala.Function2[_reduceLeftOption__B, typing.Any, _reduceLeftOption__B]) -> scala.Option[_reduceLeftOption__B]: ...
        _reduceOption__A1 = typing.TypeVar('_reduceOption__A1')  # <A1>
        def reduceOption(self, op: scala.Function2[_reduceOption__A1, _reduceOption__A1, _reduceOption__A1]) -> scala.Option[_reduceOption__A1]: ...
        _reduceRight__B = typing.TypeVar('_reduceRight__B')  # <B>
        def reduceRight(self, op: scala.Function2[typing.Any, _reduceRight__B, _reduceRight__B]) -> _reduceRight__B: ...
        _reduceRightOption__B = typing.TypeVar('_reduceRightOption__B')  # <B>
        def reduceRightOption(self, op: scala.Function2[typing.Any, _reduceRightOption__B, _reduceRightOption__B]) -> scala.Option[_reduceRightOption__B]: ...
        def remaining(self) -> int: ...
        def reverse(self) -> scala.collection.parallel.SeqSplitter[typing.Any]: ...
        _reverse2combiner__U = typing.TypeVar('_reverse2combiner__U')  # <U>
        _reverse2combiner__This = typing.TypeVar('_reverse2combiner__This')  # <This>
        def reverse2combiner(self, cb: scala.collection.parallel.Combiner[_reverse2combiner__U, _reverse2combiner__This]) -> scala.collection.parallel.Combiner[_reverse2combiner__U, _reverse2combiner__This]: ...
        _reverseMap2combiner__S = typing.TypeVar('_reverseMap2combiner__S')  # <S>
        _reverseMap2combiner__That = typing.TypeVar('_reverseMap2combiner__That')  # <That>
        def reverseMap2combiner(self, f: scala.Function1[typing.Any, _reverseMap2combiner__S], cb: scala.collection.parallel.Combiner[_reverseMap2combiner__S, _reverseMap2combiner__That]) -> scala.collection.parallel.Combiner[_reverseMap2combiner__S, _reverseMap2combiner__That]: ...
        def reversed(self) -> scala.collection.immutable.List[typing.Any]: ...
        def sameElements(self, that: scala.collection.Iterator[typing.Any]) -> bool: ...
        _scanLeft__B = typing.TypeVar('_scanLeft__B')  # <B>
        def scanLeft(self, z: _scanLeft__B, op: scala.Function2[_scanLeft__B, typing.Any, _scanLeft__B]) -> scala.collection.Iterator[_scanLeft__B]: ...
        _scanRight__B = typing.TypeVar('_scanRight__B')  # <B>
        def scanRight(self, z: _scanRight__B, op: scala.Function2[typing.Any, _scanRight__B, _scanRight__B]) -> scala.collection.Iterator[_scanRight__B]: ...
        _scanToArray__U = typing.TypeVar('_scanToArray__U')  # <U>
        _scanToArray__A = typing.TypeVar('_scanToArray__A')  # <A>
        def scanToArray(self, z: _scanToArray__U, op: scala.Function2[_scanToArray__U, _scanToArray__U, _scanToArray__U], array: typing.Any, from_: int) -> None: ...
        _scanToCombiner_0__U = typing.TypeVar('_scanToCombiner_0__U')  # <U>
        _scanToCombiner_0__That = typing.TypeVar('_scanToCombiner_0__That')  # <That>
        _scanToCombiner_1__U = typing.TypeVar('_scanToCombiner_1__U')  # <U>
        _scanToCombiner_1__That = typing.TypeVar('_scanToCombiner_1__That')  # <That>
        @typing.overload
        def scanToCombiner(self, howmany: int, startValue: _scanToCombiner_0__U, op: scala.Function2[_scanToCombiner_0__U, _scanToCombiner_0__U, _scanToCombiner_0__U], cb: scala.collection.parallel.Combiner[_scanToCombiner_0__U, _scanToCombiner_0__That]) -> scala.collection.parallel.Combiner[_scanToCombiner_0__U, _scanToCombiner_0__That]: ...
        @typing.overload
        def scanToCombiner(self, startValue: _scanToCombiner_1__U, op: scala.Function2[_scanToCombiner_1__U, _scanToCombiner_1__U, _scanToCombiner_1__U], cb: scala.collection.parallel.Combiner[_scanToCombiner_1__U, _scanToCombiner_1__That]) -> scala.collection.parallel.Combiner[_scanToCombiner_1__U, _scanToCombiner_1__That]: ...
        def seq(self) -> scala.collection.Iterator[typing.Any]: ...
        def setIndexFlag(self, f: int) -> None: ...
        def setIndexFlagIfGreater(self, f: int) -> None: ...
        def setIndexFlagIfLesser(self, f: int) -> None: ...
        _shouldSplitFurther__S = typing.TypeVar('_shouldSplitFurther__S')  # <S>
        def shouldSplitFurther(self, coll: scala.collection.parallel.ParIterable[_shouldSplitFurther__S], parallelismLevel: int) -> bool: ...
        def signalDelegate(self) -> scala.collection.generic.Signalling: ...
        def signalDelegate_$eq(self, x$1: scala.collection.generic.Signalling) -> None: ...
        def size(self) -> int: ...
        def sizeHintIfCheap(self) -> int: ...
        def slice(self, from1: int, until1: int) -> scala.collection.parallel.SeqSplitter[typing.Any]: ...
        _slice2combiner__U = typing.TypeVar('_slice2combiner__U')  # <U>
        _slice2combiner__This = typing.TypeVar('_slice2combiner__This')  # <This>
        def slice2combiner(self, from_: int, until: int, cb: scala.collection.parallel.Combiner[_slice2combiner__U, _slice2combiner__This]) -> scala.collection.parallel.Combiner[_slice2combiner__U, _slice2combiner__This]: ...
        def sliceIterator(self, from_: int, until: int) -> scala.collection.Iterator[typing.Any]: ...
        _sliding__B = typing.TypeVar('_sliding__B')  # <B>
        def sliding(self, size: int, step: int) -> scala.collection.Iterator.GroupedIterator[_sliding__B]: ...
        _sliding$default$2__B = typing.TypeVar('_sliding$default$2__B')  # <B>
        def sliding$default$2(self) -> int: ...
        def span(self, p: scala.Function1[typing.Any, typing.Any]) -> scala.Tuple2[scala.collection.Iterator[typing.Any], scala.collection.Iterator[typing.Any]]: ...
        _span2combiners__U = typing.TypeVar('_span2combiners__U')  # <U>
        _span2combiners__This = typing.TypeVar('_span2combiners__This')  # <This>
        def span2combiners(self, p: scala.Function1[typing.Any, typing.Any], before: scala.collection.parallel.Combiner[_span2combiners__U, _span2combiners__This], after: scala.collection.parallel.Combiner[_span2combiners__U, _span2combiners__This]) -> scala.Tuple2[scala.collection.parallel.Combiner[_span2combiners__U, _span2combiners__This], scala.collection.parallel.Combiner[_span2combiners__U, _span2combiners__This]]: ...
        def split(self) -> scala.collection.Seq[scala.collection.parallel.SeqSplitter[typing.Any]]: ...
        _splitAt2combiners__U = typing.TypeVar('_splitAt2combiners__U')  # <U>
        _splitAt2combiners__This = typing.TypeVar('_splitAt2combiners__This')  # <This>
        def splitAt2combiners(self, at: int, before: scala.collection.parallel.Combiner[_splitAt2combiners__U, _splitAt2combiners__This], after: scala.collection.parallel.Combiner[_splitAt2combiners__U, _splitAt2combiners__This]) -> scala.Tuple2[scala.collection.parallel.Combiner[_splitAt2combiners__U, _splitAt2combiners__This], scala.collection.parallel.Combiner[_splitAt2combiners__U, _splitAt2combiners__This]]: ...
        def splitWithSignalling(self) -> scala.collection.Seq[scala.collection.parallel.SeqSplitter[typing.Any]]: ...
        _sum__U = typing.TypeVar('_sum__U')  # <U>
        def sum(self, num: scala.math.Numeric[_sum__U]) -> _sum__U: ...
        def tag(self) -> int: ...
        def take(self, n: int) -> scala.collection.parallel.SeqSplitter[typing.Any]: ...
        _take2combiner__U = typing.TypeVar('_take2combiner__U')  # <U>
        _take2combiner__This = typing.TypeVar('_take2combiner__This')  # <This>
        def take2combiner(self, n: int, cb: scala.collection.parallel.Combiner[_take2combiner__U, _take2combiner__This]) -> scala.collection.parallel.Combiner[_take2combiner__U, _take2combiner__This]: ...
        def takeWhile(self, p: scala.Function1[typing.Any, typing.Any]) -> scala.collection.Iterator[typing.Any]: ...
        _takeWhile2combiner__U = typing.TypeVar('_takeWhile2combiner__U')  # <U>
        _takeWhile2combiner__This = typing.TypeVar('_takeWhile2combiner__This')  # <This>
        def takeWhile2combiner(self, p: scala.Function1[typing.Any, typing.Any], cb: scala.collection.parallel.Combiner[_takeWhile2combiner__U, _takeWhile2combiner__This]) -> scala.Tuple2[scala.collection.parallel.Combiner[_takeWhile2combiner__U, _takeWhile2combiner__This], typing.Any]: ...
        _to__Col = typing.TypeVar('_to__Col')  # <Col>
        def to(self, cbf: scala.collection.generic.CanBuildFrom[scala.runtime.Nothing., typing.Any, _to__Col]) -> _to__Col: ...
        _toArray__B = typing.TypeVar('_toArray__B')  # <B>
        def toArray(self, evidence$1: scala.reflect.ClassTag[_toArray__B]) -> typing.Any: ...
        _toBuffer__B = typing.TypeVar('_toBuffer__B')  # <B>
        def toBuffer(self) -> scala.collection.mutable.Buffer[_toBuffer__B]: ...
        def toIndexedSeq(self) -> scala.collection.immutable.IndexedSeq[typing.Any]: ...
        def toIterable(self) -> scala.collection.Iterable[typing.Any]: ...
        def toIterator(self) -> scala.collection.Iterator[typing.Any]: ...
        def toList(self) -> scala.collection.immutable.List[typing.Any]: ...
        _toMap__T = typing.TypeVar('_toMap__T')  # <T>
        _toMap__U = typing.TypeVar('_toMap__U')  # <U>
        def toMap(self, ev: scala.Predef..less.colon.less[typing.Any, scala.Tuple2[_toMap__T, _toMap__U]]) -> scala.collection.immutable.Map[_toMap__T, _toMap__U]: ...
        def toSeq(self) -> scala.collection.Seq[typing.Any]: ...
        _toSet__B = typing.TypeVar('_toSet__B')  # <B>
        def toSet(self) -> scala.collection.immutable.Set[_toSet__B]: ...
        def toStream(self) -> scala.collection.immutable.Stream[typing.Any]: ...
        def toString(self) -> java.lang.String: ...
        def toTraversable(self) -> scala.collection.Traversable[typing.Any]: ...
        def toVector(self) -> scala.collection.immutable.Vector[typing.Any]: ...
        _updated2combiner__U = typing.TypeVar('_updated2combiner__U')  # <U>
        _updated2combiner__That = typing.TypeVar('_updated2combiner__That')  # <That>
        def updated2combiner(self, index: int, elem: _updated2combiner__U, cb: scala.collection.parallel.Combiner[_updated2combiner__U, _updated2combiner__That]) -> scala.collection.parallel.Combiner[_updated2combiner__U, _updated2combiner__That]: ...
        def withFilter(self, p: scala.Function1[typing.Any, typing.Any]) -> scala.collection.Iterator[typing.Any]: ...
        _zip__B = typing.TypeVar('_zip__B')  # <B>
        def zip(self, that: scala.collection.Iterator[_zip__B]) -> scala.collection.Iterator[scala.Tuple2[typing.Any, _zip__B]]: ...
        _zip2combiner__U = typing.TypeVar('_zip2combiner__U')  # <U>
        _zip2combiner__S = typing.TypeVar('_zip2combiner__S')  # <S>
        _zip2combiner__That = typing.TypeVar('_zip2combiner__That')  # <That>
        def zip2combiner(self, otherpit: scala.collection.parallel.RemainsIterator[_zip2combiner__S], cb: scala.collection.parallel.Combiner[scala.Tuple2[_zip2combiner__U, _zip2combiner__S], _zip2combiner__That]) -> scala.collection.parallel.Combiner[scala.Tuple2[_zip2combiner__U, _zip2combiner__S], _zip2combiner__That]: ...
        _zipAll__B = typing.TypeVar('_zipAll__B')  # <B>
        _zipAll__A1 = typing.TypeVar('_zipAll__A1')  # <A1>
        _zipAll__B1 = typing.TypeVar('_zipAll__B1')  # <B1>
        def zipAll(self, that: scala.collection.Iterator[_zipAll__B], thisElem: _zipAll__A1, thatElem: _zipAll__B1) -> scala.collection.Iterator[scala.Tuple2[_zipAll__A1, _zipAll__B1]]: ...
        _zipAll2combiner__U = typing.TypeVar('_zipAll2combiner__U')  # <U>
        _zipAll2combiner__S = typing.TypeVar('_zipAll2combiner__S')  # <S>
        _zipAll2combiner__That = typing.TypeVar('_zipAll2combiner__That')  # <That>
        def zipAll2combiner(self, that: scala.collection.parallel.RemainsIterator[_zipAll2combiner__S], thiselem: _zipAll2combiner__U, thatelem: _zipAll2combiner__S, cb: scala.collection.parallel.Combiner[scala.Tuple2[_zipAll2combiner__U, _zipAll2combiner__S], _zipAll2combiner__That]) -> scala.collection.parallel.Combiner[scala.Tuple2[_zipAll2combiner__U, _zipAll2combiner__S], _zipAll2combiner__That]: ...
        _zipAllParSeq__S = typing.TypeVar('_zipAllParSeq__S')  # <S>
        _zipAllParSeq__U = typing.TypeVar('_zipAllParSeq__U')  # <U>
        _zipAllParSeq__R = typing.TypeVar('_zipAllParSeq__R')  # <R>
        def zipAllParSeq(self, that: scala.collection.parallel.SeqSplitter[_zipAllParSeq__S], thisElem: _zipAllParSeq__U, thatElem: _zipAllParSeq__R) -> scala.collection.parallel.SeqSplitter.ZippedAll[_zipAllParSeq__U, _zipAllParSeq__R]: ...
        _zipParSeq__S = typing.TypeVar('_zipParSeq__S')  # <S>
        def zipParSeq(self, that: scala.collection.parallel.SeqSplitter[_zipParSeq__S]) -> scala.collection.parallel.SeqSplitter.Zipped[_zipParSeq__S]: ...
        def zipWithIndex(self) -> scala.collection.Iterator[scala.Tuple2[typing.Any, typing.Any]]: ...
    class ParRangeIterator$:
        def __init__(self, $outer: 'ParRange'): ...
        def $lessinit$greater$default$1(self) -> scala.collection.immutable.Range: ...

_ParVector__T = typing.TypeVar('_ParVector__T')  # <T>
class ParVector(ParSeq[_ParVector__T], scala.Serializable, typing.Generic[_ParVector__T]):
    @typing.overload
    def __init__(self): ...
    @typing.overload
    def __init__(self, vector: scala.collection.immutable.Vector[_ParVector__T]): ...
    _$colon$bslash__S = typing.TypeVar('_$colon$bslash__S')  # <S>
    def $colon$bslash(self, z: _.colon.bslash__S, op: scala.Function2[_ParVector__T, _.colon.bslash__S, _.colon.bslash__S]) -> _.colon.bslash__S: ...
    _$colon$plus__U = typing.TypeVar('_$colon$plus__U')  # <U>
    _$colon$plus__That = typing.TypeVar('_$colon$plus__That')  # <That>
    def $colon$plus(self, elem: _.colon.plus__U, bf: scala.collection.generic.CanBuildFrom['ParVector'[_ParVector__T], _.colon.plus__U, _.colon.plus__That]) -> _.colon.plus__That: ...
    _$div$colon__S = typing.TypeVar('_$div$colon__S')  # <S>
    def $div$colon(self, z: _.div.colon__S, op: scala.Function2[_.div.colon__S, _ParVector__T, _.div.colon__S]) -> _.div.colon__S: ...
    _$plus$colon__U = typing.TypeVar('_$plus$colon__U')  # <U>
    _$plus$colon__That = typing.TypeVar('_$plus$colon__That')  # <That>
    def $plus$colon(self, elem: _.plus.colon__U, bf: scala.collection.generic.CanBuildFrom['ParVector'[_ParVector__T], _.plus.colon__U, _.plus.colon__That]) -> _.plus.colon__That: ...
    _$plus$plus__U = typing.TypeVar('_$plus$plus__U')  # <U>
    _$plus$plus__That = typing.TypeVar('_$plus$plus__That')  # <That>
    def $plus$plus(self, that: scala.collection.GenTraversableOnce[_.plus.plus__U], bf: scala.collection.generic.CanBuildFrom['ParVector'[_ParVector__T], _.plus.plus__U, _.plus.plus__That]) -> _.plus.plus__That: ...
    @staticmethod
    def ReusableCBF() -> scala.collection.generic.GenTraversableFactory.GenericCanBuildFrom[scala.runtime.Nothing.]: ...
    def ScanLeaf(self) -> scala.collection.parallel.ParIterableLike.ScanLeaf.: ...
    def ScanNode(self) -> scala.collection.parallel.ParIterableLike.ScanNode.: ...
    _aggregate__S = typing.TypeVar('_aggregate__S')  # <S>
    def aggregate(self, z: scala.Function0[_aggregate__S], seqop: scala.Function2[_aggregate__S, _ParVector__T, _aggregate__S], combop: scala.Function2[_aggregate__S, _aggregate__S, _aggregate__S]) -> _aggregate__S: ...
    def apply(self, idx: int) -> _ParVector__T: ...
    _bf2seq__S = typing.TypeVar('_bf2seq__S')  # <S>
    _bf2seq__That = typing.TypeVar('_bf2seq__That')  # <That>
    def bf2seq(self, bf: scala.collection.generic.CanBuildFrom['ParVector'[_ParVector__T], _bf2seq__S, _bf2seq__That]) -> scala.collection.generic.CanBuildFrom[scala.collection.immutable.Vector[_ParVector__T], _bf2seq__S, _bf2seq__That]: ...
    def brokenInvariants(self) -> scala.collection.Seq[java.lang.String]: ...
    _builder2ops__Elem = typing.TypeVar('_builder2ops__Elem')  # <Elem>
    _builder2ops__To = typing.TypeVar('_builder2ops__To')  # <To>
    def builder2ops(self, cb: scala.collection.mutable.Builder[_builder2ops__Elem, _builder2ops__To]) -> scala.collection.parallel.ParIterableLike.BuilderOps[_builder2ops__Elem, _builder2ops__To]: ...
    _canBuildFrom__T = typing.TypeVar('_canBuildFrom__T')  # <T>
    @staticmethod
    def canBuildFrom() -> scala.collection.generic.CanCombineFrom['ParVector'[typing.Any], _canBuildFrom__T, 'ParVector'[_canBuildFrom__T]]: ...
    def canEqual(self, other: typing.Any) -> bool: ...
    _collect__S = typing.TypeVar('_collect__S')  # <S>
    _collect__That = typing.TypeVar('_collect__That')  # <That>
    def collect(self, pf: scala.PartialFunction[_ParVector__T, _collect__S], bf: scala.collection.generic.CanBuildFrom['ParVector'[_ParVector__T], _collect__S, _collect__That]) -> _collect__That: ...
    _combinerFactory_1__S = typing.TypeVar('_combinerFactory_1__S')  # <S>
    _combinerFactory_1__That = typing.TypeVar('_combinerFactory_1__That')  # <That>
    @typing.overload
    def combinerFactory(self) -> scala.collection.parallel.CombinerFactory[_ParVector__T, 'ParVector'[_ParVector__T]]: ...
    @typing.overload
    def combinerFactory(self, cbf: scala.Function0[scala.collection.parallel.Combiner[_combinerFactory_1__S, _combinerFactory_1__That]]) -> scala.collection.parallel.CombinerFactory[_combinerFactory_1__S, _combinerFactory_1__That]: ...
    def companion(self) -> 'ParVector.': ...
    @staticmethod
    def concat(xss: scala.collection.Seq) -> scala.collection.GenTraversable: ...
    _copyToArray_0__U = typing.TypeVar('_copyToArray_0__U')  # <U>
    _copyToArray_1__U = typing.TypeVar('_copyToArray_1__U')  # <U>
    _copyToArray_2__U = typing.TypeVar('_copyToArray_2__U')  # <U>
    @typing.overload
    def copyToArray(self, xs: typing.Any) -> None: ...
    @typing.overload
    def copyToArray(self, xs: typing.Any, start: int) -> None: ...
    @typing.overload
    def copyToArray(self, xs: typing.Any, start: int, len: int) -> None: ...
    _corresponds__S = typing.TypeVar('_corresponds__S')  # <S>
    def corresponds(self, that: scala.collection.GenSeq[_corresponds__S], p: scala.Function2[_ParVector__T, _corresponds__S, typing.Any]) -> bool: ...
    def count(self, p: scala.Function1[_ParVector__T, typing.Any]) -> int: ...
    def debugBuffer(self) -> scala.collection.mutable.ArrayBuffer[java.lang.String]: ...
    def debugInformation(self) -> java.lang.String: ...
    def debugclear(self) -> None: ...
    def debuglog(self, s: typing.Union[java.lang.String, str]) -> scala.collection.mutable.ArrayBuffer[java.lang.String]: ...
    _delegatedSignalling2ops__PI = typing.TypeVar('_delegatedSignalling2ops__PI', bound=scala.collection.generic.DelegatedSignalling)  # <PI>
    def delegatedSignalling2ops(self, it: _delegatedSignalling2ops__PI) -> scala.collection.parallel.ParIterableLike.SignallingOps[_delegatedSignalling2ops__PI]: ...
    def diff(self, that: scala.collection.GenSeq) -> scala.collection.parallel.ParSeq: ...
    def distinct(self) -> scala.collection.parallel.ParSeq: ...
    def down(self, p: scala.collection.parallel.IterableSplitter[typing.Any]) -> scala.collection.parallel.SeqSplitter[_ParVector__T]: ...
    def drop(self, n: int) -> scala.collection.parallel.ParIterable: ...
    def dropWhile(self, pred: scala.Function1) -> scala.collection.parallel.ParIterable: ...
    @staticmethod
    def empty() -> scala.collection.GenTraversable: ...
    _endsWith__S = typing.TypeVar('_endsWith__S')  # <S>
    def endsWith(self, that: scala.collection.GenSeq[_endsWith__S]) -> bool: ...
    def equals(self, that: typing.Any) -> bool: ...
    def exists(self, p: scala.Function1[_ParVector__T, typing.Any]) -> bool: ...
    @typing.overload
    @staticmethod
    def fill(n1: int, n2: int, n3: int, n4: int, n5: int, elem: scala.Function0) -> scala.collection.GenTraversable: ...
    @typing.overload
    @staticmethod
    def fill(n1: int, n2: int, n3: int, n4: int, elem: scala.Function0) -> scala.collection.GenTraversable: ...
    @typing.overload
    @staticmethod
    def fill(n1: int, n2: int, n3: int, elem: scala.Function0) -> scala.collection.GenTraversable: ...
    @typing.overload
    @staticmethod
    def fill(n1: int, n2: int, elem: scala.Function0) -> scala.collection.GenTraversable: ...
    @typing.overload
    @staticmethod
    def fill(n: int, elem: scala.Function0) -> scala.collection.GenTraversable: ...
    def filter(self, pred: scala.Function1) -> scala.collection.parallel.ParIterable: ...
    def filterNot(self, pred: scala.Function1) -> scala.collection.parallel.ParIterable: ...
    def find(self, p: scala.Function1[_ParVector__T, typing.Any]) -> scala.Option[_ParVector__T]: ...
    _flatMap__S = typing.TypeVar('_flatMap__S')  # <S>
    _flatMap__That = typing.TypeVar('_flatMap__That')  # <That>
    def flatMap(self, f: scala.Function1[_ParVector__T, scala.collection.GenTraversableOnce[_flatMap__S]], bf: scala.collection.generic.CanBuildFrom['ParVector'[_ParVector__T], _flatMap__S, _flatMap__That]) -> _flatMap__That: ...
    def flatten(self, asTraversable: scala.Function1) -> scala.collection.GenTraversable: ...
    _fold__U = typing.TypeVar('_fold__U')  # <U>
    def fold(self, z: _fold__U, op: scala.Function2[_fold__U, _fold__U, _fold__U]) -> _fold__U: ...
    _foldLeft__S = typing.TypeVar('_foldLeft__S')  # <S>
    def foldLeft(self, z: _foldLeft__S, op: scala.Function2[_foldLeft__S, _ParVector__T, _foldLeft__S]) -> _foldLeft__S: ...
    _foldRight__S = typing.TypeVar('_foldRight__S')  # <S>
    def foldRight(self, z: _foldRight__S, op: scala.Function2[_ParVector__T, _foldRight__S, _foldRight__S]) -> _foldRight__S: ...
    def forall(self, p: scala.Function1[_ParVector__T, typing.Any]) -> bool: ...
    _foreach__U = typing.TypeVar('_foreach__U')  # <U>
    def foreach(self, f: scala.Function1[_ParVector__T, _foreach__U]) -> None: ...
    _genericBuilder__B = typing.TypeVar('_genericBuilder__B')  # <B>
    def genericBuilder(self) -> scala.collection.parallel.Combiner[_genericBuilder__B, 'ParVector'[_genericBuilder__B]]: ...
    _genericCombiner__B = typing.TypeVar('_genericCombiner__B')  # <B>
    def genericCombiner(self) -> scala.collection.parallel.Combiner[_genericCombiner__B, 'ParVector'[_genericCombiner__B]]: ...
    _groupBy__K = typing.TypeVar('_groupBy__K')  # <K>
    def groupBy(self, f: scala.Function1[_ParVector__T, _groupBy__K]) -> 'ParMap'[_groupBy__K, 'ParVector'[_ParVector__T]]: ...
    def hasDefiniteSize(self) -> bool: ...
    def hashCode(self) -> int: ...
    def head(self) -> _ParVector__T: ...
    def headOption(self) -> scala.Option[_ParVector__T]: ...
    _indexOf_0__B = typing.TypeVar('_indexOf_0__B')  # <B>
    _indexOf_1__B = typing.TypeVar('_indexOf_1__B')  # <B>
    @typing.overload
    def indexOf(self, elem: _indexOf_0__B) -> int: ...
    @typing.overload
    def indexOf(self, elem: _indexOf_1__B, from_: int) -> int: ...
    @typing.overload
    def indexWhere(self, p: scala.Function1[_ParVector__T, typing.Any]) -> int: ...
    @typing.overload
    def indexWhere(self, p: scala.Function1[_ParVector__T, typing.Any], from_: int) -> int: ...
    def init(self) -> scala.collection.parallel.ParIterable: ...
    def initTaskSupport(self) -> None: ...
    def intersect(self, that: scala.collection.GenSeq) -> scala.collection.parallel.ParSeq: ...
    def isDefinedAt(self, idx: int) -> bool: ...
    def isEmpty(self) -> bool: ...
    def isStrictSplitterCollection(self) -> bool: ...
    def isTraversableAgain(self) -> bool: ...
    @staticmethod
    def iterate(start: typing.Any, len: int, f: scala.Function1) -> scala.collection.GenTraversable: ...
    def iterator(self) -> scala.collection.parallel.PreciseSplitter[_ParVector__T]: ...
    def last(self) -> _ParVector__T: ...
    _lastIndexOf_0__B = typing.TypeVar('_lastIndexOf_0__B')  # <B>
    _lastIndexOf_1__B = typing.TypeVar('_lastIndexOf_1__B')  # <B>
    @typing.overload
    def lastIndexOf(self, elem: _lastIndexOf_0__B) -> int: ...
    @typing.overload
    def lastIndexOf(self, elem: _lastIndexOf_1__B, end: int) -> int: ...
    @typing.overload
    def lastIndexWhere(self, p: scala.Function1[_ParVector__T, typing.Any]) -> int: ...
    @typing.overload
    def lastIndexWhere(self, p: scala.Function1[_ParVector__T, typing.Any], end: int) -> int: ...
    def lastOption(self) -> scala.Option[_ParVector__T]: ...
    def length(self) -> int: ...
    _map__S = typing.TypeVar('_map__S')  # <S>
    _map__That = typing.TypeVar('_map__That')  # <That>
    def map(self, f: scala.Function1[_ParVector__T, _map__S], bf: scala.collection.generic.CanBuildFrom['ParVector'[_ParVector__T], _map__S, _map__That]) -> _map__That: ...
    _max__U = typing.TypeVar('_max__U')  # <U>
    def max(self, ord: scala.math.Ordering[_max__U]) -> _ParVector__T: ...
    _maxBy__S = typing.TypeVar('_maxBy__S')  # <S>
    def maxBy(self, f: scala.Function1[_ParVector__T, _maxBy__S], cmp: scala.math.Ordering[_maxBy__S]) -> _ParVector__T: ...
    _min__U = typing.TypeVar('_min__U')  # <U>
    def min(self, ord: scala.math.Ordering[_min__U]) -> _ParVector__T: ...
    _minBy__S = typing.TypeVar('_minBy__S')  # <S>
    def minBy(self, f: scala.Function1[_ParVector__T, _minBy__S], cmp: scala.math.Ordering[_minBy__S]) -> _ParVector__T: ...
    @typing.overload
    def mkString(self) -> java.lang.String: ...
    @typing.overload
    def mkString(self, sep: typing.Union[java.lang.String, str]) -> java.lang.String: ...
    @typing.overload
    def mkString(self, start: typing.Union[java.lang.String, str], sep: typing.Union[java.lang.String, str], end: typing.Union[java.lang.String, str]) -> java.lang.String: ...
    def newBuilder(self) -> scala.collection.mutable.Builder[_ParVector__T, 'ParVector'[_ParVector__T]]: ...
    def newCombiner(self) -> scala.collection.parallel.Combiner[_ParVector__T, 'ParVector'[_ParVector__T]]: ...
    def nonEmpty(self) -> bool: ...
    _padTo__U = typing.TypeVar('_padTo__U')  # <U>
    _padTo__That = typing.TypeVar('_padTo__That')  # <That>
    def padTo(self, len: int, elem: _padTo__U, bf: scala.collection.generic.CanBuildFrom['ParVector'[_ParVector__T], _padTo__U, _padTo__That]) -> _padTo__That: ...
    def par(self) -> scala.collection.parallel.ParIterable: ...
    def parCombiner(self) -> scala.collection.parallel.Combiner[_ParVector__T, 'ParVector'[_ParVector__T]]: ...
    def partition(self, pred: scala.Function1[_ParVector__T, typing.Any]) -> scala.Tuple2['ParVector'[_ParVector__T], 'ParVector'[_ParVector__T]]: ...
    _patch__U = typing.TypeVar('_patch__U')  # <U>
    _patch__That = typing.TypeVar('_patch__That')  # <That>
    def patch(self, from_: int, patch: scala.collection.GenSeq[_patch__U], replaced: int, bf: scala.collection.generic.CanBuildFrom['ParVector'[_ParVector__T], _patch__U, _patch__That]) -> _patch__That: ...
    def prefixLength(self, p: scala.Function1[_ParVector__T, typing.Any]) -> int: ...
    def printDebugBuffer(self) -> None: ...
    _product__U = typing.TypeVar('_product__U')  # <U>
    def product(self, num: scala.math.Numeric[_product__U]) -> _product__U: ...
    @typing.overload
    @staticmethod
    def range(start: typing.Any, end: typing.Any, step: typing.Any, evidence$2: scala.math.Integral) -> scala.collection.GenTraversable: ...
    @typing.overload
    @staticmethod
    def range(start: typing.Any, end: typing.Any, evidence$1: scala.math.Integral) -> scala.collection.GenTraversable: ...
    _reduce__U = typing.TypeVar('_reduce__U')  # <U>
    def reduce(self, op: scala.Function2[_reduce__U, _reduce__U, _reduce__U]) -> _reduce__U: ...
    _reduceLeft__U = typing.TypeVar('_reduceLeft__U')  # <U>
    def reduceLeft(self, op: scala.Function2[_reduceLeft__U, _ParVector__T, _reduceLeft__U]) -> _reduceLeft__U: ...
    _reduceLeftOption__U = typing.TypeVar('_reduceLeftOption__U')  # <U>
    def reduceLeftOption(self, op: scala.Function2[_reduceLeftOption__U, _ParVector__T, _reduceLeftOption__U]) -> scala.Option[_reduceLeftOption__U]: ...
    _reduceOption__U = typing.TypeVar('_reduceOption__U')  # <U>
    def reduceOption(self, op: scala.Function2[_reduceOption__U, _reduceOption__U, _reduceOption__U]) -> scala.Option[_reduceOption__U]: ...
    _reduceRight__U = typing.TypeVar('_reduceRight__U')  # <U>
    def reduceRight(self, op: scala.Function2[_ParVector__T, _reduceRight__U, _reduceRight__U]) -> _reduceRight__U: ...
    _reduceRightOption__U = typing.TypeVar('_reduceRightOption__U')  # <U>
    def reduceRightOption(self, op: scala.Function2[_ParVector__T, _reduceRightOption__U, _reduceRightOption__U]) -> scala.Option[_reduceRightOption__U]: ...
    def repr(self) -> scala.collection.parallel.ParIterable: ...
    _reuse__S = typing.TypeVar('_reuse__S')  # <S>
    _reuse__That = typing.TypeVar('_reuse__That')  # <That>
    def reuse(self, oldc: scala.Option[scala.collection.parallel.Combiner[_reuse__S, _reuse__That]], newc: scala.collection.parallel.Combiner[_reuse__S, _reuse__That]) -> scala.collection.parallel.Combiner[_reuse__S, _reuse__That]: ...
    def reverse(self) -> scala.collection.parallel.ParSeq: ...
    _reverseMap__S = typing.TypeVar('_reverseMap__S')  # <S>
    _reverseMap__That = typing.TypeVar('_reverseMap__That')  # <That>
    def reverseMap(self, f: scala.Function1[_ParVector__T, _reverseMap__S], bf: scala.collection.generic.CanBuildFrom['ParVector'[_ParVector__T], _reverseMap__S, _reverseMap__That]) -> _reverseMap__That: ...
    _sameElements__U = typing.TypeVar('_sameElements__U')  # <U>
    def sameElements(self, that: scala.collection.GenIterable[_sameElements__U]) -> bool: ...
    def scala$collection$parallel$ParIterableLike$$_tasksupport(self) -> scala.collection.parallel.TaskSupport: ...
    def scala$collection$parallel$ParIterableLike$$_tasksupport_$eq(self, x$1: scala.collection.parallel.TaskSupport) -> None: ...
    _scan__U = typing.TypeVar('_scan__U')  # <U>
    _scan__That = typing.TypeVar('_scan__That')  # <That>
    def scan(self, z: _scan__U, op: scala.Function2[_scan__U, _scan__U, _scan__U], bf: scala.collection.generic.CanBuildFrom['ParVector'[_ParVector__T], _scan__U, _scan__That]) -> _scan__That: ...
    def scanBlockSize(self) -> int: ...
    _scanLeft__S = typing.TypeVar('_scanLeft__S')  # <S>
    _scanLeft__That = typing.TypeVar('_scanLeft__That')  # <That>
    def scanLeft(self, z: _scanLeft__S, op: scala.Function2[_scanLeft__S, _ParVector__T, _scanLeft__S], bf: scala.collection.generic.CanBuildFrom['ParVector'[_ParVector__T], _scanLeft__S, _scanLeft__That]) -> _scanLeft__That: ...
    _scanRight__S = typing.TypeVar('_scanRight__S')  # <S>
    _scanRight__That = typing.TypeVar('_scanRight__That')  # <That>
    def scanRight(self, z: _scanRight__S, op: scala.Function2[_ParVector__T, _scanRight__S, _scanRight__S], bf: scala.collection.generic.CanBuildFrom['ParVector'[_ParVector__T], _scanRight__S, _scanRight__That]) -> _scanRight__That: ...
    def segmentLength(self, p: scala.Function1[_ParVector__T, typing.Any], from_: int) -> int: ...
    def seq(self) -> scala.collection.immutable.Vector[_ParVector__T]: ...
    def sequentially(self, b: scala.Function1) -> scala.collection.parallel.ParIterable: ...
    def size(self) -> int: ...
    def sizeHintIfCheap(self) -> int: ...
    def slice(self, unc_from: int, unc_until: int) -> scala.collection.parallel.ParIterable: ...
    def span(self, pred: scala.Function1[_ParVector__T, typing.Any]) -> scala.Tuple2['ParVector'[_ParVector__T], 'ParVector'[_ParVector__T]]: ...
    def splitAt(self, n: int) -> scala.Tuple2['ParVector'[_ParVector__T], 'ParVector'[_ParVector__T]]: ...
    def splitter(self) -> scala.collection.parallel.SeqSplitter[_ParVector__T]: ...
    _startsWith_0__B = typing.TypeVar('_startsWith_0__B')  # <B>
    _startsWith_1__S = typing.TypeVar('_startsWith_1__S')  # <S>
    @typing.overload
    def startsWith(self, that: scala.collection.GenSeq[_startsWith_0__B]) -> bool: ...
    @typing.overload
    def startsWith(self, that: scala.collection.GenSeq[_startsWith_1__S], offset: int) -> bool: ...
    def stringPrefix(self) -> java.lang.String: ...
    _sum__U = typing.TypeVar('_sum__U')  # <U>
    def sum(self, num: scala.math.Numeric[_sum__U]) -> _sum__U: ...
    @typing.overload
    @staticmethod
    def tabulate(n1: int, n2: int, n3: int, n4: int, n5: int, f: scala.Function5) -> scala.collection.GenTraversable: ...
    @typing.overload
    @staticmethod
    def tabulate(n1: int, n2: int, n3: int, n4: int, f: scala.Function4) -> scala.collection.GenTraversable: ...
    @typing.overload
    @staticmethod
    def tabulate(n1: int, n2: int, n3: int, f: scala.Function3) -> scala.collection.GenTraversable: ...
    @typing.overload
    @staticmethod
    def tabulate(n1: int, n2: int, f: scala.Function2) -> scala.collection.GenTraversable: ...
    @typing.overload
    @staticmethod
    def tabulate(n: int, f: scala.Function1) -> scala.collection.GenTraversable: ...
    def tail(self) -> scala.collection.parallel.ParIterable: ...
    def take(self, n: int) -> scala.collection.parallel.ParIterable: ...
    def takeWhile(self, pred: scala.Function1) -> scala.collection.parallel.ParIterable: ...
    _task2ops__R = typing.TypeVar('_task2ops__R')  # <R>
    _task2ops__Tp = typing.TypeVar('_task2ops__Tp')  # <Tp>
    def task2ops(self, tsk: scala.collection.parallel.ParIterableLike.StrictSplitterCheckTask[_task2ops__R, _task2ops__Tp]) -> scala.collection.parallel.ParIterableLike.TaskOps[_task2ops__R, _task2ops__Tp]: ...
    def tasksupport(self) -> scala.collection.parallel.TaskSupport: ...
    def tasksupport_$eq(self, ts: scala.collection.parallel.TaskSupport) -> None: ...
    _to__Col = typing.TypeVar('_to__Col')  # <Col>
    def to(self, cbf: scala.collection.generic.CanBuildFrom[scala.runtime.Nothing., _ParVector__T, _to__Col]) -> _to__Col: ...
    _toArray__U = typing.TypeVar('_toArray__U')  # <U>
    def toArray(self, evidence$1: scala.reflect.ClassTag[_toArray__U]) -> typing.Any: ...
    _toBuffer__U = typing.TypeVar('_toBuffer__U')  # <U>
    def toBuffer(self) -> scala.collection.mutable.Buffer[_toBuffer__U]: ...
    def toIndexedSeq(self) -> scala.collection.immutable.IndexedSeq[_ParVector__T]: ...
    def toIterable(self) -> ParIterable[_ParVector__T]: ...
    def toIterator(self) -> scala.collection.Iterator[_ParVector__T]: ...
    def toList(self) -> scala.collection.immutable.List[_ParVector__T]: ...
    _toMap__K = typing.TypeVar('_toMap__K')  # <K>
    _toMap__V = typing.TypeVar('_toMap__V')  # <V>
    def toMap(self, ev: scala.Predef..less.colon.less[_ParVector__T, scala.Tuple2[_toMap__K, _toMap__V]]) -> 'ParMap'[_toMap__K, _toMap__V]: ...
    _toParCollection__U = typing.TypeVar('_toParCollection__U')  # <U>
    _toParCollection__That = typing.TypeVar('_toParCollection__That')  # <That>
    def toParCollection(self, cbf: scala.Function0[scala.collection.parallel.Combiner[_toParCollection__U, _toParCollection__That]]) -> _toParCollection__That: ...
    _toParMap__K = typing.TypeVar('_toParMap__K')  # <K>
    _toParMap__V = typing.TypeVar('_toParMap__V')  # <V>
    _toParMap__That = typing.TypeVar('_toParMap__That')  # <That>
    def toParMap(self, cbf: scala.Function0[scala.collection.parallel.Combiner[scala.Tuple2[_toParMap__K, _toParMap__V], _toParMap__That]], ev: scala.Predef..less.colon.less[_ParVector__T, scala.Tuple2[_toParMap__K, _toParMap__V]]) -> _toParMap__That: ...
    def toSeq(self) -> ParSeq[_ParVector__T]: ...
    _toSet__U = typing.TypeVar('_toSet__U')  # <U>
    def toSet(self) -> ParSet[_toSet__U]: ...
    def toStream(self) -> scala.collection.immutable.Stream[_ParVector__T]: ...
    def toString(self) -> java.lang.String: ...
    def toTraversable(self) -> scala.collection.GenTraversable[_ParVector__T]: ...
    def toVector(self) -> scala.collection.immutable.Vector[_ParVector__T]: ...
    def transpose(self, asTraversable: scala.Function1) -> scala.collection.GenTraversable: ...
    _union__B = typing.TypeVar('_union__B')  # <B>
    _union__That = typing.TypeVar('_union__That')  # <That>
    def union(self, that: scala.collection.GenSeq[_union__B], bf: scala.collection.generic.CanBuildFrom['ParVector'[_ParVector__T], _union__B, _union__That]) -> _union__That: ...
    _unzip__A1 = typing.TypeVar('_unzip__A1')  # <A1>
    _unzip__A2 = typing.TypeVar('_unzip__A2')  # <A2>
    def unzip(self, asPair: scala.Function1[_ParVector__T, scala.Tuple2[_unzip__A1, _unzip__A2]]) -> scala.Tuple2['ParVector'[_unzip__A1], 'ParVector'[_unzip__A2]]: ...
    _unzip3__A1 = typing.TypeVar('_unzip3__A1')  # <A1>
    _unzip3__A2 = typing.TypeVar('_unzip3__A2')  # <A2>
    _unzip3__A3 = typing.TypeVar('_unzip3__A3')  # <A3>
    def unzip3(self, asTriple: scala.Function1[_ParVector__T, scala.Tuple3[_unzip3__A1, _unzip3__A2, _unzip3__A3]]) -> scala.Tuple3['ParVector'[_unzip3__A1], 'ParVector'[_unzip3__A2], 'ParVector'[_unzip3__A3]]: ...
    _updated__U = typing.TypeVar('_updated__U')  # <U>
    _updated__That = typing.TypeVar('_updated__That')  # <That>
    def updated(self, index: int, elem: _updated__U, bf: scala.collection.generic.CanBuildFrom['ParVector'[_ParVector__T], _updated__U, _updated__That]) -> _updated__That: ...
    def view(self) -> scala.collection.SeqView[_ParVector__T, scala.collection.immutable.Vector[_ParVector__T]]: ...
    def withFilter(self, pred: scala.Function1) -> scala.collection.parallel.ParIterable: ...
    _wrap__R = typing.TypeVar('_wrap__R')  # <R>
    def wrap(self, body: scala.Function0[_wrap__R]) -> scala.collection.parallel.ParIterableLike.NonDivisible[_wrap__R]: ...
    _zip__U = typing.TypeVar('_zip__U')  # <U>
    _zip__S = typing.TypeVar('_zip__S')  # <S>
    _zip__That = typing.TypeVar('_zip__That')  # <That>
    def zip(self, that: scala.collection.GenIterable[_zip__S], bf: scala.collection.generic.CanBuildFrom['ParVector'[_ParVector__T], scala.Tuple2[_zip__U, _zip__S], _zip__That]) -> _zip__That: ...
    _zipAll__S = typing.TypeVar('_zipAll__S')  # <S>
    _zipAll__U = typing.TypeVar('_zipAll__U')  # <U>
    _zipAll__That = typing.TypeVar('_zipAll__That')  # <That>
    def zipAll(self, that: scala.collection.GenIterable[_zipAll__S], thisElem: _zipAll__U, thatElem: _zipAll__S, bf: scala.collection.generic.CanBuildFrom['ParVector'[_ParVector__T], scala.Tuple2[_zipAll__U, _zipAll__S], _zipAll__That]) -> _zipAll__That: ...
    _zipWithIndex__U = typing.TypeVar('_zipWithIndex__U')  # <U>
    _zipWithIndex__That = typing.TypeVar('_zipWithIndex__That')  # <That>
    def zipWithIndex(self, bf: scala.collection.generic.CanBuildFrom['ParVector'[_ParVector__T], scala.Tuple2[_zipWithIndex__U, typing.Any], _zipWithIndex__That]) -> _zipWithIndex__That: ...
    class ParVectorIterator(scala.collection.immutable.VectorIterator[_ParVector__T], scala.collection.parallel.SeqSplitter[_ParVector__T]):
        $outer: 'ParVector' = ...
        def __init__(self, $outer: 'ParVector', _start: int, _end: int): ...
        def abort(self) -> None: ...
        _appendParIterable__U = typing.TypeVar('_appendParIterable__U')  # <U>
        _appendParIterable__PI = typing.TypeVar('_appendParIterable__PI', bound=scala.collection.parallel.IterableSplitter)  # <PI>
        def appendParIterable(self, that: _appendParIterable__PI) -> scala.collection.parallel.IterableSplitter.Appended[_appendParIterable__U, _appendParIterable__PI]: ...
        _appendParSeq__U = typing.TypeVar('_appendParSeq__U')  # <U>
        _appendParSeq__PI = typing.TypeVar('_appendParSeq__PI', bound=scala.collection.parallel.SeqSplitter)  # <PI>
        def appendParSeq(self, that: _appendParSeq__PI) -> scala.collection.parallel.SeqSplitter.Appended[_appendParSeq__U, _appendParSeq__PI]: ...
        def buildString(self, closure: scala.Function1[scala.Function1[typing.Union[java.lang.String, str], scala.runtime.BoxedUnit], scala.runtime.BoxedUnit]) -> java.lang.String: ...
        _collect2combiner__S = typing.TypeVar('_collect2combiner__S')  # <S>
        _collect2combiner__That = typing.TypeVar('_collect2combiner__That')  # <That>
        def collect2combiner(self, pf: scala.PartialFunction[_ParVector__T, _collect2combiner__S], cb: scala.collection.parallel.Combiner[_collect2combiner__S, _collect2combiner__That]) -> scala.collection.parallel.Combiner[_collect2combiner__S, _collect2combiner__That]: ...
        _copy2builder__U = typing.TypeVar('_copy2builder__U')  # <U>
        _copy2builder__Coll = typing.TypeVar('_copy2builder__Coll')  # <Coll>
        _copy2builder__Bld = typing.TypeVar('_copy2builder__Bld', bound=scala.collection.mutable.Builder)  # <Bld>
        def copy2builder(self, b: _copy2builder__Bld) -> _copy2builder__Bld: ...
        _copyToArray_0__B = typing.TypeVar('_copyToArray_0__B')  # <B>
        _copyToArray_1__B = typing.TypeVar('_copyToArray_1__B')  # <B>
        _copyToArray_2__U = typing.TypeVar('_copyToArray_2__U')  # <U>
        @typing.overload
        def copyToArray(self, xs: typing.Any) -> None: ...
        @typing.overload
        def copyToArray(self, xs: typing.Any, start: int) -> None: ...
        @typing.overload
        def copyToArray(self, array: typing.Any, from_: int, len: int) -> None: ...
        _corresponds_0__B = typing.TypeVar('_corresponds_0__B')  # <B>
        _corresponds_1__S = typing.TypeVar('_corresponds_1__S')  # <S>
        @typing.overload
        def corresponds(self, that: scala.collection.GenTraversableOnce[_corresponds_0__B], p: scala.Function2[typing.Any, _corresponds_0__B, typing.Any]) -> bool: ...
        @typing.overload
        def corresponds(self, corr: scala.Function2[_ParVector__T, _corresponds_1__S, typing.Any], that: scala.collection.Iterator[_corresponds_1__S]) -> bool: ...
        def count(self, p: scala.Function1[_ParVector__T, typing.Any]) -> int: ...
        def debugInformation(self) -> java.lang.String: ...
        def drop(self, n: int) -> scala.collection.parallel.IterableSplitter[_ParVector__T]: ...
        _drop2combiner__U = typing.TypeVar('_drop2combiner__U')  # <U>
        _drop2combiner__This = typing.TypeVar('_drop2combiner__This')  # <This>
        def drop2combiner(self, n: int, cb: scala.collection.parallel.Combiner[_drop2combiner__U, _drop2combiner__This]) -> scala.collection.parallel.Combiner[_drop2combiner__U, _drop2combiner__This]: ...
        def dup(self) -> scala.collection.parallel.SeqSplitter[_ParVector__T]: ...
        _filter2combiner__U = typing.TypeVar('_filter2combiner__U')  # <U>
        _filter2combiner__This = typing.TypeVar('_filter2combiner__This')  # <This>
        def filter2combiner(self, pred: scala.Function1[_ParVector__T, typing.Any], cb: scala.collection.parallel.Combiner[_filter2combiner__U, _filter2combiner__This]) -> scala.collection.parallel.Combiner[_filter2combiner__U, _filter2combiner__This]: ...
        _filterNot2combiner__U = typing.TypeVar('_filterNot2combiner__U')  # <U>
        _filterNot2combiner__This = typing.TypeVar('_filterNot2combiner__This')  # <This>
        def filterNot2combiner(self, pred: scala.Function1[_ParVector__T, typing.Any], cb: scala.collection.parallel.Combiner[_filterNot2combiner__U, _filterNot2combiner__This]) -> scala.collection.parallel.Combiner[_filterNot2combiner__U, _filterNot2combiner__This]: ...
        _flatmap2combiner__S = typing.TypeVar('_flatmap2combiner__S')  # <S>
        _flatmap2combiner__That = typing.TypeVar('_flatmap2combiner__That')  # <That>
        def flatmap2combiner(self, f: scala.Function1[_ParVector__T, scala.collection.GenTraversableOnce[_flatmap2combiner__S]], cb: scala.collection.parallel.Combiner[_flatmap2combiner__S, _flatmap2combiner__That]) -> scala.collection.parallel.Combiner[_flatmap2combiner__S, _flatmap2combiner__That]: ...
        _fold__U = typing.TypeVar('_fold__U')  # <U>
        def fold(self, z: _fold__U, op: scala.Function2[_fold__U, _fold__U, _fold__U]) -> _fold__U: ...
        def indexFlag(self) -> int: ...
        @typing.overload
        def indexWhere(self, p: scala.Function1[typing.Any, typing.Any], from_: int) -> int: ...
        @typing.overload
        def indexWhere(self, pred: scala.Function1[_ParVector__T, typing.Any]) -> int: ...
        def isAborted(self) -> bool: ...
        def isRemainingCheap(self) -> bool: ...
        def lastIndexWhere(self, pred: scala.Function1[_ParVector__T, typing.Any]) -> int: ...
        _map__S = typing.TypeVar('_map__S')  # <S>
        def map(self, f: scala.Function1[_ParVector__T, _map__S]) -> scala.collection.parallel.SeqSplitter.Mapped[_map__S]: ...
        _map2combiner__S = typing.TypeVar('_map2combiner__S')  # <S>
        _map2combiner__That = typing.TypeVar('_map2combiner__That')  # <That>
        def map2combiner(self, f: scala.Function1[_ParVector__T, _map2combiner__S], cb: scala.collection.parallel.Combiner[_map2combiner__S, _map2combiner__That]) -> scala.collection.parallel.Combiner[_map2combiner__S, _map2combiner__That]: ...
        _max__U = typing.TypeVar('_max__U')  # <U>
        def max(self, ord: scala.math.Ordering[_max__U]) -> _ParVector__T: ...
        _min__U = typing.TypeVar('_min__U')  # <U>
        def min(self, ord: scala.math.Ordering[_min__U]) -> _ParVector__T: ...
        _newSliceInternal__U = typing.TypeVar('_newSliceInternal__U', bound=scala.collection.parallel.IterableSplitter.Taken)  # <U>
        def newSliceInternal(self, it: _newSliceInternal__U, from1: int) -> _newSliceInternal__U: ...
        def newTaken(self, until: int) -> scala.collection.parallel.SeqSplitter.Taken: ...
        _partition2combiners__U = typing.TypeVar('_partition2combiners__U')  # <U>
        _partition2combiners__This = typing.TypeVar('_partition2combiners__This')  # <This>
        def partition2combiners(self, pred: scala.Function1[_ParVector__T, typing.Any], btrue: scala.collection.parallel.Combiner[_partition2combiners__U, _partition2combiners__This], bfalse: scala.collection.parallel.Combiner[_partition2combiners__U, _partition2combiners__This]) -> scala.Tuple2[scala.collection.parallel.Combiner[_partition2combiners__U, _partition2combiners__This], scala.collection.parallel.Combiner[_partition2combiners__U, _partition2combiners__This]]: ...
        _patchParSeq__U = typing.TypeVar('_patchParSeq__U')  # <U>
        def patchParSeq(self, from_: int, patchElems: scala.collection.parallel.SeqSplitter[_patchParSeq__U], replaced: int) -> scala.collection.parallel.SeqSplitter.Patched[_patchParSeq__U]: ...
        def prefixLength(self, pred: scala.Function1[_ParVector__T, typing.Any]) -> int: ...
        _product__U = typing.TypeVar('_product__U')  # <U>
        def product(self, num: scala.math.Numeric[_product__U]) -> _product__U: ...
        def psplit(self, sizes: scala.collection.Seq[typing.Any]) -> scala.collection.Seq['ParVector.ParVectorIterator']: ...
        def psplitWithSignalling(self, sizes: scala.collection.Seq[typing.Any]) -> scala.collection.Seq[scala.collection.parallel.SeqSplitter[_ParVector__T]]: ...
        _reduce__U = typing.TypeVar('_reduce__U')  # <U>
        def reduce(self, op: scala.Function2[_reduce__U, _reduce__U, _reduce__U]) -> _reduce__U: ...
        _reduceLeft_0__B = typing.TypeVar('_reduceLeft_0__B')  # <B>
        _reduceLeft_1__U = typing.TypeVar('_reduceLeft_1__U')  # <U>
        @typing.overload
        def reduceLeft(self, op: scala.Function2[_reduceLeft_0__B, typing.Any, _reduceLeft_0__B]) -> _reduceLeft_0__B: ...
        @typing.overload
        def reduceLeft(self, howmany: int, op: scala.Function2[_reduceLeft_1__U, _reduceLeft_1__U, _reduceLeft_1__U]) -> _reduceLeft_1__U: ...
        def remaining(self) -> int: ...
        def reverse(self) -> scala.collection.parallel.SeqSplitter[_ParVector__T]: ...
        _reverse2combiner__U = typing.TypeVar('_reverse2combiner__U')  # <U>
        _reverse2combiner__This = typing.TypeVar('_reverse2combiner__This')  # <This>
        def reverse2combiner(self, cb: scala.collection.parallel.Combiner[_reverse2combiner__U, _reverse2combiner__This]) -> scala.collection.parallel.Combiner[_reverse2combiner__U, _reverse2combiner__This]: ...
        _reverseMap2combiner__S = typing.TypeVar('_reverseMap2combiner__S')  # <S>
        _reverseMap2combiner__That = typing.TypeVar('_reverseMap2combiner__That')  # <That>
        def reverseMap2combiner(self, f: scala.Function1[_ParVector__T, _reverseMap2combiner__S], cb: scala.collection.parallel.Combiner[_reverseMap2combiner__S, _reverseMap2combiner__That]) -> scala.collection.parallel.Combiner[_reverseMap2combiner__S, _reverseMap2combiner__That]: ...
        _scanToArray__U = typing.TypeVar('_scanToArray__U')  # <U>
        _scanToArray__A = typing.TypeVar('_scanToArray__A')  # <A>
        def scanToArray(self, z: _scanToArray__U, op: scala.Function2[_scanToArray__U, _scanToArray__U, _scanToArray__U], array: typing.Any, from_: int) -> None: ...
        _scanToCombiner_0__U = typing.TypeVar('_scanToCombiner_0__U')  # <U>
        _scanToCombiner_0__That = typing.TypeVar('_scanToCombiner_0__That')  # <That>
        _scanToCombiner_1__U = typing.TypeVar('_scanToCombiner_1__U')  # <U>
        _scanToCombiner_1__That = typing.TypeVar('_scanToCombiner_1__That')  # <That>
        @typing.overload
        def scanToCombiner(self, howmany: int, startValue: _scanToCombiner_0__U, op: scala.Function2[_scanToCombiner_0__U, _scanToCombiner_0__U, _scanToCombiner_0__U], cb: scala.collection.parallel.Combiner[_scanToCombiner_0__U, _scanToCombiner_0__That]) -> scala.collection.parallel.Combiner[_scanToCombiner_0__U, _scanToCombiner_0__That]: ...
        @typing.overload
        def scanToCombiner(self, startValue: _scanToCombiner_1__U, op: scala.Function2[_scanToCombiner_1__U, _scanToCombiner_1__U, _scanToCombiner_1__U], cb: scala.collection.parallel.Combiner[_scanToCombiner_1__U, _scanToCombiner_1__That]) -> scala.collection.parallel.Combiner[_scanToCombiner_1__U, _scanToCombiner_1__That]: ...
        def setIndexFlag(self, f: int) -> None: ...
        def setIndexFlagIfGreater(self, f: int) -> None: ...
        def setIndexFlagIfLesser(self, f: int) -> None: ...
        _shouldSplitFurther__S = typing.TypeVar('_shouldSplitFurther__S')  # <S>
        def shouldSplitFurther(self, coll: scala.collection.parallel.ParIterable[_shouldSplitFurther__S], parallelismLevel: int) -> bool: ...
        def signalDelegate(self) -> scala.collection.generic.Signalling: ...
        def signalDelegate_$eq(self, x$1: scala.collection.generic.Signalling) -> None: ...
        def slice(self, from1: int, until1: int) -> scala.collection.parallel.SeqSplitter[_ParVector__T]: ...
        _slice2combiner__U = typing.TypeVar('_slice2combiner__U')  # <U>
        _slice2combiner__This = typing.TypeVar('_slice2combiner__This')  # <This>
        def slice2combiner(self, from_: int, until: int, cb: scala.collection.parallel.Combiner[_slice2combiner__U, _slice2combiner__This]) -> scala.collection.parallel.Combiner[_slice2combiner__U, _slice2combiner__This]: ...
        _span2combiners__U = typing.TypeVar('_span2combiners__U')  # <U>
        _span2combiners__This = typing.TypeVar('_span2combiners__This')  # <This>
        def span2combiners(self, p: scala.Function1[_ParVector__T, typing.Any], before: scala.collection.parallel.Combiner[_span2combiners__U, _span2combiners__This], after: scala.collection.parallel.Combiner[_span2combiners__U, _span2combiners__This]) -> scala.Tuple2[scala.collection.parallel.Combiner[_span2combiners__U, _span2combiners__This], scala.collection.parallel.Combiner[_span2combiners__U, _span2combiners__This]]: ...
        def split(self) -> scala.collection.Seq['ParVector.ParVectorIterator']: ...
        _splitAt2combiners__U = typing.TypeVar('_splitAt2combiners__U')  # <U>
        _splitAt2combiners__This = typing.TypeVar('_splitAt2combiners__This')  # <This>
        def splitAt2combiners(self, at: int, before: scala.collection.parallel.Combiner[_splitAt2combiners__U, _splitAt2combiners__This], after: scala.collection.parallel.Combiner[_splitAt2combiners__U, _splitAt2combiners__This]) -> scala.Tuple2[scala.collection.parallel.Combiner[_splitAt2combiners__U, _splitAt2combiners__This], scala.collection.parallel.Combiner[_splitAt2combiners__U, _splitAt2combiners__This]]: ...
        def splitWithSignalling(self) -> scala.collection.Seq[scala.collection.parallel.SeqSplitter[_ParVector__T]]: ...
        _sum__U = typing.TypeVar('_sum__U')  # <U>
        def sum(self, num: scala.math.Numeric[_sum__U]) -> _sum__U: ...
        def tag(self) -> int: ...
        def take(self, n: int) -> scala.collection.parallel.SeqSplitter[_ParVector__T]: ...
        _take2combiner__U = typing.TypeVar('_take2combiner__U')  # <U>
        _take2combiner__This = typing.TypeVar('_take2combiner__This')  # <This>
        def take2combiner(self, n: int, cb: scala.collection.parallel.Combiner[_take2combiner__U, _take2combiner__This]) -> scala.collection.parallel.Combiner[_take2combiner__U, _take2combiner__This]: ...
        _takeWhile2combiner__U = typing.TypeVar('_takeWhile2combiner__U')  # <U>
        _takeWhile2combiner__This = typing.TypeVar('_takeWhile2combiner__This')  # <This>
        def takeWhile2combiner(self, p: scala.Function1[_ParVector__T, typing.Any], cb: scala.collection.parallel.Combiner[_takeWhile2combiner__U, _takeWhile2combiner__This]) -> scala.Tuple2[scala.collection.parallel.Combiner[_takeWhile2combiner__U, _takeWhile2combiner__This], typing.Any]: ...
        _updated2combiner__U = typing.TypeVar('_updated2combiner__U')  # <U>
        _updated2combiner__That = typing.TypeVar('_updated2combiner__That')  # <That>
        def updated2combiner(self, index: int, elem: _updated2combiner__U, cb: scala.collection.parallel.Combiner[_updated2combiner__U, _updated2combiner__That]) -> scala.collection.parallel.Combiner[_updated2combiner__U, _updated2combiner__That]: ...
        _zip2combiner__U = typing.TypeVar('_zip2combiner__U')  # <U>
        _zip2combiner__S = typing.TypeVar('_zip2combiner__S')  # <S>
        _zip2combiner__That = typing.TypeVar('_zip2combiner__That')  # <That>
        def zip2combiner(self, otherpit: scala.collection.parallel.RemainsIterator[_zip2combiner__S], cb: scala.collection.parallel.Combiner[scala.Tuple2[_zip2combiner__U, _zip2combiner__S], _zip2combiner__That]) -> scala.collection.parallel.Combiner[scala.Tuple2[_zip2combiner__U, _zip2combiner__S], _zip2combiner__That]: ...
        _zipAll2combiner__U = typing.TypeVar('_zipAll2combiner__U')  # <U>
        _zipAll2combiner__S = typing.TypeVar('_zipAll2combiner__S')  # <S>
        _zipAll2combiner__That = typing.TypeVar('_zipAll2combiner__That')  # <That>
        def zipAll2combiner(self, that: scala.collection.parallel.RemainsIterator[_zipAll2combiner__S], thiselem: _zipAll2combiner__U, thatelem: _zipAll2combiner__S, cb: scala.collection.parallel.Combiner[scala.Tuple2[_zipAll2combiner__U, _zipAll2combiner__S], _zipAll2combiner__That]) -> scala.collection.parallel.Combiner[scala.Tuple2[_zipAll2combiner__U, _zipAll2combiner__S], _zipAll2combiner__That]: ...
        _zipAllParSeq__S = typing.TypeVar('_zipAllParSeq__S')  # <S>
        _zipAllParSeq__U = typing.TypeVar('_zipAllParSeq__U')  # <U>
        _zipAllParSeq__R = typing.TypeVar('_zipAllParSeq__R')  # <R>
        def zipAllParSeq(self, that: scala.collection.parallel.SeqSplitter[_zipAllParSeq__S], thisElem: _zipAllParSeq__U, thatElem: _zipAllParSeq__R) -> scala.collection.parallel.SeqSplitter.ZippedAll[_zipAllParSeq__U, _zipAllParSeq__R]: ...
        _zipParSeq__S = typing.TypeVar('_zipParSeq__S')  # <S>
        def zipParSeq(self, that: scala.collection.parallel.SeqSplitter[_zipParSeq__S]) -> scala.collection.parallel.SeqSplitter.Zipped[_zipParSeq__S]: ...
    class : ...

_Repetition__T = typing.TypeVar('_Repetition__T')  # <T>
class Repetition(ParSeq[_Repetition__T], typing.Generic[_Repetition__T]):
    scala$collection$parallel$immutable$Repetition$$elem: typing.Any = ...
    def __init__(self, elem: _Repetition__T, length: int): ...
    _$colon$bslash__S = typing.TypeVar('_$colon$bslash__S')  # <S>
    def $colon$bslash(self, z: _.colon.bslash__S, op: scala.Function2[_Repetition__T, _.colon.bslash__S, _.colon.bslash__S]) -> _.colon.bslash__S: ...
    _$colon$plus__U = typing.TypeVar('_$colon$plus__U')  # <U>
    _$colon$plus__That = typing.TypeVar('_$colon$plus__That')  # <That>
    def $colon$plus(self, elem: _.colon.plus__U, bf: scala.collection.generic.CanBuildFrom[ParSeq[_Repetition__T], _.colon.plus__U, _.colon.plus__That]) -> _.colon.plus__That: ...
    _$div$colon__S = typing.TypeVar('_$div$colon__S')  # <S>
    def $div$colon(self, z: _.div.colon__S, op: scala.Function2[_.div.colon__S, _Repetition__T, _.div.colon__S]) -> _.div.colon__S: ...
    _$plus$colon__U = typing.TypeVar('_$plus$colon__U')  # <U>
    _$plus$colon__That = typing.TypeVar('_$plus$colon__That')  # <That>
    def $plus$colon(self, elem: _.plus.colon__U, bf: scala.collection.generic.CanBuildFrom[ParSeq[_Repetition__T], _.plus.colon__U, _.plus.colon__That]) -> _.plus.colon__That: ...
    _$plus$plus__U = typing.TypeVar('_$plus$plus__U')  # <U>
    _$plus$plus__That = typing.TypeVar('_$plus$plus__That')  # <That>
    def $plus$plus(self, that: scala.collection.GenTraversableOnce[_.plus.plus__U], bf: scala.collection.generic.CanBuildFrom[ParSeq[_Repetition__T], _.plus.plus__U, _.plus.plus__That]) -> _.plus.plus__That: ...
    def ScanLeaf(self) -> scala.collection.parallel.ParIterableLike.ScanLeaf.: ...
    def ScanNode(self) -> scala.collection.parallel.ParIterableLike.ScanNode.: ...
    _aggregate__S = typing.TypeVar('_aggregate__S')  # <S>
    def aggregate(self, z: scala.Function0[_aggregate__S], seqop: scala.Function2[_aggregate__S, _Repetition__T, _aggregate__S], combop: scala.Function2[_aggregate__S, _aggregate__S, _aggregate__S]) -> _aggregate__S: ...
    def apply(self, idx: int) -> _Repetition__T: ...
    _bf2seq__S = typing.TypeVar('_bf2seq__S')  # <S>
    _bf2seq__That = typing.TypeVar('_bf2seq__That')  # <That>
    def bf2seq(self, bf: scala.collection.generic.CanBuildFrom[ParSeq[_Repetition__T], _bf2seq__S, _bf2seq__That]) -> scala.collection.generic.CanBuildFrom[scala.collection.immutable.Seq[_Repetition__T], _bf2seq__S, _bf2seq__That]: ...
    def brokenInvariants(self) -> scala.collection.Seq[java.lang.String]: ...
    _builder2ops__Elem = typing.TypeVar('_builder2ops__Elem')  # <Elem>
    _builder2ops__To = typing.TypeVar('_builder2ops__To')  # <To>
    def builder2ops(self, cb: scala.collection.mutable.Builder[_builder2ops__Elem, _builder2ops__To]) -> scala.collection.parallel.ParIterableLike.BuilderOps[_builder2ops__Elem, _builder2ops__To]: ...
    def canEqual(self, other: typing.Any) -> bool: ...
    _collect__S = typing.TypeVar('_collect__S')  # <S>
    _collect__That = typing.TypeVar('_collect__That')  # <That>
    def collect(self, pf: scala.PartialFunction[_Repetition__T, _collect__S], bf: scala.collection.generic.CanBuildFrom[ParSeq[_Repetition__T], _collect__S, _collect__That]) -> _collect__That: ...
    _combinerFactory_1__S = typing.TypeVar('_combinerFactory_1__S')  # <S>
    _combinerFactory_1__That = typing.TypeVar('_combinerFactory_1__That')  # <That>
    @typing.overload
    def combinerFactory(self) -> scala.collection.parallel.CombinerFactory[_Repetition__T, ParSeq[_Repetition__T]]: ...
    @typing.overload
    def combinerFactory(self, cbf: scala.Function0[scala.collection.parallel.Combiner[_combinerFactory_1__S, _combinerFactory_1__That]]) -> scala.collection.parallel.CombinerFactory[_combinerFactory_1__S, _combinerFactory_1__That]: ...
    def companion(self) -> scala.collection.generic.GenericCompanion[ParSeq]: ...
    _copyToArray_0__U = typing.TypeVar('_copyToArray_0__U')  # <U>
    _copyToArray_1__U = typing.TypeVar('_copyToArray_1__U')  # <U>
    _copyToArray_2__U = typing.TypeVar('_copyToArray_2__U')  # <U>
    @typing.overload
    def copyToArray(self, xs: typing.Any) -> None: ...
    @typing.overload
    def copyToArray(self, xs: typing.Any, start: int) -> None: ...
    @typing.overload
    def copyToArray(self, xs: typing.Any, start: int, len: int) -> None: ...
    _corresponds__S = typing.TypeVar('_corresponds__S')  # <S>
    def corresponds(self, that: scala.collection.GenSeq[_corresponds__S], p: scala.Function2[_Repetition__T, _corresponds__S, typing.Any]) -> bool: ...
    def count(self, p: scala.Function1[_Repetition__T, typing.Any]) -> int: ...
    def debugBuffer(self) -> scala.collection.mutable.ArrayBuffer[java.lang.String]: ...
    def debugInformation(self) -> java.lang.String: ...
    def debugclear(self) -> None: ...
    def debuglog(self, s: typing.Union[java.lang.String, str]) -> scala.collection.mutable.ArrayBuffer[java.lang.String]: ...
    _delegatedSignalling2ops__PI = typing.TypeVar('_delegatedSignalling2ops__PI', bound=scala.collection.generic.DelegatedSignalling)  # <PI>
    def delegatedSignalling2ops(self, it: _delegatedSignalling2ops__PI) -> scala.collection.parallel.ParIterableLike.SignallingOps[_delegatedSignalling2ops__PI]: ...
    def diff(self, that: scala.collection.GenSeq) -> scala.collection.parallel.ParSeq: ...
    def distinct(self) -> scala.collection.parallel.ParSeq: ...
    def down(self, p: scala.collection.parallel.IterableSplitter[typing.Any]) -> scala.collection.parallel.SeqSplitter[_Repetition__T]: ...
    def drop(self, n: int) -> scala.collection.parallel.ParIterable: ...
    def dropWhile(self, pred: scala.Function1) -> scala.collection.parallel.ParIterable: ...
    _endsWith__S = typing.TypeVar('_endsWith__S')  # <S>
    def endsWith(self, that: scala.collection.GenSeq[_endsWith__S]) -> bool: ...
    def equals(self, that: typing.Any) -> bool: ...
    def exists(self, p: scala.Function1[_Repetition__T, typing.Any]) -> bool: ...
    def filter(self, pred: scala.Function1) -> scala.collection.parallel.ParIterable: ...
    def filterNot(self, pred: scala.Function1) -> scala.collection.parallel.ParIterable: ...
    def find(self, p: scala.Function1[_Repetition__T, typing.Any]) -> scala.Option[_Repetition__T]: ...
    _flatMap__S = typing.TypeVar('_flatMap__S')  # <S>
    _flatMap__That = typing.TypeVar('_flatMap__That')  # <That>
    def flatMap(self, f: scala.Function1[_Repetition__T, scala.collection.GenTraversableOnce[_flatMap__S]], bf: scala.collection.generic.CanBuildFrom[ParSeq[_Repetition__T], _flatMap__S, _flatMap__That]) -> _flatMap__That: ...
    def flatten(self, asTraversable: scala.Function1) -> scala.collection.GenTraversable: ...
    _fold__U = typing.TypeVar('_fold__U')  # <U>
    def fold(self, z: _fold__U, op: scala.Function2[_fold__U, _fold__U, _fold__U]) -> _fold__U: ...
    _foldLeft__S = typing.TypeVar('_foldLeft__S')  # <S>
    def foldLeft(self, z: _foldLeft__S, op: scala.Function2[_foldLeft__S, _Repetition__T, _foldLeft__S]) -> _foldLeft__S: ...
    _foldRight__S = typing.TypeVar('_foldRight__S')  # <S>
    def foldRight(self, z: _foldRight__S, op: scala.Function2[_Repetition__T, _foldRight__S, _foldRight__S]) -> _foldRight__S: ...
    def forall(self, p: scala.Function1[_Repetition__T, typing.Any]) -> bool: ...
    _foreach__U = typing.TypeVar('_foreach__U')  # <U>
    def foreach(self, f: scala.Function1[_Repetition__T, _foreach__U]) -> None: ...
    _genericBuilder__B = typing.TypeVar('_genericBuilder__B')  # <B>
    def genericBuilder(self) -> scala.collection.parallel.Combiner[_genericBuilder__B, ParSeq[_genericBuilder__B]]: ...
    _genericCombiner__B = typing.TypeVar('_genericCombiner__B')  # <B>
    def genericCombiner(self) -> scala.collection.parallel.Combiner[_genericCombiner__B, ParSeq[_genericCombiner__B]]: ...
    _groupBy__K = typing.TypeVar('_groupBy__K')  # <K>
    def groupBy(self, f: scala.Function1[_Repetition__T, _groupBy__K]) -> 'ParMap'[_groupBy__K, ParSeq[_Repetition__T]]: ...
    def hasDefiniteSize(self) -> bool: ...
    def hashCode(self) -> int: ...
    def head(self) -> _Repetition__T: ...
    def headOption(self) -> scala.Option[_Repetition__T]: ...
    _indexOf_0__B = typing.TypeVar('_indexOf_0__B')  # <B>
    _indexOf_1__B = typing.TypeVar('_indexOf_1__B')  # <B>
    @typing.overload
    def indexOf(self, elem: _indexOf_0__B) -> int: ...
    @typing.overload
    def indexOf(self, elem: _indexOf_1__B, from_: int) -> int: ...
    @typing.overload
    def indexWhere(self, p: scala.Function1[_Repetition__T, typing.Any]) -> int: ...
    @typing.overload
    def indexWhere(self, p: scala.Function1[_Repetition__T, typing.Any], from_: int) -> int: ...
    def init(self) -> scala.collection.parallel.ParIterable: ...
    def initTaskSupport(self) -> None: ...
    def intersect(self, that: scala.collection.GenSeq) -> scala.collection.parallel.ParSeq: ...
    def isDefinedAt(self, idx: int) -> bool: ...
    def isEmpty(self) -> bool: ...
    def isStrictSplitterCollection(self) -> bool: ...
    def isTraversableAgain(self) -> bool: ...
    def iterator(self) -> scala.collection.parallel.PreciseSplitter[_Repetition__T]: ...
    def last(self) -> _Repetition__T: ...
    _lastIndexOf_0__B = typing.TypeVar('_lastIndexOf_0__B')  # <B>
    _lastIndexOf_1__B = typing.TypeVar('_lastIndexOf_1__B')  # <B>
    @typing.overload
    def lastIndexOf(self, elem: _lastIndexOf_0__B) -> int: ...
    @typing.overload
    def lastIndexOf(self, elem: _lastIndexOf_1__B, end: int) -> int: ...
    @typing.overload
    def lastIndexWhere(self, p: scala.Function1[_Repetition__T, typing.Any]) -> int: ...
    @typing.overload
    def lastIndexWhere(self, p: scala.Function1[_Repetition__T, typing.Any], end: int) -> int: ...
    def lastOption(self) -> scala.Option[_Repetition__T]: ...
    def length(self) -> int: ...
    _map__S = typing.TypeVar('_map__S')  # <S>
    _map__That = typing.TypeVar('_map__That')  # <That>
    def map(self, f: scala.Function1[_Repetition__T, _map__S], bf: scala.collection.generic.CanBuildFrom[ParSeq[_Repetition__T], _map__S, _map__That]) -> _map__That: ...
    _max__U = typing.TypeVar('_max__U')  # <U>
    def max(self, ord: scala.math.Ordering[_max__U]) -> _Repetition__T: ...
    _maxBy__S = typing.TypeVar('_maxBy__S')  # <S>
    def maxBy(self, f: scala.Function1[_Repetition__T, _maxBy__S], cmp: scala.math.Ordering[_maxBy__S]) -> _Repetition__T: ...
    _min__U = typing.TypeVar('_min__U')  # <U>
    def min(self, ord: scala.math.Ordering[_min__U]) -> _Repetition__T: ...
    _minBy__S = typing.TypeVar('_minBy__S')  # <S>
    def minBy(self, f: scala.Function1[_Repetition__T, _minBy__S], cmp: scala.math.Ordering[_minBy__S]) -> _Repetition__T: ...
    @typing.overload
    def mkString(self) -> java.lang.String: ...
    @typing.overload
    def mkString(self, sep: typing.Union[java.lang.String, str]) -> java.lang.String: ...
    @typing.overload
    def mkString(self, start: typing.Union[java.lang.String, str], sep: typing.Union[java.lang.String, str], end: typing.Union[java.lang.String, str]) -> java.lang.String: ...
    def newBuilder(self) -> scala.collection.mutable.Builder[_Repetition__T, ParSeq[_Repetition__T]]: ...
    def newCombiner(self) -> scala.collection.parallel.Combiner[_Repetition__T, ParSeq[_Repetition__T]]: ...
    def nonEmpty(self) -> bool: ...
    _padTo__U = typing.TypeVar('_padTo__U')  # <U>
    _padTo__That = typing.TypeVar('_padTo__That')  # <That>
    def padTo(self, len: int, elem: _padTo__U, bf: scala.collection.generic.CanBuildFrom[ParSeq[_Repetition__T], _padTo__U, _padTo__That]) -> _padTo__That: ...
    def par(self) -> scala.collection.parallel.ParIterable: ...
    def parCombiner(self) -> scala.collection.parallel.Combiner[_Repetition__T, ParSeq[_Repetition__T]]: ...
    def partition(self, pred: scala.Function1[_Repetition__T, typing.Any]) -> scala.Tuple2[ParSeq[_Repetition__T], ParSeq[_Repetition__T]]: ...
    _patch__U = typing.TypeVar('_patch__U')  # <U>
    _patch__That = typing.TypeVar('_patch__That')  # <That>
    def patch(self, from_: int, patch: scala.collection.GenSeq[_patch__U], replaced: int, bf: scala.collection.generic.CanBuildFrom[ParSeq[_Repetition__T], _patch__U, _patch__That]) -> _patch__That: ...
    def prefixLength(self, p: scala.Function1[_Repetition__T, typing.Any]) -> int: ...
    def printDebugBuffer(self) -> None: ...
    _product__U = typing.TypeVar('_product__U')  # <U>
    def product(self, num: scala.math.Numeric[_product__U]) -> _product__U: ...
    _reduce__U = typing.TypeVar('_reduce__U')  # <U>
    def reduce(self, op: scala.Function2[_reduce__U, _reduce__U, _reduce__U]) -> _reduce__U: ...
    _reduceLeft__U = typing.TypeVar('_reduceLeft__U')  # <U>
    def reduceLeft(self, op: scala.Function2[_reduceLeft__U, _Repetition__T, _reduceLeft__U]) -> _reduceLeft__U: ...
    _reduceLeftOption__U = typing.TypeVar('_reduceLeftOption__U')  # <U>
    def reduceLeftOption(self, op: scala.Function2[_reduceLeftOption__U, _Repetition__T, _reduceLeftOption__U]) -> scala.Option[_reduceLeftOption__U]: ...
    _reduceOption__U = typing.TypeVar('_reduceOption__U')  # <U>
    def reduceOption(self, op: scala.Function2[_reduceOption__U, _reduceOption__U, _reduceOption__U]) -> scala.Option[_reduceOption__U]: ...
    _reduceRight__U = typing.TypeVar('_reduceRight__U')  # <U>
    def reduceRight(self, op: scala.Function2[_Repetition__T, _reduceRight__U, _reduceRight__U]) -> _reduceRight__U: ...
    _reduceRightOption__U = typing.TypeVar('_reduceRightOption__U')  # <U>
    def reduceRightOption(self, op: scala.Function2[_Repetition__T, _reduceRightOption__U, _reduceRightOption__U]) -> scala.Option[_reduceRightOption__U]: ...
    def repr(self) -> scala.collection.parallel.ParIterable: ...
    _reuse__S = typing.TypeVar('_reuse__S')  # <S>
    _reuse__That = typing.TypeVar('_reuse__That')  # <That>
    def reuse(self, oldc: scala.Option[scala.collection.parallel.Combiner[_reuse__S, _reuse__That]], newc: scala.collection.parallel.Combiner[_reuse__S, _reuse__That]) -> scala.collection.parallel.Combiner[_reuse__S, _reuse__That]: ...
    def reverse(self) -> scala.collection.parallel.ParSeq: ...
    _reverseMap__S = typing.TypeVar('_reverseMap__S')  # <S>
    _reverseMap__That = typing.TypeVar('_reverseMap__That')  # <That>
    def reverseMap(self, f: scala.Function1[_Repetition__T, _reverseMap__S], bf: scala.collection.generic.CanBuildFrom[ParSeq[_Repetition__T], _reverseMap__S, _reverseMap__That]) -> _reverseMap__That: ...
    _sameElements__U = typing.TypeVar('_sameElements__U')  # <U>
    def sameElements(self, that: scala.collection.GenIterable[_sameElements__U]) -> bool: ...
    def scala$collection$parallel$ParIterableLike$$_tasksupport(self) -> scala.collection.parallel.TaskSupport: ...
    def scala$collection$parallel$ParIterableLike$$_tasksupport_$eq(self, x$1: scala.collection.parallel.TaskSupport) -> None: ...
    _scan__U = typing.TypeVar('_scan__U')  # <U>
    _scan__That = typing.TypeVar('_scan__That')  # <That>
    def scan(self, z: _scan__U, op: scala.Function2[_scan__U, _scan__U, _scan__U], bf: scala.collection.generic.CanBuildFrom[ParSeq[_Repetition__T], _scan__U, _scan__That]) -> _scan__That: ...
    def scanBlockSize(self) -> int: ...
    _scanLeft__S = typing.TypeVar('_scanLeft__S')  # <S>
    _scanLeft__That = typing.TypeVar('_scanLeft__That')  # <That>
    def scanLeft(self, z: _scanLeft__S, op: scala.Function2[_scanLeft__S, _Repetition__T, _scanLeft__S], bf: scala.collection.generic.CanBuildFrom[ParSeq[_Repetition__T], _scanLeft__S, _scanLeft__That]) -> _scanLeft__That: ...
    _scanRight__S = typing.TypeVar('_scanRight__S')  # <S>
    _scanRight__That = typing.TypeVar('_scanRight__That')  # <That>
    def scanRight(self, z: _scanRight__S, op: scala.Function2[_Repetition__T, _scanRight__S, _scanRight__S], bf: scala.collection.generic.CanBuildFrom[ParSeq[_Repetition__T], _scanRight__S, _scanRight__That]) -> _scanRight__That: ...
    def segmentLength(self, p: scala.Function1[_Repetition__T, typing.Any], from_: int) -> int: ...
    def seq(self) -> scala.collection.immutable.Seq[_Repetition__T]: ...
    def sequentially(self, b: scala.Function1) -> scala.collection.parallel.ParIterable: ...
    def size(self) -> int: ...
    def sizeHintIfCheap(self) -> int: ...
    def slice(self, unc_from: int, unc_until: int) -> scala.collection.parallel.ParIterable: ...
    def span(self, pred: scala.Function1[_Repetition__T, typing.Any]) -> scala.Tuple2[ParSeq[_Repetition__T], ParSeq[_Repetition__T]]: ...
    def splitAt(self, n: int) -> scala.Tuple2[ParSeq[_Repetition__T], ParSeq[_Repetition__T]]: ...
    def splitter(self) -> 'Repetition.ParIterator': ...
    _startsWith_0__B = typing.TypeVar('_startsWith_0__B')  # <B>
    _startsWith_1__S = typing.TypeVar('_startsWith_1__S')  # <S>
    @typing.overload
    def startsWith(self, that: scala.collection.GenSeq[_startsWith_0__B]) -> bool: ...
    @typing.overload
    def startsWith(self, that: scala.collection.GenSeq[_startsWith_1__S], offset: int) -> bool: ...
    def stringPrefix(self) -> java.lang.String: ...
    _sum__U = typing.TypeVar('_sum__U')  # <U>
    def sum(self, num: scala.math.Numeric[_sum__U]) -> _sum__U: ...
    def tail(self) -> scala.collection.parallel.ParIterable: ...
    def take(self, n: int) -> scala.collection.parallel.ParIterable: ...
    def takeWhile(self, pred: scala.Function1) -> scala.collection.parallel.ParIterable: ...
    _task2ops__R = typing.TypeVar('_task2ops__R')  # <R>
    _task2ops__Tp = typing.TypeVar('_task2ops__Tp')  # <Tp>
    def task2ops(self, tsk: scala.collection.parallel.ParIterableLike.StrictSplitterCheckTask[_task2ops__R, _task2ops__Tp]) -> scala.collection.parallel.ParIterableLike.TaskOps[_task2ops__R, _task2ops__Tp]: ...
    def tasksupport(self) -> scala.collection.parallel.TaskSupport: ...
    def tasksupport_$eq(self, ts: scala.collection.parallel.TaskSupport) -> None: ...
    _to__Col = typing.TypeVar('_to__Col')  # <Col>
    def to(self, cbf: scala.collection.generic.CanBuildFrom[scala.runtime.Nothing., _Repetition__T, _to__Col]) -> _to__Col: ...
    _toArray__U = typing.TypeVar('_toArray__U')  # <U>
    def toArray(self, evidence$1: scala.reflect.ClassTag[_toArray__U]) -> typing.Any: ...
    _toBuffer__U = typing.TypeVar('_toBuffer__U')  # <U>
    def toBuffer(self) -> scala.collection.mutable.Buffer[_toBuffer__U]: ...
    def toIndexedSeq(self) -> scala.collection.immutable.IndexedSeq[_Repetition__T]: ...
    def toIterable(self) -> ParIterable[_Repetition__T]: ...
    def toIterator(self) -> scala.collection.Iterator[_Repetition__T]: ...
    def toList(self) -> scala.collection.immutable.List[_Repetition__T]: ...
    _toMap__K = typing.TypeVar('_toMap__K')  # <K>
    _toMap__V = typing.TypeVar('_toMap__V')  # <V>
    def toMap(self, ev: scala.Predef..less.colon.less[_Repetition__T, scala.Tuple2[_toMap__K, _toMap__V]]) -> 'ParMap'[_toMap__K, _toMap__V]: ...
    _toParCollection__U = typing.TypeVar('_toParCollection__U')  # <U>
    _toParCollection__That = typing.TypeVar('_toParCollection__That')  # <That>
    def toParCollection(self, cbf: scala.Function0[scala.collection.parallel.Combiner[_toParCollection__U, _toParCollection__That]]) -> _toParCollection__That: ...
    _toParMap__K = typing.TypeVar('_toParMap__K')  # <K>
    _toParMap__V = typing.TypeVar('_toParMap__V')  # <V>
    _toParMap__That = typing.TypeVar('_toParMap__That')  # <That>
    def toParMap(self, cbf: scala.Function0[scala.collection.parallel.Combiner[scala.Tuple2[_toParMap__K, _toParMap__V], _toParMap__That]], ev: scala.Predef..less.colon.less[_Repetition__T, scala.Tuple2[_toParMap__K, _toParMap__V]]) -> _toParMap__That: ...
    def toSeq(self) -> ParSeq[_Repetition__T]: ...
    _toSet__U = typing.TypeVar('_toSet__U')  # <U>
    def toSet(self) -> ParSet[_toSet__U]: ...
    def toStream(self) -> scala.collection.immutable.Stream[_Repetition__T]: ...
    def toString(self) -> java.lang.String: ...
    def toTraversable(self) -> scala.collection.GenTraversable[_Repetition__T]: ...
    def toVector(self) -> scala.collection.immutable.Vector[_Repetition__T]: ...
    def transpose(self, asTraversable: scala.Function1) -> scala.collection.GenTraversable: ...
    _union__B = typing.TypeVar('_union__B')  # <B>
    _union__That = typing.TypeVar('_union__That')  # <That>
    def union(self, that: scala.collection.GenSeq[_union__B], bf: scala.collection.generic.CanBuildFrom[ParSeq[_Repetition__T], _union__B, _union__That]) -> _union__That: ...
    _unzip__A1 = typing.TypeVar('_unzip__A1')  # <A1>
    _unzip__A2 = typing.TypeVar('_unzip__A2')  # <A2>
    def unzip(self, asPair: scala.Function1[_Repetition__T, scala.Tuple2[_unzip__A1, _unzip__A2]]) -> scala.Tuple2[ParSeq[_unzip__A1], ParSeq[_unzip__A2]]: ...
    _unzip3__A1 = typing.TypeVar('_unzip3__A1')  # <A1>
    _unzip3__A2 = typing.TypeVar('_unzip3__A2')  # <A2>
    _unzip3__A3 = typing.TypeVar('_unzip3__A3')  # <A3>
    def unzip3(self, asTriple: scala.Function1[_Repetition__T, scala.Tuple3[_unzip3__A1, _unzip3__A2, _unzip3__A3]]) -> scala.Tuple3[ParSeq[_unzip3__A1], ParSeq[_unzip3__A2], ParSeq[_unzip3__A3]]: ...
    def update(self, idx: int, elem: _Repetition__T) -> scala.runtime.Nothing.: ...
    _updated__U = typing.TypeVar('_updated__U')  # <U>
    _updated__That = typing.TypeVar('_updated__That')  # <That>
    def updated(self, index: int, elem: _updated__U, bf: scala.collection.generic.CanBuildFrom[ParSeq[_Repetition__T], _updated__U, _updated__That]) -> _updated__That: ...
    def view(self) -> scala.collection.SeqView[_Repetition__T, scala.collection.immutable.Seq[_Repetition__T]]: ...
    def withFilter(self, pred: scala.Function1) -> scala.collection.parallel.ParIterable: ...
    _wrap__R = typing.TypeVar('_wrap__R')  # <R>
    def wrap(self, body: scala.Function0[_wrap__R]) -> scala.collection.parallel.ParIterableLike.NonDivisible[_wrap__R]: ...
    _zip__U = typing.TypeVar('_zip__U')  # <U>
    _zip__S = typing.TypeVar('_zip__S')  # <S>
    _zip__That = typing.TypeVar('_zip__That')  # <That>
    def zip(self, that: scala.collection.GenIterable[_zip__S], bf: scala.collection.generic.CanBuildFrom[ParSeq[_Repetition__T], scala.Tuple2[_zip__U, _zip__S], _zip__That]) -> _zip__That: ...
    _zipAll__S = typing.TypeVar('_zipAll__S')  # <S>
    _zipAll__U = typing.TypeVar('_zipAll__U')  # <U>
    _zipAll__That = typing.TypeVar('_zipAll__That')  # <That>
    def zipAll(self, that: scala.collection.GenIterable[_zipAll__S], thisElem: _zipAll__U, thatElem: _zipAll__S, bf: scala.collection.generic.CanBuildFrom[ParSeq[_Repetition__T], scala.Tuple2[_zipAll__U, _zipAll__S], _zipAll__That]) -> _zipAll__That: ...
    _zipWithIndex__U = typing.TypeVar('_zipWithIndex__U')  # <U>
    _zipWithIndex__That = typing.TypeVar('_zipWithIndex__That')  # <That>
    def zipWithIndex(self, bf: scala.collection.generic.CanBuildFrom[ParSeq[_Repetition__T], scala.Tuple2[_zipWithIndex__U, typing.Any], _zipWithIndex__That]) -> _zipWithIndex__That: ...
    class ParIterator(scala.collection.parallel.SeqSplitter[_Repetition__T]):
        $outer: 'Repetition' = ...
        def __init__(self, $outer: 'Repetition', i: int, until: int, elem: _Repetition__T): ...
        _$colon$bslash__B = typing.TypeVar('_$colon$bslash__B')  # <B>
        def $colon$bslash(self, z: _.colon.bslash__B, op: scala.Function2[_Repetition__T, _.colon.bslash__B, _.colon.bslash__B]) -> _.colon.bslash__B: ...
        _$div$colon__B = typing.TypeVar('_$div$colon__B')  # <B>
        def $div$colon(self, z: _.div.colon__B, op: scala.Function2[_.div.colon__B, _Repetition__T, _.div.colon__B]) -> _.div.colon__B: ...
        _$plus$plus__B = typing.TypeVar('_$plus$plus__B')  # <B>
        def $plus$plus(self, that: scala.Function0[scala.collection.GenTraversableOnce[_.plus.plus__B]]) -> scala.collection.Iterator[_.plus.plus__B]: ...
        def abort(self) -> None: ...
        @typing.overload
        def addString(self, b: scala.collection.mutable.StringBuilder) -> scala.collection.mutable.StringBuilder: ...
        @typing.overload
        def addString(self, b: scala.collection.mutable.StringBuilder, sep: typing.Union[java.lang.String, str]) -> scala.collection.mutable.StringBuilder: ...
        @typing.overload
        def addString(self, b: scala.collection.mutable.StringBuilder, start: typing.Union[java.lang.String, str], sep: typing.Union[java.lang.String, str], end: typing.Union[java.lang.String, str]) -> scala.collection.mutable.StringBuilder: ...
        _aggregate__B = typing.TypeVar('_aggregate__B')  # <B>
        def aggregate(self, z: scala.Function0[_aggregate__B], seqop: scala.Function2[_aggregate__B, _Repetition__T, _aggregate__B], combop: scala.Function2[_aggregate__B, _aggregate__B, _aggregate__B]) -> _aggregate__B: ...
        _appendParIterable__U = typing.TypeVar('_appendParIterable__U')  # <U>
        _appendParIterable__PI = typing.TypeVar('_appendParIterable__PI', bound=scala.collection.parallel.IterableSplitter)  # <PI>
        def appendParIterable(self, that: _appendParIterable__PI) -> scala.collection.parallel.IterableSplitter.Appended[_appendParIterable__U, _appendParIterable__PI]: ...
        _appendParSeq__U = typing.TypeVar('_appendParSeq__U')  # <U>
        _appendParSeq__PI = typing.TypeVar('_appendParSeq__PI', bound=scala.collection.parallel.SeqSplitter)  # <PI>
        def appendParSeq(self, that: _appendParSeq__PI) -> scala.collection.parallel.SeqSplitter.Appended[_appendParSeq__U, _appendParSeq__PI]: ...
        def buffered(self) -> scala.collection.BufferedIterator[_Repetition__T]: ...
        def buildString(self, closure: scala.Function1[scala.Function1[typing.Union[java.lang.String, str], scala.runtime.BoxedUnit], scala.runtime.BoxedUnit]) -> java.lang.String: ...
        _collect__B = typing.TypeVar('_collect__B')  # <B>
        def collect(self, pf: scala.PartialFunction[_Repetition__T, _collect__B]) -> scala.collection.Iterator[_collect__B]: ...
        _collect2combiner__S = typing.TypeVar('_collect2combiner__S')  # <S>
        _collect2combiner__That = typing.TypeVar('_collect2combiner__That')  # <That>
        def collect2combiner(self, pf: scala.PartialFunction[_Repetition__T, _collect2combiner__S], cb: scala.collection.parallel.Combiner[_collect2combiner__S, _collect2combiner__That]) -> scala.collection.parallel.Combiner[_collect2combiner__S, _collect2combiner__That]: ...
        _collectFirst__B = typing.TypeVar('_collectFirst__B')  # <B>
        def collectFirst(self, pf: scala.PartialFunction[_Repetition__T, _collectFirst__B]) -> scala.Option[_collectFirst__B]: ...
        def contains(self, elem: typing.Any) -> bool: ...
        _copy2builder__U = typing.TypeVar('_copy2builder__U')  # <U>
        _copy2builder__Coll = typing.TypeVar('_copy2builder__Coll')  # <Coll>
        _copy2builder__Bld = typing.TypeVar('_copy2builder__Bld', bound=scala.collection.mutable.Builder)  # <Bld>
        def copy2builder(self, b: _copy2builder__Bld) -> _copy2builder__Bld: ...
        _copyToArray_0__B = typing.TypeVar('_copyToArray_0__B')  # <B>
        _copyToArray_1__B = typing.TypeVar('_copyToArray_1__B')  # <B>
        _copyToArray_2__U = typing.TypeVar('_copyToArray_2__U')  # <U>
        @typing.overload
        def copyToArray(self, xs: typing.Any) -> None: ...
        @typing.overload
        def copyToArray(self, xs: typing.Any, start: int) -> None: ...
        @typing.overload
        def copyToArray(self, array: typing.Any, from_: int, len: int) -> None: ...
        _copyToBuffer__B = typing.TypeVar('_copyToBuffer__B')  # <B>
        def copyToBuffer(self, dest: scala.collection.mutable.Buffer[_copyToBuffer__B]) -> None: ...
        _corresponds_0__S = typing.TypeVar('_corresponds_0__S')  # <S>
        _corresponds_1__B = typing.TypeVar('_corresponds_1__B')  # <B>
        @typing.overload
        def corresponds(self, corr: scala.Function2[_Repetition__T, _corresponds_0__S, typing.Any], that: scala.collection.Iterator[_corresponds_0__S]) -> bool: ...
        @typing.overload
        def corresponds(self, that: scala.collection.GenTraversableOnce[_corresponds_1__B], p: scala.Function2[_Repetition__T, _corresponds_1__B, typing.Any]) -> bool: ...
        def count(self, p: scala.Function1[_Repetition__T, typing.Any]) -> int: ...
        def debugInformation(self) -> java.lang.String: ...
        def drop(self, n: int) -> scala.collection.parallel.IterableSplitter[_Repetition__T]: ...
        _drop2combiner__U = typing.TypeVar('_drop2combiner__U')  # <U>
        _drop2combiner__This = typing.TypeVar('_drop2combiner__This')  # <This>
        def drop2combiner(self, n: int, cb: scala.collection.parallel.Combiner[_drop2combiner__U, _drop2combiner__This]) -> scala.collection.parallel.Combiner[_drop2combiner__U, _drop2combiner__This]: ...
        def dropWhile(self, p: scala.Function1[_Repetition__T, typing.Any]) -> scala.collection.Iterator[_Repetition__T]: ...
        def dup(self) -> 'Repetition.ParIterator': ...
        def duplicate(self) -> scala.Tuple2[scala.collection.Iterator[_Repetition__T], scala.collection.Iterator[_Repetition__T]]: ...
        def exists(self, p: scala.Function1[_Repetition__T, typing.Any]) -> bool: ...
        def filter(self, p: scala.Function1[_Repetition__T, typing.Any]) -> scala.collection.Iterator[_Repetition__T]: ...
        _filter2combiner__U = typing.TypeVar('_filter2combiner__U')  # <U>
        _filter2combiner__This = typing.TypeVar('_filter2combiner__This')  # <This>
        def filter2combiner(self, pred: scala.Function1[_Repetition__T, typing.Any], cb: scala.collection.parallel.Combiner[_filter2combiner__U, _filter2combiner__This]) -> scala.collection.parallel.Combiner[_filter2combiner__U, _filter2combiner__This]: ...
        def filterNot(self, p: scala.Function1[_Repetition__T, typing.Any]) -> scala.collection.Iterator[_Repetition__T]: ...
        _filterNot2combiner__U = typing.TypeVar('_filterNot2combiner__U')  # <U>
        _filterNot2combiner__This = typing.TypeVar('_filterNot2combiner__This')  # <This>
        def filterNot2combiner(self, pred: scala.Function1[_Repetition__T, typing.Any], cb: scala.collection.parallel.Combiner[_filterNot2combiner__U, _filterNot2combiner__This]) -> scala.collection.parallel.Combiner[_filterNot2combiner__U, _filterNot2combiner__This]: ...
        def find(self, p: scala.Function1[_Repetition__T, typing.Any]) -> scala.Option[_Repetition__T]: ...
        _flatMap__B = typing.TypeVar('_flatMap__B')  # <B>
        def flatMap(self, f: scala.Function1[_Repetition__T, scala.collection.GenTraversableOnce[_flatMap__B]]) -> scala.collection.Iterator[_flatMap__B]: ...
        _flatmap2combiner__S = typing.TypeVar('_flatmap2combiner__S')  # <S>
        _flatmap2combiner__That = typing.TypeVar('_flatmap2combiner__That')  # <That>
        def flatmap2combiner(self, f: scala.Function1[_Repetition__T, scala.collection.GenTraversableOnce[_flatmap2combiner__S]], cb: scala.collection.parallel.Combiner[_flatmap2combiner__S, _flatmap2combiner__That]) -> scala.collection.parallel.Combiner[_flatmap2combiner__S, _flatmap2combiner__That]: ...
        _fold__U = typing.TypeVar('_fold__U')  # <U>
        def fold(self, z: _fold__U, op: scala.Function2[_fold__U, _fold__U, _fold__U]) -> _fold__U: ...
        _foldLeft__B = typing.TypeVar('_foldLeft__B')  # <B>
        def foldLeft(self, z: _foldLeft__B, op: scala.Function2[_foldLeft__B, _Repetition__T, _foldLeft__B]) -> _foldLeft__B: ...
        _foldRight__B = typing.TypeVar('_foldRight__B')  # <B>
        def foldRight(self, z: _foldRight__B, op: scala.Function2[_Repetition__T, _foldRight__B, _foldRight__B]) -> _foldRight__B: ...
        def forall(self, p: scala.Function1[_Repetition__T, typing.Any]) -> bool: ...
        _foreach__U = typing.TypeVar('_foreach__U')  # <U>
        def foreach(self, f: scala.Function1[_Repetition__T, _foreach__U]) -> None: ...
        _grouped__B = typing.TypeVar('_grouped__B')  # <B>
        def grouped(self, size: int) -> scala.collection.Iterator.GroupedIterator[_grouped__B]: ...
        def hasDefiniteSize(self) -> bool: ...
        def hasNext(self) -> bool: ...
        def i(self) -> int: ...
        def i_$eq(self, x$1: int) -> None: ...
        def indexFlag(self) -> int: ...
        _indexOf_0__B = typing.TypeVar('_indexOf_0__B')  # <B>
        _indexOf_1__B = typing.TypeVar('_indexOf_1__B')  # <B>
        @typing.overload
        def indexOf(self, elem: _indexOf_0__B) -> int: ...
        @typing.overload
        def indexOf(self, elem: _indexOf_1__B, from_: int) -> int: ...
        @typing.overload
        def indexWhere(self, pred: scala.Function1[_Repetition__T, typing.Any]) -> int: ...
        @typing.overload
        def indexWhere(self, p: scala.Function1[_Repetition__T, typing.Any], from_: int) -> int: ...
        def isAborted(self) -> bool: ...
        def isEmpty(self) -> bool: ...
        def isRemainingCheap(self) -> bool: ...
        def isTraversableAgain(self) -> bool: ...
        def lastIndexWhere(self, pred: scala.Function1[_Repetition__T, typing.Any]) -> int: ...
        def length(self) -> int: ...
        _map__S = typing.TypeVar('_map__S')  # <S>
        def map(self, f: scala.Function1[_Repetition__T, _map__S]) -> scala.collection.parallel.SeqSplitter.Mapped[_map__S]: ...
        _map2combiner__S = typing.TypeVar('_map2combiner__S')  # <S>
        _map2combiner__That = typing.TypeVar('_map2combiner__That')  # <That>
        def map2combiner(self, f: scala.Function1[_Repetition__T, _map2combiner__S], cb: scala.collection.parallel.Combiner[_map2combiner__S, _map2combiner__That]) -> scala.collection.parallel.Combiner[_map2combiner__S, _map2combiner__That]: ...
        _max__U = typing.TypeVar('_max__U')  # <U>
        def max(self, ord: scala.math.Ordering[_max__U]) -> _Repetition__T: ...
        _maxBy__B = typing.TypeVar('_maxBy__B')  # <B>
        def maxBy(self, f: scala.Function1[_Repetition__T, _maxBy__B], cmp: scala.math.Ordering[_maxBy__B]) -> _Repetition__T: ...
        _min__U = typing.TypeVar('_min__U')  # <U>
        def min(self, ord: scala.math.Ordering[_min__U]) -> _Repetition__T: ...
        _minBy__B = typing.TypeVar('_minBy__B')  # <B>
        def minBy(self, f: scala.Function1[_Repetition__T, _minBy__B], cmp: scala.math.Ordering[_minBy__B]) -> _Repetition__T: ...
        @typing.overload
        def mkString(self) -> java.lang.String: ...
        @typing.overload
        def mkString(self, sep: typing.Union[java.lang.String, str]) -> java.lang.String: ...
        @typing.overload
        def mkString(self, start: typing.Union[java.lang.String, str], sep: typing.Union[java.lang.String, str], end: typing.Union[java.lang.String, str]) -> java.lang.String: ...
        _newSliceInternal__U = typing.TypeVar('_newSliceInternal__U', bound=scala.collection.parallel.IterableSplitter.Taken)  # <U>
        def newSliceInternal(self, it: _newSliceInternal__U, from1: int) -> _newSliceInternal__U: ...
        def newTaken(self, until: int) -> scala.collection.parallel.SeqSplitter.Taken: ...
        def next(self) -> _Repetition__T: ...
        def nonEmpty(self) -> bool: ...
        _padTo__A1 = typing.TypeVar('_padTo__A1')  # <A1>
        def padTo(self, len: int, elem: _padTo__A1) -> scala.collection.Iterator[_padTo__A1]: ...
        def partition(self, p: scala.Function1[_Repetition__T, typing.Any]) -> scala.Tuple2[scala.collection.Iterator[_Repetition__T], scala.collection.Iterator[_Repetition__T]]: ...
        _partition2combiners__U = typing.TypeVar('_partition2combiners__U')  # <U>
        _partition2combiners__This = typing.TypeVar('_partition2combiners__This')  # <This>
        def partition2combiners(self, pred: scala.Function1[_Repetition__T, typing.Any], btrue: scala.collection.parallel.Combiner[_partition2combiners__U, _partition2combiners__This], bfalse: scala.collection.parallel.Combiner[_partition2combiners__U, _partition2combiners__This]) -> scala.Tuple2[scala.collection.parallel.Combiner[_partition2combiners__U, _partition2combiners__This], scala.collection.parallel.Combiner[_partition2combiners__U, _partition2combiners__This]]: ...
        _patch__B = typing.TypeVar('_patch__B')  # <B>
        def patch(self, from_: int, patchElems: scala.collection.Iterator[_patch__B], replaced: int) -> scala.collection.Iterator[_patch__B]: ...
        _patchParSeq__U = typing.TypeVar('_patchParSeq__U')  # <U>
        def patchParSeq(self, from_: int, patchElems: scala.collection.parallel.SeqSplitter[_patchParSeq__U], replaced: int) -> scala.collection.parallel.SeqSplitter.Patched[_patchParSeq__U]: ...
        def prefixLength(self, pred: scala.Function1[_Repetition__T, typing.Any]) -> int: ...
        _product__U = typing.TypeVar('_product__U')  # <U>
        def product(self, num: scala.math.Numeric[_product__U]) -> _product__U: ...
        def psplit(self, sizes: scala.collection.Seq[typing.Any]) -> scala.collection.Seq[scala.collection.parallel.SeqSplitter[_Repetition__T]]: ...
        def psplitWithSignalling(self, sizes: scala.collection.Seq[typing.Any]) -> scala.collection.Seq[scala.collection.parallel.SeqSplitter[_Repetition__T]]: ...
        _reduce__U = typing.TypeVar('_reduce__U')  # <U>
        def reduce(self, op: scala.Function2[_reduce__U, _reduce__U, _reduce__U]) -> _reduce__U: ...
        _reduceLeft_0__U = typing.TypeVar('_reduceLeft_0__U')  # <U>
        _reduceLeft_1__B = typing.TypeVar('_reduceLeft_1__B')  # <B>
        @typing.overload
        def reduceLeft(self, howmany: int, op: scala.Function2[_reduceLeft_0__U, _reduceLeft_0__U, _reduceLeft_0__U]) -> _reduceLeft_0__U: ...
        @typing.overload
        def reduceLeft(self, op: scala.Function2[_reduceLeft_1__B, _Repetition__T, _reduceLeft_1__B]) -> _reduceLeft_1__B: ...
        _reduceLeftOption__B = typing.TypeVar('_reduceLeftOption__B')  # <B>
        def reduceLeftOption(self, op: scala.Function2[_reduceLeftOption__B, _Repetition__T, _reduceLeftOption__B]) -> scala.Option[_reduceLeftOption__B]: ...
        _reduceOption__A1 = typing.TypeVar('_reduceOption__A1')  # <A1>
        def reduceOption(self, op: scala.Function2[_reduceOption__A1, _reduceOption__A1, _reduceOption__A1]) -> scala.Option[_reduceOption__A1]: ...
        _reduceRight__B = typing.TypeVar('_reduceRight__B')  # <B>
        def reduceRight(self, op: scala.Function2[_Repetition__T, _reduceRight__B, _reduceRight__B]) -> _reduceRight__B: ...
        _reduceRightOption__B = typing.TypeVar('_reduceRightOption__B')  # <B>
        def reduceRightOption(self, op: scala.Function2[_Repetition__T, _reduceRightOption__B, _reduceRightOption__B]) -> scala.Option[_reduceRightOption__B]: ...
        def remaining(self) -> int: ...
        def reverse(self) -> scala.collection.parallel.SeqSplitter[_Repetition__T]: ...
        _reverse2combiner__U = typing.TypeVar('_reverse2combiner__U')  # <U>
        _reverse2combiner__This = typing.TypeVar('_reverse2combiner__This')  # <This>
        def reverse2combiner(self, cb: scala.collection.parallel.Combiner[_reverse2combiner__U, _reverse2combiner__This]) -> scala.collection.parallel.Combiner[_reverse2combiner__U, _reverse2combiner__This]: ...
        _reverseMap2combiner__S = typing.TypeVar('_reverseMap2combiner__S')  # <S>
        _reverseMap2combiner__That = typing.TypeVar('_reverseMap2combiner__That')  # <That>
        def reverseMap2combiner(self, f: scala.Function1[_Repetition__T, _reverseMap2combiner__S], cb: scala.collection.parallel.Combiner[_reverseMap2combiner__S, _reverseMap2combiner__That]) -> scala.collection.parallel.Combiner[_reverseMap2combiner__S, _reverseMap2combiner__That]: ...
        def reversed(self) -> scala.collection.immutable.List[_Repetition__T]: ...
        def sameElements(self, that: scala.collection.Iterator[typing.Any]) -> bool: ...
        _scanLeft__B = typing.TypeVar('_scanLeft__B')  # <B>
        def scanLeft(self, z: _scanLeft__B, op: scala.Function2[_scanLeft__B, _Repetition__T, _scanLeft__B]) -> scala.collection.Iterator[_scanLeft__B]: ...
        _scanRight__B = typing.TypeVar('_scanRight__B')  # <B>
        def scanRight(self, z: _scanRight__B, op: scala.Function2[_Repetition__T, _scanRight__B, _scanRight__B]) -> scala.collection.Iterator[_scanRight__B]: ...
        _scanToArray__U = typing.TypeVar('_scanToArray__U')  # <U>
        _scanToArray__A = typing.TypeVar('_scanToArray__A')  # <A>
        def scanToArray(self, z: _scanToArray__U, op: scala.Function2[_scanToArray__U, _scanToArray__U, _scanToArray__U], array: typing.Any, from_: int) -> None: ...
        _scanToCombiner_0__U = typing.TypeVar('_scanToCombiner_0__U')  # <U>
        _scanToCombiner_0__That = typing.TypeVar('_scanToCombiner_0__That')  # <That>
        _scanToCombiner_1__U = typing.TypeVar('_scanToCombiner_1__U')  # <U>
        _scanToCombiner_1__That = typing.TypeVar('_scanToCombiner_1__That')  # <That>
        @typing.overload
        def scanToCombiner(self, howmany: int, startValue: _scanToCombiner_0__U, op: scala.Function2[_scanToCombiner_0__U, _scanToCombiner_0__U, _scanToCombiner_0__U], cb: scala.collection.parallel.Combiner[_scanToCombiner_0__U, _scanToCombiner_0__That]) -> scala.collection.parallel.Combiner[_scanToCombiner_0__U, _scanToCombiner_0__That]: ...
        @typing.overload
        def scanToCombiner(self, startValue: _scanToCombiner_1__U, op: scala.Function2[_scanToCombiner_1__U, _scanToCombiner_1__U, _scanToCombiner_1__U], cb: scala.collection.parallel.Combiner[_scanToCombiner_1__U, _scanToCombiner_1__That]) -> scala.collection.parallel.Combiner[_scanToCombiner_1__U, _scanToCombiner_1__That]: ...
        def seq(self) -> scala.collection.Iterator[_Repetition__T]: ...
        def setIndexFlag(self, f: int) -> None: ...
        def setIndexFlagIfGreater(self, f: int) -> None: ...
        def setIndexFlagIfLesser(self, f: int) -> None: ...
        _shouldSplitFurther__S = typing.TypeVar('_shouldSplitFurther__S')  # <S>
        def shouldSplitFurther(self, coll: scala.collection.parallel.ParIterable[_shouldSplitFurther__S], parallelismLevel: int) -> bool: ...
        def signalDelegate(self) -> scala.collection.generic.Signalling: ...
        def signalDelegate_$eq(self, x$1: scala.collection.generic.Signalling) -> None: ...
        def size(self) -> int: ...
        def sizeHintIfCheap(self) -> int: ...
        def slice(self, from1: int, until1: int) -> scala.collection.parallel.SeqSplitter[_Repetition__T]: ...
        _slice2combiner__U = typing.TypeVar('_slice2combiner__U')  # <U>
        _slice2combiner__This = typing.TypeVar('_slice2combiner__This')  # <This>
        def slice2combiner(self, from_: int, until: int, cb: scala.collection.parallel.Combiner[_slice2combiner__U, _slice2combiner__This]) -> scala.collection.parallel.Combiner[_slice2combiner__U, _slice2combiner__This]: ...
        def sliceIterator(self, from_: int, until: int) -> scala.collection.Iterator[_Repetition__T]: ...
        _sliding__B = typing.TypeVar('_sliding__B')  # <B>
        def sliding(self, size: int, step: int) -> scala.collection.Iterator.GroupedIterator[_sliding__B]: ...
        _sliding$default$2__B = typing.TypeVar('_sliding$default$2__B')  # <B>
        def sliding$default$2(self) -> int: ...
        def span(self, p: scala.Function1[_Repetition__T, typing.Any]) -> scala.Tuple2[scala.collection.Iterator[_Repetition__T], scala.collection.Iterator[_Repetition__T]]: ...
        _span2combiners__U = typing.TypeVar('_span2combiners__U')  # <U>
        _span2combiners__This = typing.TypeVar('_span2combiners__This')  # <This>
        def span2combiners(self, p: scala.Function1[_Repetition__T, typing.Any], before: scala.collection.parallel.Combiner[_span2combiners__U, _span2combiners__This], after: scala.collection.parallel.Combiner[_span2combiners__U, _span2combiners__This]) -> scala.Tuple2[scala.collection.parallel.Combiner[_span2combiners__U, _span2combiners__This], scala.collection.parallel.Combiner[_span2combiners__U, _span2combiners__This]]: ...
        def split(self) -> scala.collection.Seq[scala.collection.parallel.SeqSplitter[_Repetition__T]]: ...
        _splitAt2combiners__U = typing.TypeVar('_splitAt2combiners__U')  # <U>
        _splitAt2combiners__This = typing.TypeVar('_splitAt2combiners__This')  # <This>
        def splitAt2combiners(self, at: int, before: scala.collection.parallel.Combiner[_splitAt2combiners__U, _splitAt2combiners__This], after: scala.collection.parallel.Combiner[_splitAt2combiners__U, _splitAt2combiners__This]) -> scala.Tuple2[scala.collection.parallel.Combiner[_splitAt2combiners__U, _splitAt2combiners__This], scala.collection.parallel.Combiner[_splitAt2combiners__U, _splitAt2combiners__This]]: ...
        def splitWithSignalling(self) -> scala.collection.Seq[scala.collection.parallel.SeqSplitter[_Repetition__T]]: ...
        _sum__U = typing.TypeVar('_sum__U')  # <U>
        def sum(self, num: scala.math.Numeric[_sum__U]) -> _sum__U: ...
        def tag(self) -> int: ...
        def take(self, n: int) -> scala.collection.parallel.SeqSplitter[_Repetition__T]: ...
        _take2combiner__U = typing.TypeVar('_take2combiner__U')  # <U>
        _take2combiner__This = typing.TypeVar('_take2combiner__This')  # <This>
        def take2combiner(self, n: int, cb: scala.collection.parallel.Combiner[_take2combiner__U, _take2combiner__This]) -> scala.collection.parallel.Combiner[_take2combiner__U, _take2combiner__This]: ...
        def takeWhile(self, p: scala.Function1[_Repetition__T, typing.Any]) -> scala.collection.Iterator[_Repetition__T]: ...
        _takeWhile2combiner__U = typing.TypeVar('_takeWhile2combiner__U')  # <U>
        _takeWhile2combiner__This = typing.TypeVar('_takeWhile2combiner__This')  # <This>
        def takeWhile2combiner(self, p: scala.Function1[_Repetition__T, typing.Any], cb: scala.collection.parallel.Combiner[_takeWhile2combiner__U, _takeWhile2combiner__This]) -> scala.Tuple2[scala.collection.parallel.Combiner[_takeWhile2combiner__U, _takeWhile2combiner__This], typing.Any]: ...
        _to__Col = typing.TypeVar('_to__Col')  # <Col>
        def to(self, cbf: scala.collection.generic.CanBuildFrom[scala.runtime.Nothing., _Repetition__T, _to__Col]) -> _to__Col: ...
        _toArray__B = typing.TypeVar('_toArray__B')  # <B>
        def toArray(self, evidence$1: scala.reflect.ClassTag[_toArray__B]) -> typing.Any: ...
        _toBuffer__B = typing.TypeVar('_toBuffer__B')  # <B>
        def toBuffer(self) -> scala.collection.mutable.Buffer[_toBuffer__B]: ...
        def toIndexedSeq(self) -> scala.collection.immutable.IndexedSeq[_Repetition__T]: ...
        def toIterable(self) -> scala.collection.Iterable[_Repetition__T]: ...
        def toIterator(self) -> scala.collection.Iterator[_Repetition__T]: ...
        def toList(self) -> scala.collection.immutable.List[_Repetition__T]: ...
        _toMap__T = typing.TypeVar('_toMap__T')  # <T>
        _toMap__U = typing.TypeVar('_toMap__U')  # <U>
        def toMap(self, ev: scala.Predef..less.colon.less[typing.Any, scala.Tuple2[typing.Any, _toMap__U]]) -> scala.collection.immutable.Map[typing.Any, _toMap__U]: ...
        def toSeq(self) -> scala.collection.Seq[_Repetition__T]: ...
        _toSet__B = typing.TypeVar('_toSet__B')  # <B>
        def toSet(self) -> scala.collection.immutable.Set[_toSet__B]: ...
        def toStream(self) -> scala.collection.immutable.Stream[_Repetition__T]: ...
        def toString(self) -> java.lang.String: ...
        def toTraversable(self) -> scala.collection.Traversable[_Repetition__T]: ...
        def toVector(self) -> scala.collection.immutable.Vector[_Repetition__T]: ...
        def until(self) -> int: ...
        _updated2combiner__U = typing.TypeVar('_updated2combiner__U')  # <U>
        _updated2combiner__That = typing.TypeVar('_updated2combiner__That')  # <That>
        def updated2combiner(self, index: int, elem: _updated2combiner__U, cb: scala.collection.parallel.Combiner[_updated2combiner__U, _updated2combiner__That]) -> scala.collection.parallel.Combiner[_updated2combiner__U, _updated2combiner__That]: ...
        def withFilter(self, p: scala.Function1[_Repetition__T, typing.Any]) -> scala.collection.Iterator[_Repetition__T]: ...
        _zip__B = typing.TypeVar('_zip__B')  # <B>
        def zip(self, that: scala.collection.Iterator[_zip__B]) -> scala.collection.Iterator[scala.Tuple2[_Repetition__T, _zip__B]]: ...
        _zip2combiner__U = typing.TypeVar('_zip2combiner__U')  # <U>
        _zip2combiner__S = typing.TypeVar('_zip2combiner__S')  # <S>
        _zip2combiner__That = typing.TypeVar('_zip2combiner__That')  # <That>
        def zip2combiner(self, otherpit: scala.collection.parallel.RemainsIterator[_zip2combiner__S], cb: scala.collection.parallel.Combiner[scala.Tuple2[_zip2combiner__U, _zip2combiner__S], _zip2combiner__That]) -> scala.collection.parallel.Combiner[scala.Tuple2[_zip2combiner__U, _zip2combiner__S], _zip2combiner__That]: ...
        _zipAll__B = typing.TypeVar('_zipAll__B')  # <B>
        _zipAll__A1 = typing.TypeVar('_zipAll__A1')  # <A1>
        _zipAll__B1 = typing.TypeVar('_zipAll__B1')  # <B1>
        def zipAll(self, that: scala.collection.Iterator[_zipAll__B], thisElem: _zipAll__A1, thatElem: _zipAll__B1) -> scala.collection.Iterator[scala.Tuple2[_zipAll__A1, _zipAll__B1]]: ...
        _zipAll2combiner__U = typing.TypeVar('_zipAll2combiner__U')  # <U>
        _zipAll2combiner__S = typing.TypeVar('_zipAll2combiner__S')  # <S>
        _zipAll2combiner__That = typing.TypeVar('_zipAll2combiner__That')  # <That>
        def zipAll2combiner(self, that: scala.collection.parallel.RemainsIterator[_zipAll2combiner__S], thiselem: _zipAll2combiner__U, thatelem: _zipAll2combiner__S, cb: scala.collection.parallel.Combiner[scala.Tuple2[_zipAll2combiner__U, _zipAll2combiner__S], _zipAll2combiner__That]) -> scala.collection.parallel.Combiner[scala.Tuple2[_zipAll2combiner__U, _zipAll2combiner__S], _zipAll2combiner__That]: ...
        _zipAllParSeq__S = typing.TypeVar('_zipAllParSeq__S')  # <S>
        _zipAllParSeq__U = typing.TypeVar('_zipAllParSeq__U')  # <U>
        _zipAllParSeq__R = typing.TypeVar('_zipAllParSeq__R')  # <R>
        def zipAllParSeq(self, that: scala.collection.parallel.SeqSplitter[_zipAllParSeq__S], thisElem: _zipAllParSeq__U, thatElem: _zipAllParSeq__R) -> scala.collection.parallel.SeqSplitter.ZippedAll[_zipAllParSeq__U, _zipAllParSeq__R]: ...
        _zipParSeq__S = typing.TypeVar('_zipParSeq__S')  # <S>
        def zipParSeq(self, that: scala.collection.parallel.SeqSplitter[_zipParSeq__S]) -> scala.collection.parallel.SeqSplitter.Zipped[_zipParSeq__S]: ...
        def zipWithIndex(self) -> scala.collection.Iterator[scala.Tuple2[_Repetition__T, typing.Any]]: ...
    class ParIterator$:
        def __init__(self, $outer: 'Repetition'): ...
        def $lessinit$greater$default$1(self) -> int: ...
        def $lessinit$greater$default$2(self) -> int: ...
        def $lessinit$greater$default$3(self) -> _Repetition__T: ...

_ParHashMap__K = typing.TypeVar('_ParHashMap__K')  # <K>
_ParHashMap__V = typing.TypeVar('_ParHashMap__V')  # <V>
class ParHashMap(scala.collection.parallel.immutable.ParMap[_ParHashMap__K, _ParHashMap__V], scala.Serializable, typing.Generic[_ParHashMap__K, _ParHashMap__V]):
    serialVersionUID: typing.ClassVar[int] = ...
    @typing.overload
    def __init__(self): ...
    @typing.overload
    def __init__(self, trie: scala.collection.immutable.HashMap[_ParHashMap__K, _ParHashMap__V]): ...
    _$colon$bslash__S = typing.TypeVar('_$colon$bslash__S')  # <S>
    def $colon$bslash(self, z: _.colon.bslash__S, op: scala.Function2[scala.Tuple2[_ParHashMap__K, _ParHashMap__V], _.colon.bslash__S, _.colon.bslash__S]) -> _.colon.bslash__S: ...
    _$div$colon__S = typing.TypeVar('_$div$colon__S')  # <S>
    def $div$colon(self, z: _.div.colon__S, op: scala.Function2[_.div.colon__S, scala.Tuple2[_ParHashMap__K, _ParHashMap__V], _.div.colon__S]) -> _.div.colon__S: ...
    def $minus(self, k: _ParHashMap__K) -> 'ParHashMap'[_ParHashMap__K, _ParHashMap__V]: ...
    _$plus__U = typing.TypeVar('_$plus__U')  # <U>
    def $plus(self, kv: scala.Tuple2[_ParHashMap__K, _.plus__U]) -> 'ParHashMap'[_ParHashMap__K, _.plus__U]: ...
    _$plus$plus__U = typing.TypeVar('_$plus$plus__U')  # <U>
    _$plus$plus__That = typing.TypeVar('_$plus$plus__That')  # <That>
    def $plus$plus(self, that: scala.collection.GenTraversableOnce[_.plus.plus__U], bf: scala.collection.generic.CanBuildFrom['ParHashMap'[_ParHashMap__K, _ParHashMap__V], _.plus.plus__U, _.plus.plus__That]) -> _.plus.plus__That: ...
    def ScanLeaf(self) -> scala.collection.parallel.ParIterableLike.ScanLeaf.: ...
    def ScanNode(self) -> scala.collection.parallel.ParIterableLike.ScanNode.: ...
    _aggregate__S = typing.TypeVar('_aggregate__S')  # <S>
    def aggregate(self, z: scala.Function0[_aggregate__S], seqop: scala.Function2[_aggregate__S, scala.Tuple2[_ParHashMap__K, _ParHashMap__V], _aggregate__S], combop: scala.Function2[_aggregate__S, _aggregate__S, _aggregate__S]) -> _aggregate__S: ...
    def apply(self, key: _ParHashMap__K) -> _ParHashMap__V: ...
    _bf2seq__S = typing.TypeVar('_bf2seq__S')  # <S>
    _bf2seq__That = typing.TypeVar('_bf2seq__That')  # <That>
    def bf2seq(self, bf: scala.collection.generic.CanBuildFrom['ParHashMap'[_ParHashMap__K, _ParHashMap__V], _bf2seq__S, _bf2seq__That]) -> scala.collection.generic.CanBuildFrom[scala.collection.immutable.HashMap[_ParHashMap__K, _ParHashMap__V], _bf2seq__S, _bf2seq__That]: ...
    def brokenInvariants(self) -> scala.collection.Seq[java.lang.String]: ...
    _builder2ops__Elem = typing.TypeVar('_builder2ops__Elem')  # <Elem>
    _builder2ops__To = typing.TypeVar('_builder2ops__To')  # <To>
    def builder2ops(self, cb: scala.collection.mutable.Builder[_builder2ops__Elem, _builder2ops__To]) -> scala.collection.parallel.ParIterableLike.BuilderOps[_builder2ops__Elem, _builder2ops__To]: ...
    _canBuildFrom__K = typing.TypeVar('_canBuildFrom__K')  # <K>
    _canBuildFrom__V = typing.TypeVar('_canBuildFrom__V')  # <V>
    @staticmethod
    def canBuildFrom() -> scala.collection.generic.CanCombineFrom['ParHashMap'[typing.Any, typing.Any], scala.Tuple2[_canBuildFrom__K, _canBuildFrom__V], 'ParHashMap'[_canBuildFrom__K, _canBuildFrom__V]]: ...
    def canEqual(self, other: typing.Any) -> bool: ...
    _collect__S = typing.TypeVar('_collect__S')  # <S>
    _collect__That = typing.TypeVar('_collect__That')  # <That>
    def collect(self, pf: scala.PartialFunction[scala.Tuple2[_ParHashMap__K, _ParHashMap__V], _collect__S], bf: scala.collection.generic.CanBuildFrom['ParHashMap'[_ParHashMap__K, _ParHashMap__V], _collect__S, _collect__That]) -> _collect__That: ...
    _combinerFactory_1__S = typing.TypeVar('_combinerFactory_1__S')  # <S>
    _combinerFactory_1__That = typing.TypeVar('_combinerFactory_1__That')  # <That>
    @typing.overload
    def combinerFactory(self) -> scala.collection.parallel.CombinerFactory[scala.Tuple2[_ParHashMap__K, _ParHashMap__V], 'ParHashMap'[_ParHashMap__K, _ParHashMap__V]]: ...
    @typing.overload
    def combinerFactory(self, cbf: scala.Function0[scala.collection.parallel.Combiner[_combinerFactory_1__S, _combinerFactory_1__That]]) -> scala.collection.parallel.CombinerFactory[_combinerFactory_1__S, _combinerFactory_1__That]: ...
    def companion(self) -> scala.collection.generic.GenericCompanion[ParIterable]: ...
    def contains(self, key: _ParHashMap__K) -> bool: ...
    _copyToArray_0__U = typing.TypeVar('_copyToArray_0__U')  # <U>
    _copyToArray_1__U = typing.TypeVar('_copyToArray_1__U')  # <U>
    _copyToArray_2__U = typing.TypeVar('_copyToArray_2__U')  # <U>
    @typing.overload
    def copyToArray(self, xs: typing.Any) -> None: ...
    @typing.overload
    def copyToArray(self, xs: typing.Any, start: int) -> None: ...
    @typing.overload
    def copyToArray(self, xs: typing.Any, start: int, len: int) -> None: ...
    def count(self, p: scala.Function1[scala.Tuple2[_ParHashMap__K, _ParHashMap__V], typing.Any]) -> int: ...
    def debugBuffer(self) -> scala.collection.mutable.ArrayBuffer[java.lang.String]: ...
    def debugInformation(self) -> java.lang.String: ...
    def debugclear(self) -> None: ...
    def debuglog(self, s: typing.Union[java.lang.String, str]) -> scala.collection.mutable.ArrayBuffer[java.lang.String]: ...
    def default(self, key: _ParHashMap__K) -> _ParHashMap__V: ...
    _delegatedSignalling2ops__PI = typing.TypeVar('_delegatedSignalling2ops__PI', bound=scala.collection.generic.DelegatedSignalling)  # <PI>
    def delegatedSignalling2ops(self, it: _delegatedSignalling2ops__PI) -> scala.collection.parallel.ParIterableLike.SignallingOps[_delegatedSignalling2ops__PI]: ...
    def drop(self, n: int) -> scala.collection.parallel.ParIterable: ...
    def dropWhile(self, pred: scala.Function1) -> scala.collection.parallel.ParIterable: ...
    def empty(self) -> 'ParHashMap'[_ParHashMap__K, _ParHashMap__V]: ...
    def equals(self, that: typing.Any) -> bool: ...
    def exists(self, p: scala.Function1[scala.Tuple2[_ParHashMap__K, _ParHashMap__V], typing.Any]) -> bool: ...
    def filter(self, pred: scala.Function1) -> scala.collection.parallel.ParIterable: ...
    def filterKeys(self, p: scala.Function1[_ParHashMap__K, typing.Any]) -> scala.collection.parallel.ParMap[_ParHashMap__K, _ParHashMap__V]: ...
    def filterNot(self, pred: scala.Function1) -> scala.collection.parallel.ParIterable: ...
    def find(self, p: scala.Function1[scala.Tuple2[_ParHashMap__K, _ParHashMap__V], typing.Any]) -> scala.Option[scala.Tuple2[_ParHashMap__K, _ParHashMap__V]]: ...
    _flatMap__S = typing.TypeVar('_flatMap__S')  # <S>
    _flatMap__That = typing.TypeVar('_flatMap__That')  # <That>
    def flatMap(self, f: scala.Function1[scala.Tuple2[_ParHashMap__K, _ParHashMap__V], scala.collection.GenTraversableOnce[_flatMap__S]], bf: scala.collection.generic.CanBuildFrom['ParHashMap'[_ParHashMap__K, _ParHashMap__V], _flatMap__S, _flatMap__That]) -> _flatMap__That: ...
    def flatten(self, asTraversable: scala.Function1) -> scala.collection.GenTraversable: ...
    _fold__U = typing.TypeVar('_fold__U')  # <U>
    def fold(self, z: _fold__U, op: scala.Function2[_fold__U, _fold__U, _fold__U]) -> _fold__U: ...
    _foldLeft__S = typing.TypeVar('_foldLeft__S')  # <S>
    def foldLeft(self, z: _foldLeft__S, op: scala.Function2[_foldLeft__S, scala.Tuple2[_ParHashMap__K, _ParHashMap__V], _foldLeft__S]) -> _foldLeft__S: ...
    _foldRight__S = typing.TypeVar('_foldRight__S')  # <S>
    def foldRight(self, z: _foldRight__S, op: scala.Function2[scala.Tuple2[_ParHashMap__K, _ParHashMap__V], _foldRight__S, _foldRight__S]) -> _foldRight__S: ...
    def forall(self, p: scala.Function1[scala.Tuple2[_ParHashMap__K, _ParHashMap__V], typing.Any]) -> bool: ...
    _foreach__U = typing.TypeVar('_foreach__U')  # <U>
    def foreach(self, f: scala.Function1[scala.Tuple2[_ParHashMap__K, _ParHashMap__V], _foreach__U]) -> None: ...
    _fromTrie__K = typing.TypeVar('_fromTrie__K')  # <K>
    _fromTrie__V = typing.TypeVar('_fromTrie__V')  # <V>
    @staticmethod
    def fromTrie(t: scala.collection.immutable.HashMap[_fromTrie__K, _fromTrie__V]) -> 'ParHashMap'[_fromTrie__K, _fromTrie__V]: ...
    _genericBuilder__B = typing.TypeVar('_genericBuilder__B')  # <B>
    def genericBuilder(self) -> scala.collection.parallel.Combiner[_genericBuilder__B, ParIterable[_genericBuilder__B]]: ...
    _genericCombiner__B = typing.TypeVar('_genericCombiner__B')  # <B>
    def genericCombiner(self) -> scala.collection.parallel.Combiner[_genericCombiner__B, ParIterable[_genericCombiner__B]]: ...
    _genericMapCombiner__P = typing.TypeVar('_genericMapCombiner__P')  # <P>
    _genericMapCombiner__Q = typing.TypeVar('_genericMapCombiner__Q')  # <Q>
    def genericMapCombiner(self) -> scala.collection.parallel.Combiner[scala.Tuple2[_genericMapCombiner__P, _genericMapCombiner__Q], 'ParHashMap'[_genericMapCombiner__P, _genericMapCombiner__Q]]: ...
    def get(self, k: _ParHashMap__K) -> scala.Option[_ParHashMap__V]: ...
    _getOrElse__U = typing.TypeVar('_getOrElse__U')  # <U>
    def getOrElse(self, key: _ParHashMap__K, default: scala.Function0[_getOrElse__U]) -> _getOrElse__U: ...
    _groupBy__K = typing.TypeVar('_groupBy__K')  # <K>
    def groupBy(self, f: scala.Function1[scala.Tuple2[typing.Any, _ParHashMap__V], typing.Any]) -> 'ParMap'[typing.Any, 'ParHashMap'[typing.Any, _ParHashMap__V]]: ...
    def hasDefiniteSize(self) -> bool: ...
    def hashCode(self) -> int: ...
    def head(self) -> typing.Any: ...
    def headOption(self) -> scala.Option[scala.Tuple2[_ParHashMap__K, _ParHashMap__V]]: ...
    def init(self) -> scala.collection.parallel.ParIterable: ...
    def initTaskSupport(self) -> None: ...
    def isDefinedAt(self, key: _ParHashMap__K) -> bool: ...
    def isEmpty(self) -> bool: ...
    def isStrictSplitterCollection(self) -> bool: ...
    def isTraversableAgain(self) -> bool: ...
    def iterator(self) -> scala.collection.parallel.Splitter[scala.Tuple2[_ParHashMap__K, _ParHashMap__V]]: ...
    def keySet(self) -> scala.collection.parallel.ParSet[_ParHashMap__K]: ...
    def keys(self) -> scala.collection.parallel.ParIterable[_ParHashMap__K]: ...
    def keysIterator(self) -> scala.collection.parallel.IterableSplitter[_ParHashMap__K]: ...
    def last(self) -> typing.Any: ...
    def lastOption(self) -> scala.Option[scala.Tuple2[_ParHashMap__K, _ParHashMap__V]]: ...
    _map__S = typing.TypeVar('_map__S')  # <S>
    _map__That = typing.TypeVar('_map__That')  # <That>
    def map(self, f: scala.Function1[scala.Tuple2[_ParHashMap__K, _ParHashMap__V], _map__S], bf: scala.collection.generic.CanBuildFrom['ParHashMap'[_ParHashMap__K, _ParHashMap__V], _map__S, _map__That]) -> _map__That: ...
    def mapCompanion(self) -> scala.collection.generic.GenericParMapCompanion['ParHashMap']: ...
    _mapValues__S = typing.TypeVar('_mapValues__S')  # <S>
    def mapValues(self, f: scala.Function1[_ParHashMap__V, _mapValues__S]) -> scala.collection.parallel.ParMap[_ParHashMap__K, _mapValues__S]: ...
    def max(self, ord: scala.math.Ordering) -> typing.Any: ...
    def maxBy(self, f: scala.Function1, cmp: scala.math.Ordering) -> typing.Any: ...
    def min(self, ord: scala.math.Ordering) -> typing.Any: ...
    def minBy(self, f: scala.Function1, cmp: scala.math.Ordering) -> typing.Any: ...
    @typing.overload
    def mkString(self) -> java.lang.String: ...
    @typing.overload
    def mkString(self, sep: typing.Union[java.lang.String, str]) -> java.lang.String: ...
    @typing.overload
    def mkString(self, start: typing.Union[java.lang.String, str], sep: typing.Union[java.lang.String, str], end: typing.Union[java.lang.String, str]) -> java.lang.String: ...
    def newBuilder(self) -> scala.collection.mutable.Builder[scala.Tuple2[_ParHashMap__K, _ParHashMap__V], ParIterable[scala.Tuple2[_ParHashMap__K, _ParHashMap__V]]]: ...
    def newCombiner(self) -> HashMapCombiner[_ParHashMap__K, _ParHashMap__V]: ...
    def nonEmpty(self) -> bool: ...
    def par(self) -> scala.collection.parallel.ParIterable: ...
    def parCombiner(self) -> scala.collection.parallel.Combiner[scala.Tuple2[_ParHashMap__K, _ParHashMap__V], 'ParHashMap'[_ParHashMap__K, _ParHashMap__V]]: ...
    def partition(self, pred: scala.Function1[scala.Tuple2[_ParHashMap__K, _ParHashMap__V], typing.Any]) -> scala.Tuple2['ParHashMap'[_ParHashMap__K, _ParHashMap__V], 'ParHashMap'[_ParHashMap__K, _ParHashMap__V]]: ...
    def printDebugBuffer(self) -> None: ...
    def printDebugInfo(self) -> None: ...
    _product__U = typing.TypeVar('_product__U')  # <U>
    def product(self, num: scala.math.Numeric[_product__U]) -> _product__U: ...
    _reduce__U = typing.TypeVar('_reduce__U')  # <U>
    def reduce(self, op: scala.Function2[_reduce__U, _reduce__U, _reduce__U]) -> _reduce__U: ...
    _reduceLeft__U = typing.TypeVar('_reduceLeft__U')  # <U>
    def reduceLeft(self, op: scala.Function2[_reduceLeft__U, scala.Tuple2[_ParHashMap__K, _ParHashMap__V], _reduceLeft__U]) -> _reduceLeft__U: ...
    _reduceLeftOption__U = typing.TypeVar('_reduceLeftOption__U')  # <U>
    def reduceLeftOption(self, op: scala.Function2[_reduceLeftOption__U, scala.Tuple2[_ParHashMap__K, _ParHashMap__V], _reduceLeftOption__U]) -> scala.Option[_reduceLeftOption__U]: ...
    _reduceOption__U = typing.TypeVar('_reduceOption__U')  # <U>
    def reduceOption(self, op: scala.Function2[_reduceOption__U, _reduceOption__U, _reduceOption__U]) -> scala.Option[_reduceOption__U]: ...
    _reduceRight__U = typing.TypeVar('_reduceRight__U')  # <U>
    def reduceRight(self, op: scala.Function2[scala.Tuple2[_ParHashMap__K, _ParHashMap__V], _reduceRight__U, _reduceRight__U]) -> _reduceRight__U: ...
    _reduceRightOption__U = typing.TypeVar('_reduceRightOption__U')  # <U>
    def reduceRightOption(self, op: scala.Function2[scala.Tuple2[_ParHashMap__K, _ParHashMap__V], _reduceRightOption__U, _reduceRightOption__U]) -> scala.Option[_reduceRightOption__U]: ...
    def repr(self) -> scala.collection.parallel.ParIterable: ...
    _reuse__S = typing.TypeVar('_reuse__S')  # <S>
    _reuse__That = typing.TypeVar('_reuse__That')  # <That>
    def reuse(self, oldc: scala.Option[scala.collection.parallel.Combiner[_reuse__S, _reuse__That]], newc: scala.collection.parallel.Combiner[_reuse__S, _reuse__That]) -> scala.collection.parallel.Combiner[_reuse__S, _reuse__That]: ...
    _sameElements__U = typing.TypeVar('_sameElements__U')  # <U>
    def sameElements(self, that: scala.collection.GenIterable[_sameElements__U]) -> bool: ...
    def scala$collection$parallel$ParIterableLike$$_tasksupport(self) -> scala.collection.parallel.TaskSupport: ...
    def scala$collection$parallel$ParIterableLike$$_tasksupport_$eq(self, x$1: scala.collection.parallel.TaskSupport) -> None: ...
    _scan__U = typing.TypeVar('_scan__U')  # <U>
    _scan__That = typing.TypeVar('_scan__That')  # <That>
    def scan(self, z: _scan__U, op: scala.Function2[_scan__U, _scan__U, _scan__U], bf: scala.collection.generic.CanBuildFrom['ParHashMap'[_ParHashMap__K, _ParHashMap__V], _scan__U, _scan__That]) -> _scan__That: ...
    def scanBlockSize(self) -> int: ...
    _scanLeft__S = typing.TypeVar('_scanLeft__S')  # <S>
    _scanLeft__That = typing.TypeVar('_scanLeft__That')  # <That>
    def scanLeft(self, z: _scanLeft__S, op: scala.Function2[_scanLeft__S, scala.Tuple2[_ParHashMap__K, _ParHashMap__V], _scanLeft__S], bf: scala.collection.generic.CanBuildFrom['ParHashMap'[_ParHashMap__K, _ParHashMap__V], _scanLeft__S, _scanLeft__That]) -> _scanLeft__That: ...
    _scanRight__S = typing.TypeVar('_scanRight__S')  # <S>
    _scanRight__That = typing.TypeVar('_scanRight__That')  # <That>
    def scanRight(self, z: _scanRight__S, op: scala.Function2[scala.Tuple2[_ParHashMap__K, _ParHashMap__V], _scanRight__S, _scanRight__S], bf: scala.collection.generic.CanBuildFrom['ParHashMap'[_ParHashMap__K, _ParHashMap__V], _scanRight__S, _scanRight__That]) -> _scanRight__That: ...
    def seq(self) -> scala.collection.immutable.HashMap[_ParHashMap__K, _ParHashMap__V]: ...
    def sequentially(self, b: scala.Function1) -> scala.collection.parallel.ParIterable: ...
    def size(self) -> int: ...
    def sizeHintIfCheap(self) -> int: ...
    def slice(self, unc_from: int, unc_until: int) -> scala.collection.parallel.ParIterable: ...
    def span(self, pred: scala.Function1[scala.Tuple2[_ParHashMap__K, _ParHashMap__V], typing.Any]) -> scala.Tuple2['ParHashMap'[_ParHashMap__K, _ParHashMap__V], 'ParHashMap'[_ParHashMap__K, _ParHashMap__V]]: ...
    def splitAt(self, n: int) -> scala.Tuple2['ParHashMap'[_ParHashMap__K, _ParHashMap__V], 'ParHashMap'[_ParHashMap__K, _ParHashMap__V]]: ...
    def splitter(self) -> scala.collection.parallel.IterableSplitter[scala.Tuple2[_ParHashMap__K, _ParHashMap__V]]: ...
    def stringPrefix(self) -> java.lang.String: ...
    _sum__U = typing.TypeVar('_sum__U')  # <U>
    def sum(self, num: scala.math.Numeric[_sum__U]) -> _sum__U: ...
    def tail(self) -> scala.collection.parallel.ParIterable: ...
    def take(self, n: int) -> scala.collection.parallel.ParIterable: ...
    def takeWhile(self, pred: scala.Function1) -> scala.collection.parallel.ParIterable: ...
    _task2ops__R = typing.TypeVar('_task2ops__R')  # <R>
    _task2ops__Tp = typing.TypeVar('_task2ops__Tp')  # <Tp>
    def task2ops(self, tsk: scala.collection.parallel.ParIterableLike.StrictSplitterCheckTask[_task2ops__R, _task2ops__Tp]) -> scala.collection.parallel.ParIterableLike.TaskOps[_task2ops__R, _task2ops__Tp]: ...
    def tasksupport(self) -> scala.collection.parallel.TaskSupport: ...
    def tasksupport_$eq(self, ts: scala.collection.parallel.TaskSupport) -> None: ...
    _to__Col = typing.TypeVar('_to__Col')  # <Col>
    def to(self, cbf: scala.collection.generic.CanBuildFrom[scala.runtime.Nothing., scala.Tuple2[_ParHashMap__K, _ParHashMap__V], _to__Col]) -> _to__Col: ...
    _toArray__U = typing.TypeVar('_toArray__U')  # <U>
    def toArray(self, evidence$1: scala.reflect.ClassTag[_toArray__U]) -> typing.Any: ...
    _toBuffer__U = typing.TypeVar('_toBuffer__U')  # <U>
    def toBuffer(self) -> scala.collection.mutable.Buffer[_toBuffer__U]: ...
    def toIndexedSeq(self) -> scala.collection.immutable.IndexedSeq[scala.Tuple2[_ParHashMap__K, _ParHashMap__V]]: ...
    def toIterable(self) -> ParIterable[scala.Tuple2[_ParHashMap__K, _ParHashMap__V]]: ...
    def toIterator(self) -> scala.collection.Iterator[scala.Tuple2[_ParHashMap__K, _ParHashMap__V]]: ...
    def toList(self) -> scala.collection.immutable.List[scala.Tuple2[_ParHashMap__K, _ParHashMap__V]]: ...
    _toMap__P = typing.TypeVar('_toMap__P')  # <P>
    _toMap__Q = typing.TypeVar('_toMap__Q')  # <Q>
    def toMap(self, ev: scala.Predef..less.colon.less[scala.Tuple2[_ParHashMap__K, _ParHashMap__V], scala.Tuple2[_toMap__P, _toMap__Q]]) -> 'ParMap'[_toMap__P, _toMap__Q]: ...
    _toParCollection__U = typing.TypeVar('_toParCollection__U')  # <U>
    _toParCollection__That = typing.TypeVar('_toParCollection__That')  # <That>
    def toParCollection(self, cbf: scala.Function0[scala.collection.parallel.Combiner[_toParCollection__U, _toParCollection__That]]) -> _toParCollection__That: ...
    _toParMap__K = typing.TypeVar('_toParMap__K')  # <K>
    _toParMap__V = typing.TypeVar('_toParMap__V')  # <V>
    _toParMap__That = typing.TypeVar('_toParMap__That')  # <That>
    def toParMap(self, cbf: scala.Function0[scala.collection.parallel.Combiner[scala.Tuple2[typing.Any, typing.Any], _toParMap__That]], ev: scala.Predef..less.colon.less[scala.Tuple2[typing.Any, typing.Any], scala.Tuple2[typing.Any, typing.Any]]) -> _toParMap__That: ...
    def toSeq(self) -> ParSeq[scala.Tuple2[_ParHashMap__K, _ParHashMap__V]]: ...
    _toSet__U = typing.TypeVar('_toSet__U')  # <U>
    def toSet(self) -> ParSet[_toSet__U]: ...
    def toStream(self) -> scala.collection.immutable.Stream[scala.Tuple2[_ParHashMap__K, _ParHashMap__V]]: ...
    def toString(self) -> java.lang.String: ...
    def toTraversable(self) -> scala.collection.GenTraversable[scala.Tuple2[_ParHashMap__K, _ParHashMap__V]]: ...
    def toVector(self) -> scala.collection.immutable.Vector[scala.Tuple2[_ParHashMap__K, _ParHashMap__V]]: ...
    @staticmethod
    def totalcombines() -> java.util.concurrent.atomic.AtomicInteger: ...
    @staticmethod
    def totalcombines_$eq(x$1: java.util.concurrent.atomic.AtomicInteger) -> None: ...
    def transpose(self, asTraversable: scala.Function1) -> scala.collection.GenTraversable: ...
    _unzip__A1 = typing.TypeVar('_unzip__A1')  # <A1>
    _unzip__A2 = typing.TypeVar('_unzip__A2')  # <A2>
    def unzip(self, asPair: scala.Function1[scala.Tuple2[_ParHashMap__K, _ParHashMap__V], scala.Tuple2[_unzip__A1, _unzip__A2]]) -> scala.Tuple2[ParIterable[_unzip__A1], ParIterable[_unzip__A2]]: ...
    _unzip3__A1 = typing.TypeVar('_unzip3__A1')  # <A1>
    _unzip3__A2 = typing.TypeVar('_unzip3__A2')  # <A2>
    _unzip3__A3 = typing.TypeVar('_unzip3__A3')  # <A3>
    def unzip3(self, asTriple: scala.Function1[scala.Tuple2[_ParHashMap__K, _ParHashMap__V], scala.Tuple3[_unzip3__A1, _unzip3__A2, _unzip3__A3]]) -> scala.Tuple3[ParIterable[_unzip3__A1], ParIterable[_unzip3__A2], ParIterable[_unzip3__A3]]: ...
    _updated__U = typing.TypeVar('_updated__U')  # <U>
    def updated(self, key: _ParHashMap__K, value: _updated__U) -> 'ParMap'[_ParHashMap__K, _updated__U]: ...
    def values(self) -> scala.collection.parallel.ParIterable[_ParHashMap__V]: ...
    def valuesIterator(self) -> scala.collection.parallel.IterableSplitter[_ParHashMap__V]: ...
    def view(self) -> scala.collection.IterableView[scala.Tuple2[_ParHashMap__K, _ParHashMap__V], scala.collection.immutable.HashMap[_ParHashMap__K, _ParHashMap__V]]: ...
    _withDefault__U = typing.TypeVar('_withDefault__U')  # <U>
    def withDefault(self, d: scala.Function1[_ParHashMap__K, _withDefault__U]) -> 'ParMap'[_ParHashMap__K, _withDefault__U]: ...
    _withDefaultValue__U = typing.TypeVar('_withDefaultValue__U')  # <U>
    def withDefaultValue(self, d: _withDefaultValue__U) -> 'ParMap'[_ParHashMap__K, _withDefaultValue__U]: ...
    def withFilter(self, pred: scala.Function1) -> scala.collection.parallel.ParIterable: ...
    _wrap__R = typing.TypeVar('_wrap__R')  # <R>
    def wrap(self, body: scala.Function0[_wrap__R]) -> scala.collection.parallel.ParIterableLike.NonDivisible[_wrap__R]: ...
    _zip__U = typing.TypeVar('_zip__U')  # <U>
    _zip__S = typing.TypeVar('_zip__S')  # <S>
    _zip__That = typing.TypeVar('_zip__That')  # <That>
    def zip(self, that: scala.collection.GenIterable[_zip__S], bf: scala.collection.generic.CanBuildFrom['ParHashMap'[_ParHashMap__K, _ParHashMap__V], scala.Tuple2[_zip__U, _zip__S], _zip__That]) -> _zip__That: ...
    _zipAll__S = typing.TypeVar('_zipAll__S')  # <S>
    _zipAll__U = typing.TypeVar('_zipAll__U')  # <U>
    _zipAll__That = typing.TypeVar('_zipAll__That')  # <That>
    def zipAll(self, that: scala.collection.GenIterable[_zipAll__S], thisElem: _zipAll__U, thatElem: _zipAll__S, bf: scala.collection.generic.CanBuildFrom['ParHashMap'[_ParHashMap__K, _ParHashMap__V], scala.Tuple2[_zipAll__U, _zipAll__S], _zipAll__That]) -> _zipAll__That: ...
    _zipWithIndex__U = typing.TypeVar('_zipWithIndex__U')  # <U>
    _zipWithIndex__That = typing.TypeVar('_zipWithIndex__That')  # <That>
    def zipWithIndex(self, bf: scala.collection.generic.CanBuildFrom['ParHashMap'[_ParHashMap__K, _ParHashMap__V], scala.Tuple2[_zipWithIndex__U, typing.Any], _zipWithIndex__That]) -> _zipWithIndex__That: ...
    class ParHashMapIterator(scala.collection.parallel.IterableSplitter[scala.Tuple2[_ParHashMap__K, _ParHashMap__V]]):
        $outer: 'ParHashMap' = ...
        def __init__(self, $outer: 'ParHashMap', triter: scala.collection.Iterator[scala.Tuple2[_ParHashMap__K, _ParHashMap__V]], sz: int): ...
        _$colon$bslash__B = typing.TypeVar('_$colon$bslash__B')  # <B>
        def $colon$bslash(self, z: _.colon.bslash__B, op: scala.Function2[scala.Tuple2[_ParHashMap__K, _ParHashMap__V], _.colon.bslash__B, _.colon.bslash__B]) -> _.colon.bslash__B: ...
        _$div$colon__B = typing.TypeVar('_$div$colon__B')  # <B>
        def $div$colon(self, z: _.div.colon__B, op: scala.Function2[_.div.colon__B, scala.Tuple2[_ParHashMap__K, _ParHashMap__V], _.div.colon__B]) -> _.div.colon__B: ...
        _$plus$plus__B = typing.TypeVar('_$plus$plus__B')  # <B>
        def $plus$plus(self, that: scala.Function0[scala.collection.GenTraversableOnce[_.plus.plus__B]]) -> scala.collection.Iterator[_.plus.plus__B]: ...
        def abort(self) -> None: ...
        @typing.overload
        def addString(self, b: scala.collection.mutable.StringBuilder) -> scala.collection.mutable.StringBuilder: ...
        @typing.overload
        def addString(self, b: scala.collection.mutable.StringBuilder, sep: typing.Union[java.lang.String, str]) -> scala.collection.mutable.StringBuilder: ...
        @typing.overload
        def addString(self, b: scala.collection.mutable.StringBuilder, start: typing.Union[java.lang.String, str], sep: typing.Union[java.lang.String, str], end: typing.Union[java.lang.String, str]) -> scala.collection.mutable.StringBuilder: ...
        _aggregate__B = typing.TypeVar('_aggregate__B')  # <B>
        def aggregate(self, z: scala.Function0[_aggregate__B], seqop: scala.Function2[_aggregate__B, scala.Tuple2[_ParHashMap__K, _ParHashMap__V], _aggregate__B], combop: scala.Function2[_aggregate__B, _aggregate__B, _aggregate__B]) -> _aggregate__B: ...
        _appendParIterable__U = typing.TypeVar('_appendParIterable__U')  # <U>
        _appendParIterable__PI = typing.TypeVar('_appendParIterable__PI', bound=scala.collection.parallel.IterableSplitter)  # <PI>
        def appendParIterable(self, that: _appendParIterable__PI) -> scala.collection.parallel.IterableSplitter.Appended[_appendParIterable__U, _appendParIterable__PI]: ...
        def buffered(self) -> scala.collection.BufferedIterator[scala.Tuple2[_ParHashMap__K, _ParHashMap__V]]: ...
        def buildString(self, closure: scala.Function1[scala.Function1[typing.Union[java.lang.String, str], scala.runtime.BoxedUnit], scala.runtime.BoxedUnit]) -> java.lang.String: ...
        _collect__B = typing.TypeVar('_collect__B')  # <B>
        def collect(self, pf: scala.PartialFunction[scala.Tuple2[_ParHashMap__K, _ParHashMap__V], _collect__B]) -> scala.collection.Iterator[_collect__B]: ...
        _collect2combiner__S = typing.TypeVar('_collect2combiner__S')  # <S>
        _collect2combiner__That = typing.TypeVar('_collect2combiner__That')  # <That>
        def collect2combiner(self, pf: scala.PartialFunction[scala.Tuple2[_ParHashMap__K, _ParHashMap__V], _collect2combiner__S], cb: scala.collection.parallel.Combiner[_collect2combiner__S, _collect2combiner__That]) -> scala.collection.parallel.Combiner[_collect2combiner__S, _collect2combiner__That]: ...
        _collectFirst__B = typing.TypeVar('_collectFirst__B')  # <B>
        def collectFirst(self, pf: scala.PartialFunction[scala.Tuple2[_ParHashMap__K, _ParHashMap__V], _collectFirst__B]) -> scala.Option[_collectFirst__B]: ...
        def contains(self, elem: typing.Any) -> bool: ...
        _copy2builder__U = typing.TypeVar('_copy2builder__U')  # <U>
        _copy2builder__Coll = typing.TypeVar('_copy2builder__Coll')  # <Coll>
        _copy2builder__Bld = typing.TypeVar('_copy2builder__Bld', bound=scala.collection.mutable.Builder)  # <Bld>
        def copy2builder(self, b: _copy2builder__Bld) -> _copy2builder__Bld: ...
        _copyToArray_0__B = typing.TypeVar('_copyToArray_0__B')  # <B>
        _copyToArray_1__B = typing.TypeVar('_copyToArray_1__B')  # <B>
        _copyToArray_2__U = typing.TypeVar('_copyToArray_2__U')  # <U>
        @typing.overload
        def copyToArray(self, xs: typing.Any) -> None: ...
        @typing.overload
        def copyToArray(self, xs: typing.Any, start: int) -> None: ...
        @typing.overload
        def copyToArray(self, array: typing.Any, from_: int, len: int) -> None: ...
        _copyToBuffer__B = typing.TypeVar('_copyToBuffer__B')  # <B>
        def copyToBuffer(self, dest: scala.collection.mutable.Buffer[_copyToBuffer__B]) -> None: ...
        _corresponds__B = typing.TypeVar('_corresponds__B')  # <B>
        def corresponds(self, that: scala.collection.GenTraversableOnce[_corresponds__B], p: scala.Function2[scala.Tuple2[_ParHashMap__K, _ParHashMap__V], _corresponds__B, typing.Any]) -> bool: ...
        def count(self, p: scala.Function1[scala.Tuple2[_ParHashMap__K, _ParHashMap__V], typing.Any]) -> int: ...
        def debugInformation(self) -> java.lang.String: ...
        def drop(self, n: int) -> scala.collection.parallel.IterableSplitter[scala.Tuple2[_ParHashMap__K, _ParHashMap__V]]: ...
        _drop2combiner__U = typing.TypeVar('_drop2combiner__U')  # <U>
        _drop2combiner__This = typing.TypeVar('_drop2combiner__This')  # <This>
        def drop2combiner(self, n: int, cb: scala.collection.parallel.Combiner[_drop2combiner__U, _drop2combiner__This]) -> scala.collection.parallel.Combiner[_drop2combiner__U, _drop2combiner__This]: ...
        def dropWhile(self, p: scala.Function1[scala.Tuple2[_ParHashMap__K, _ParHashMap__V], typing.Any]) -> scala.collection.Iterator[scala.Tuple2[_ParHashMap__K, _ParHashMap__V]]: ...
        def dup(self) -> scala.collection.parallel.IterableSplitter[scala.Tuple2[_ParHashMap__K, _ParHashMap__V]]: ...
        def duplicate(self) -> scala.Tuple2[scala.collection.Iterator[scala.Tuple2[_ParHashMap__K, _ParHashMap__V]], scala.collection.Iterator[scala.Tuple2[_ParHashMap__K, _ParHashMap__V]]]: ...
        def exists(self, p: scala.Function1[scala.Tuple2[_ParHashMap__K, _ParHashMap__V], typing.Any]) -> bool: ...
        def filter(self, p: scala.Function1[scala.Tuple2[_ParHashMap__K, _ParHashMap__V], typing.Any]) -> scala.collection.Iterator[scala.Tuple2[_ParHashMap__K, _ParHashMap__V]]: ...
        _filter2combiner__U = typing.TypeVar('_filter2combiner__U')  # <U>
        _filter2combiner__This = typing.TypeVar('_filter2combiner__This')  # <This>
        def filter2combiner(self, pred: scala.Function1[scala.Tuple2[_ParHashMap__K, _ParHashMap__V], typing.Any], cb: scala.collection.parallel.Combiner[_filter2combiner__U, _filter2combiner__This]) -> scala.collection.parallel.Combiner[_filter2combiner__U, _filter2combiner__This]: ...
        def filterNot(self, p: scala.Function1[scala.Tuple2[_ParHashMap__K, _ParHashMap__V], typing.Any]) -> scala.collection.Iterator[scala.Tuple2[_ParHashMap__K, _ParHashMap__V]]: ...
        _filterNot2combiner__U = typing.TypeVar('_filterNot2combiner__U')  # <U>
        _filterNot2combiner__This = typing.TypeVar('_filterNot2combiner__This')  # <This>
        def filterNot2combiner(self, pred: scala.Function1[scala.Tuple2[_ParHashMap__K, _ParHashMap__V], typing.Any], cb: scala.collection.parallel.Combiner[_filterNot2combiner__U, _filterNot2combiner__This]) -> scala.collection.parallel.Combiner[_filterNot2combiner__U, _filterNot2combiner__This]: ...
        def find(self, p: scala.Function1[scala.Tuple2[_ParHashMap__K, _ParHashMap__V], typing.Any]) -> scala.Option[scala.Tuple2[_ParHashMap__K, _ParHashMap__V]]: ...
        _flatMap__B = typing.TypeVar('_flatMap__B')  # <B>
        def flatMap(self, f: scala.Function1[scala.Tuple2[_ParHashMap__K, _ParHashMap__V], scala.collection.GenTraversableOnce[_flatMap__B]]) -> scala.collection.Iterator[_flatMap__B]: ...
        _flatmap2combiner__S = typing.TypeVar('_flatmap2combiner__S')  # <S>
        _flatmap2combiner__That = typing.TypeVar('_flatmap2combiner__That')  # <That>
        def flatmap2combiner(self, f: scala.Function1[scala.Tuple2[_ParHashMap__K, _ParHashMap__V], scala.collection.GenTraversableOnce[_flatmap2combiner__S]], cb: scala.collection.parallel.Combiner[_flatmap2combiner__S, _flatmap2combiner__That]) -> scala.collection.parallel.Combiner[_flatmap2combiner__S, _flatmap2combiner__That]: ...
        _fold__U = typing.TypeVar('_fold__U')  # <U>
        def fold(self, z: _fold__U, op: scala.Function2[_fold__U, _fold__U, _fold__U]) -> _fold__U: ...
        _foldLeft__B = typing.TypeVar('_foldLeft__B')  # <B>
        def foldLeft(self, z: _foldLeft__B, op: scala.Function2[_foldLeft__B, scala.Tuple2[_ParHashMap__K, _ParHashMap__V], _foldLeft__B]) -> _foldLeft__B: ...
        _foldRight__B = typing.TypeVar('_foldRight__B')  # <B>
        def foldRight(self, z: _foldRight__B, op: scala.Function2[scala.Tuple2[_ParHashMap__K, _ParHashMap__V], _foldRight__B, _foldRight__B]) -> _foldRight__B: ...
        def forall(self, p: scala.Function1[scala.Tuple2[_ParHashMap__K, _ParHashMap__V], typing.Any]) -> bool: ...
        _foreach__U = typing.TypeVar('_foreach__U')  # <U>
        def foreach(self, f: scala.Function1[scala.Tuple2[_ParHashMap__K, _ParHashMap__V], _foreach__U]) -> None: ...
        _grouped__B = typing.TypeVar('_grouped__B')  # <B>
        def grouped(self, size: int) -> scala.collection.Iterator.GroupedIterator[_grouped__B]: ...
        def hasDefiniteSize(self) -> bool: ...
        def hasNext(self) -> bool: ...
        def i(self) -> int: ...
        def i_$eq(self, x$1: int) -> None: ...
        def indexFlag(self) -> int: ...
        _indexOf_0__B = typing.TypeVar('_indexOf_0__B')  # <B>
        _indexOf_1__B = typing.TypeVar('_indexOf_1__B')  # <B>
        @typing.overload
        def indexOf(self, elem: _indexOf_0__B) -> int: ...
        @typing.overload
        def indexOf(self, elem: _indexOf_1__B, from_: int) -> int: ...
        @typing.overload
        def indexWhere(self, p: scala.Function1[scala.Tuple2[_ParHashMap__K, _ParHashMap__V], typing.Any]) -> int: ...
        @typing.overload
        def indexWhere(self, p: scala.Function1[scala.Tuple2[_ParHashMap__K, _ParHashMap__V], typing.Any], from_: int) -> int: ...
        def isAborted(self) -> bool: ...
        def isEmpty(self) -> bool: ...
        def isRemainingCheap(self) -> bool: ...
        def isTraversableAgain(self) -> bool: ...
        def length(self) -> int: ...
        _map__S = typing.TypeVar('_map__S')  # <S>
        def map(self, f: scala.Function1[scala.Tuple2[_ParHashMap__K, _ParHashMap__V], _map__S]) -> scala.collection.parallel.IterableSplitter.Mapped[_map__S]: ...
        _map2combiner__S = typing.TypeVar('_map2combiner__S')  # <S>
        _map2combiner__That = typing.TypeVar('_map2combiner__That')  # <That>
        def map2combiner(self, f: scala.Function1[scala.Tuple2[_ParHashMap__K, _ParHashMap__V], _map2combiner__S], cb: scala.collection.parallel.Combiner[_map2combiner__S, _map2combiner__That]) -> scala.collection.parallel.Combiner[_map2combiner__S, _map2combiner__That]: ...
        def max(self, ord: scala.math.Ordering) -> typing.Any: ...
        def maxBy(self, f: scala.Function1, cmp: scala.math.Ordering) -> typing.Any: ...
        def min(self, ord: scala.math.Ordering) -> typing.Any: ...
        def minBy(self, f: scala.Function1, cmp: scala.math.Ordering) -> typing.Any: ...
        @typing.overload
        def mkString(self) -> java.lang.String: ...
        @typing.overload
        def mkString(self, sep: typing.Union[java.lang.String, str]) -> java.lang.String: ...
        @typing.overload
        def mkString(self, start: typing.Union[java.lang.String, str], sep: typing.Union[java.lang.String, str], end: typing.Union[java.lang.String, str]) -> java.lang.String: ...
        _newSliceInternal__U = typing.TypeVar('_newSliceInternal__U', bound=scala.collection.parallel.IterableSplitter.Taken)  # <U>
        def newSliceInternal(self, it: _newSliceInternal__U, from1: int) -> _newSliceInternal__U: ...
        def newTaken(self, until: int) -> scala.collection.parallel.IterableSplitter.Taken: ...
        def next(self) -> scala.Tuple2[_ParHashMap__K, _ParHashMap__V]: ...
        def nonEmpty(self) -> bool: ...
        _padTo__A1 = typing.TypeVar('_padTo__A1')  # <A1>
        def padTo(self, len: int, elem: _padTo__A1) -> scala.collection.Iterator[_padTo__A1]: ...
        def partition(self, p: scala.Function1[scala.Tuple2[_ParHashMap__K, _ParHashMap__V], typing.Any]) -> scala.Tuple2[scala.collection.Iterator[scala.Tuple2[_ParHashMap__K, _ParHashMap__V]], scala.collection.Iterator[scala.Tuple2[_ParHashMap__K, _ParHashMap__V]]]: ...
        _partition2combiners__U = typing.TypeVar('_partition2combiners__U')  # <U>
        _partition2combiners__This = typing.TypeVar('_partition2combiners__This')  # <This>
        def partition2combiners(self, pred: scala.Function1[scala.Tuple2[_ParHashMap__K, _ParHashMap__V], typing.Any], btrue: scala.collection.parallel.Combiner[_partition2combiners__U, _partition2combiners__This], bfalse: scala.collection.parallel.Combiner[_partition2combiners__U, _partition2combiners__This]) -> scala.Tuple2[scala.collection.parallel.Combiner[_partition2combiners__U, _partition2combiners__This], scala.collection.parallel.Combiner[_partition2combiners__U, _partition2combiners__This]]: ...
        _patch__B = typing.TypeVar('_patch__B')  # <B>
        def patch(self, from_: int, patchElems: scala.collection.Iterator[_patch__B], replaced: int) -> scala.collection.Iterator[_patch__B]: ...
        _product__U = typing.TypeVar('_product__U')  # <U>
        def product(self, num: scala.math.Numeric[_product__U]) -> _product__U: ...
        _reduce__U = typing.TypeVar('_reduce__U')  # <U>
        def reduce(self, op: scala.Function2[_reduce__U, _reduce__U, _reduce__U]) -> _reduce__U: ...
        _reduceLeft_0__U = typing.TypeVar('_reduceLeft_0__U')  # <U>
        _reduceLeft_1__B = typing.TypeVar('_reduceLeft_1__B')  # <B>
        @typing.overload
        def reduceLeft(self, howmany: int, op: scala.Function2[_reduceLeft_0__U, _reduceLeft_0__U, _reduceLeft_0__U]) -> _reduceLeft_0__U: ...
        @typing.overload
        def reduceLeft(self, op: scala.Function2[_reduceLeft_1__B, scala.Tuple2[_ParHashMap__K, _ParHashMap__V], _reduceLeft_1__B]) -> _reduceLeft_1__B: ...
        _reduceLeftOption__B = typing.TypeVar('_reduceLeftOption__B')  # <B>
        def reduceLeftOption(self, op: scala.Function2[_reduceLeftOption__B, scala.Tuple2[_ParHashMap__K, _ParHashMap__V], _reduceLeftOption__B]) -> scala.Option[_reduceLeftOption__B]: ...
        _reduceOption__A1 = typing.TypeVar('_reduceOption__A1')  # <A1>
        def reduceOption(self, op: scala.Function2[_reduceOption__A1, _reduceOption__A1, _reduceOption__A1]) -> scala.Option[_reduceOption__A1]: ...
        _reduceRight__B = typing.TypeVar('_reduceRight__B')  # <B>
        def reduceRight(self, op: scala.Function2[scala.Tuple2[_ParHashMap__K, _ParHashMap__V], _reduceRight__B, _reduceRight__B]) -> _reduceRight__B: ...
        _reduceRightOption__B = typing.TypeVar('_reduceRightOption__B')  # <B>
        def reduceRightOption(self, op: scala.Function2[scala.Tuple2[_ParHashMap__K, _ParHashMap__V], _reduceRightOption__B, _reduceRightOption__B]) -> scala.Option[_reduceRightOption__B]: ...
        def remaining(self) -> int: ...
        def reversed(self) -> scala.collection.immutable.List[scala.Tuple2[_ParHashMap__K, _ParHashMap__V]]: ...
        def sameElements(self, that: scala.collection.Iterator[typing.Any]) -> bool: ...
        _scanLeft__B = typing.TypeVar('_scanLeft__B')  # <B>
        def scanLeft(self, z: _scanLeft__B, op: scala.Function2[_scanLeft__B, scala.Tuple2[_ParHashMap__K, _ParHashMap__V], _scanLeft__B]) -> scala.collection.Iterator[_scanLeft__B]: ...
        _scanRight__B = typing.TypeVar('_scanRight__B')  # <B>
        def scanRight(self, z: _scanRight__B, op: scala.Function2[scala.Tuple2[_ParHashMap__K, _ParHashMap__V], _scanRight__B, _scanRight__B]) -> scala.collection.Iterator[_scanRight__B]: ...
        _scanToArray__U = typing.TypeVar('_scanToArray__U')  # <U>
        _scanToArray__A = typing.TypeVar('_scanToArray__A')  # <A>
        def scanToArray(self, z: _scanToArray__U, op: scala.Function2[_scanToArray__U, _scanToArray__U, _scanToArray__U], array: typing.Any, from_: int) -> None: ...
        _scanToCombiner_0__U = typing.TypeVar('_scanToCombiner_0__U')  # <U>
        _scanToCombiner_0__That = typing.TypeVar('_scanToCombiner_0__That')  # <That>
        _scanToCombiner_1__U = typing.TypeVar('_scanToCombiner_1__U')  # <U>
        _scanToCombiner_1__That = typing.TypeVar('_scanToCombiner_1__That')  # <That>
        @typing.overload
        def scanToCombiner(self, howmany: int, startValue: _scanToCombiner_0__U, op: scala.Function2[_scanToCombiner_0__U, _scanToCombiner_0__U, _scanToCombiner_0__U], cb: scala.collection.parallel.Combiner[_scanToCombiner_0__U, _scanToCombiner_0__That]) -> scala.collection.parallel.Combiner[_scanToCombiner_0__U, _scanToCombiner_0__That]: ...
        @typing.overload
        def scanToCombiner(self, startValue: _scanToCombiner_1__U, op: scala.Function2[_scanToCombiner_1__U, _scanToCombiner_1__U, _scanToCombiner_1__U], cb: scala.collection.parallel.Combiner[_scanToCombiner_1__U, _scanToCombiner_1__That]) -> scala.collection.parallel.Combiner[_scanToCombiner_1__U, _scanToCombiner_1__That]: ...
        def seq(self) -> scala.collection.Iterator[scala.Tuple2[_ParHashMap__K, _ParHashMap__V]]: ...
        def setIndexFlag(self, f: int) -> None: ...
        def setIndexFlagIfGreater(self, f: int) -> None: ...
        def setIndexFlagIfLesser(self, f: int) -> None: ...
        _shouldSplitFurther__S = typing.TypeVar('_shouldSplitFurther__S')  # <S>
        def shouldSplitFurther(self, coll: scala.collection.parallel.ParIterable[_shouldSplitFurther__S], parallelismLevel: int) -> bool: ...
        def signalDelegate(self) -> scala.collection.generic.Signalling: ...
        def signalDelegate_$eq(self, x$1: scala.collection.generic.Signalling) -> None: ...
        def size(self) -> int: ...
        def sizeHintIfCheap(self) -> int: ...
        def slice(self, from1: int, until1: int) -> scala.collection.parallel.IterableSplitter[scala.Tuple2[_ParHashMap__K, _ParHashMap__V]]: ...
        _slice2combiner__U = typing.TypeVar('_slice2combiner__U')  # <U>
        _slice2combiner__This = typing.TypeVar('_slice2combiner__This')  # <This>
        def slice2combiner(self, from_: int, until: int, cb: scala.collection.parallel.Combiner[_slice2combiner__U, _slice2combiner__This]) -> scala.collection.parallel.Combiner[_slice2combiner__U, _slice2combiner__This]: ...
        def sliceIterator(self, from_: int, until: int) -> scala.collection.Iterator[scala.Tuple2[_ParHashMap__K, _ParHashMap__V]]: ...
        _sliding__B = typing.TypeVar('_sliding__B')  # <B>
        def sliding(self, size: int, step: int) -> scala.collection.Iterator.GroupedIterator[_sliding__B]: ...
        _sliding$default$2__B = typing.TypeVar('_sliding$default$2__B')  # <B>
        def sliding$default$2(self) -> int: ...
        def span(self, p: scala.Function1[scala.Tuple2[_ParHashMap__K, _ParHashMap__V], typing.Any]) -> scala.Tuple2[scala.collection.Iterator[scala.Tuple2[_ParHashMap__K, _ParHashMap__V]], scala.collection.Iterator[scala.Tuple2[_ParHashMap__K, _ParHashMap__V]]]: ...
        _span2combiners__U = typing.TypeVar('_span2combiners__U')  # <U>
        _span2combiners__This = typing.TypeVar('_span2combiners__This')  # <This>
        def span2combiners(self, p: scala.Function1[scala.Tuple2[_ParHashMap__K, _ParHashMap__V], typing.Any], before: scala.collection.parallel.Combiner[_span2combiners__U, _span2combiners__This], after: scala.collection.parallel.Combiner[_span2combiners__U, _span2combiners__This]) -> scala.Tuple2[scala.collection.parallel.Combiner[_span2combiners__U, _span2combiners__This], scala.collection.parallel.Combiner[_span2combiners__U, _span2combiners__This]]: ...
        def split(self) -> scala.collection.Seq[scala.collection.parallel.IterableSplitter[scala.Tuple2[_ParHashMap__K, _ParHashMap__V]]]: ...
        _splitAt2combiners__U = typing.TypeVar('_splitAt2combiners__U')  # <U>
        _splitAt2combiners__This = typing.TypeVar('_splitAt2combiners__This')  # <This>
        def splitAt2combiners(self, at: int, before: scala.collection.parallel.Combiner[_splitAt2combiners__U, _splitAt2combiners__This], after: scala.collection.parallel.Combiner[_splitAt2combiners__U, _splitAt2combiners__This]) -> scala.Tuple2[scala.collection.parallel.Combiner[_splitAt2combiners__U, _splitAt2combiners__This], scala.collection.parallel.Combiner[_splitAt2combiners__U, _splitAt2combiners__This]]: ...
        def splitWithSignalling(self) -> scala.collection.Seq[scala.collection.parallel.IterableSplitter[scala.Tuple2[_ParHashMap__K, _ParHashMap__V]]]: ...
        _sum__U = typing.TypeVar('_sum__U')  # <U>
        def sum(self, num: scala.math.Numeric[_sum__U]) -> _sum__U: ...
        def sz(self) -> int: ...
        def tag(self) -> int: ...
        def take(self, n: int) -> scala.collection.parallel.IterableSplitter[scala.Tuple2[_ParHashMap__K, _ParHashMap__V]]: ...
        _take2combiner__U = typing.TypeVar('_take2combiner__U')  # <U>
        _take2combiner__This = typing.TypeVar('_take2combiner__This')  # <This>
        def take2combiner(self, n: int, cb: scala.collection.parallel.Combiner[_take2combiner__U, _take2combiner__This]) -> scala.collection.parallel.Combiner[_take2combiner__U, _take2combiner__This]: ...
        def takeWhile(self, p: scala.Function1[scala.Tuple2[_ParHashMap__K, _ParHashMap__V], typing.Any]) -> scala.collection.Iterator[scala.Tuple2[_ParHashMap__K, _ParHashMap__V]]: ...
        _takeWhile2combiner__U = typing.TypeVar('_takeWhile2combiner__U')  # <U>
        _takeWhile2combiner__This = typing.TypeVar('_takeWhile2combiner__This')  # <This>
        def takeWhile2combiner(self, p: scala.Function1[scala.Tuple2[_ParHashMap__K, _ParHashMap__V], typing.Any], cb: scala.collection.parallel.Combiner[_takeWhile2combiner__U, _takeWhile2combiner__This]) -> scala.Tuple2[scala.collection.parallel.Combiner[_takeWhile2combiner__U, _takeWhile2combiner__This], typing.Any]: ...
        _to__Col = typing.TypeVar('_to__Col')  # <Col>
        def to(self, cbf: scala.collection.generic.CanBuildFrom[scala.runtime.Nothing., scala.Tuple2[_ParHashMap__K, _ParHashMap__V], _to__Col]) -> _to__Col: ...
        _toArray__B = typing.TypeVar('_toArray__B')  # <B>
        def toArray(self, evidence$1: scala.reflect.ClassTag[_toArray__B]) -> typing.Any: ...
        _toBuffer__B = typing.TypeVar('_toBuffer__B')  # <B>
        def toBuffer(self) -> scala.collection.mutable.Buffer[_toBuffer__B]: ...
        def toIndexedSeq(self) -> scala.collection.immutable.IndexedSeq[scala.Tuple2[_ParHashMap__K, _ParHashMap__V]]: ...
        def toIterable(self) -> scala.collection.Iterable[scala.Tuple2[_ParHashMap__K, _ParHashMap__V]]: ...
        def toIterator(self) -> scala.collection.Iterator[scala.Tuple2[_ParHashMap__K, _ParHashMap__V]]: ...
        def toList(self) -> scala.collection.immutable.List[scala.Tuple2[_ParHashMap__K, _ParHashMap__V]]: ...
        _toMap__T = typing.TypeVar('_toMap__T')  # <T>
        _toMap__U = typing.TypeVar('_toMap__U')  # <U>
        def toMap(self, ev: scala.Predef..less.colon.less[scala.Tuple2[_ParHashMap__K, _ParHashMap__V], scala.Tuple2[_toMap__T, _toMap__U]]) -> scala.collection.immutable.Map[_toMap__T, _toMap__U]: ...
        def toSeq(self) -> scala.collection.Seq[scala.Tuple2[_ParHashMap__K, _ParHashMap__V]]: ...
        _toSet__B = typing.TypeVar('_toSet__B')  # <B>
        def toSet(self) -> scala.collection.immutable.Set[_toSet__B]: ...
        def toStream(self) -> scala.collection.immutable.Stream[scala.Tuple2[_ParHashMap__K, _ParHashMap__V]]: ...
        def toString(self) -> java.lang.String: ...
        def toTraversable(self) -> scala.collection.Traversable[scala.Tuple2[_ParHashMap__K, _ParHashMap__V]]: ...
        def toVector(self) -> scala.collection.immutable.Vector[scala.Tuple2[_ParHashMap__K, _ParHashMap__V]]: ...
        def triter(self) -> scala.collection.Iterator[scala.Tuple2[_ParHashMap__K, _ParHashMap__V]]: ...
        def triter_$eq(self, x$1: scala.collection.Iterator[scala.Tuple2[_ParHashMap__K, _ParHashMap__V]]) -> None: ...
        def withFilter(self, p: scala.Function1[scala.Tuple2[_ParHashMap__K, _ParHashMap__V], typing.Any]) -> scala.collection.Iterator[scala.Tuple2[_ParHashMap__K, _ParHashMap__V]]: ...
        _zip__B = typing.TypeVar('_zip__B')  # <B>
        def zip(self, that: scala.collection.Iterator[_zip__B]) -> scala.collection.Iterator[scala.Tuple2[scala.Tuple2[_ParHashMap__K, _ParHashMap__V], _zip__B]]: ...
        _zip2combiner__U = typing.TypeVar('_zip2combiner__U')  # <U>
        _zip2combiner__S = typing.TypeVar('_zip2combiner__S')  # <S>
        _zip2combiner__That = typing.TypeVar('_zip2combiner__That')  # <That>
        def zip2combiner(self, otherpit: scala.collection.parallel.RemainsIterator[_zip2combiner__S], cb: scala.collection.parallel.Combiner[scala.Tuple2[_zip2combiner__U, _zip2combiner__S], _zip2combiner__That]) -> scala.collection.parallel.Combiner[scala.Tuple2[_zip2combiner__U, _zip2combiner__S], _zip2combiner__That]: ...
        _zipAll__B = typing.TypeVar('_zipAll__B')  # <B>
        _zipAll__A1 = typing.TypeVar('_zipAll__A1')  # <A1>
        _zipAll__B1 = typing.TypeVar('_zipAll__B1')  # <B1>
        def zipAll(self, that: scala.collection.Iterator[_zipAll__B], thisElem: _zipAll__A1, thatElem: _zipAll__B1) -> scala.collection.Iterator[scala.Tuple2[_zipAll__A1, _zipAll__B1]]: ...
        _zipAll2combiner__U = typing.TypeVar('_zipAll2combiner__U')  # <U>
        _zipAll2combiner__S = typing.TypeVar('_zipAll2combiner__S')  # <S>
        _zipAll2combiner__That = typing.TypeVar('_zipAll2combiner__That')  # <That>
        def zipAll2combiner(self, that: scala.collection.parallel.RemainsIterator[_zipAll2combiner__S], thiselem: _zipAll2combiner__U, thatelem: _zipAll2combiner__S, cb: scala.collection.parallel.Combiner[scala.Tuple2[_zipAll2combiner__U, _zipAll2combiner__S], _zipAll2combiner__That]) -> scala.collection.parallel.Combiner[scala.Tuple2[_zipAll2combiner__U, _zipAll2combiner__S], _zipAll2combiner__That]: ...
        _zipAllParSeq__S = typing.TypeVar('_zipAllParSeq__S')  # <S>
        _zipAllParSeq__U = typing.TypeVar('_zipAllParSeq__U')  # <U>
        _zipAllParSeq__R = typing.TypeVar('_zipAllParSeq__R')  # <R>
        def zipAllParSeq(self, that: scala.collection.parallel.SeqSplitter[_zipAllParSeq__S], thisElem: _zipAllParSeq__U, thatElem: _zipAllParSeq__R) -> scala.collection.parallel.IterableSplitter.ZippedAll[_zipAllParSeq__U, _zipAllParSeq__R]: ...
        _zipParSeq__S = typing.TypeVar('_zipParSeq__S')  # <S>
        def zipParSeq(self, that: scala.collection.parallel.SeqSplitter[_zipParSeq__S]) -> scala.collection.parallel.IterableSplitter.Zipped[_zipParSeq__S]: ...
        def zipWithIndex(self) -> scala.collection.Iterator[scala.Tuple2[scala.Tuple2[_ParHashMap__K, _ParHashMap__V], typing.Any]]: ...

_ParMap__WithDefault__K = typing.TypeVar('_ParMap__WithDefault__K')  # <K>
_ParMap__WithDefault__V = typing.TypeVar('_ParMap__WithDefault__V')  # <V>
_ParMap__K = typing.TypeVar('_ParMap__K')  # <K>
_ParMap__V = typing.TypeVar('_ParMap__V')  # <V>
class ParMap(scala.collection.parallel.ParMap[_ParMap__K, _ParMap__V], ParIterable[scala.Tuple2[_ParMap__K, _ParMap__V]], typing.Generic[_ParMap__K, _ParMap__V]):
    @staticmethod
    def $init$($this: 'ParMap') -> None: ...
    _$plus_0__V1 = typing.TypeVar('_$plus_0__V1')  # <V1>
    _$plus_1__U = typing.TypeVar('_$plus_1__U')  # <U>
    _$plus_2__U = typing.TypeVar('_$plus_2__U')  # <U>
    @typing.overload
    def $plus(self, kv: scala.Tuple2[_ParMap__K, _.plus_0__V1]) -> scala.collection.GenMap[_ParMap__K, _.plus_0__V1]: ...
    @typing.overload
    def $plus(self, kv: scala.Tuple2[_ParMap__K, _.plus_1__U]) -> scala.collection.parallel.ParMap[_ParMap__K, _.plus_1__U]: ...
    @typing.overload
    def $plus(self, kv: scala.Tuple2[_ParMap__K, _.plus_2__U]) -> 'ParMap'[_ParMap__K, _.plus_2__U]: ...
    _canBuildFrom__K = typing.TypeVar('_canBuildFrom__K')  # <K>
    _canBuildFrom__V = typing.TypeVar('_canBuildFrom__V')  # <V>
    @staticmethod
    def canBuildFrom() -> scala.collection.generic.CanCombineFrom['ParMap'[typing.Any, typing.Any], scala.Tuple2[_canBuildFrom__K, _canBuildFrom__V], 'ParMap'[_canBuildFrom__K, _canBuildFrom__V]]: ...
    @typing.overload
    def empty(self) -> scala.collection.parallel.ParMap[_ParMap__K, _ParMap__V]: ...
    @typing.overload
    def empty(self) -> 'ParMap'[_ParMap__K, _ParMap__V]: ...
    def equals(self, that: typing.Any) -> bool: ...
    def hashCode(self) -> int: ...
    def mapCompanion(self) -> scala.collection.generic.GenericParMapCompanion['ParMap']: ...
    def stringPrefix(self) -> java.lang.String: ...
    _toMap_0__K = typing.TypeVar('_toMap_0__K')  # <K>
    _toMap_0__V = typing.TypeVar('_toMap_0__V')  # <V>
    _toMap_1__P = typing.TypeVar('_toMap_1__P')  # <P>
    _toMap_1__Q = typing.TypeVar('_toMap_1__Q')  # <Q>
    @typing.overload
    def toMap(self, ev: scala.Predef..less.colon.less[typing.Any, scala.Tuple2[typing.Any, typing.Any]]) -> scala.collection.GenMap[typing.Any, typing.Any]: ...
    @typing.overload
    def toMap(self, ev: scala.Predef..less.colon.less[scala.Tuple2[_ParMap__K, _ParMap__V], scala.Tuple2[_toMap_1__P, _toMap_1__Q]]) -> 'ParMap'[_toMap_1__P, _toMap_1__Q]: ...
    def toString(self) -> java.lang.String: ...
    _updated_0__V1 = typing.TypeVar('_updated_0__V1')  # <V1>
    _updated_1__U = typing.TypeVar('_updated_1__U')  # <U>
    _updated_2__U = typing.TypeVar('_updated_2__U')  # <U>
    @typing.overload
    def updated(self, key: _ParMap__K, value: _updated_0__V1) -> scala.collection.GenMap[_ParMap__K, _updated_0__V1]: ...
    @typing.overload
    def updated(self, key: _ParMap__K, value: _updated_1__U) -> scala.collection.parallel.ParMap[_ParMap__K, _updated_1__U]: ...
    @typing.overload
    def updated(self, key: _ParMap__K, value: _updated_2__U) -> 'ParMap'[_ParMap__K, _updated_2__U]: ...
    _withDefault__U = typing.TypeVar('_withDefault__U')  # <U>
    def withDefault(self, d: scala.Function1[_ParMap__K, _withDefault__U]) -> 'ParMap'[_ParMap__K, _withDefault__U]: ...
    _withDefaultValue__U = typing.TypeVar('_withDefaultValue__U')  # <U>
    def withDefaultValue(self, d: _withDefaultValue__U) -> 'ParMap'[_ParMap__K, _withDefaultValue__U]: ...
    class WithDefault(scala.collection.parallel.ParMap.WithDefault[_ParMap__WithDefault__K, _ParMap__WithDefault__V], scala.collection.parallel.immutable.ParMap[_ParMap__WithDefault__K, _ParMap__WithDefault__V], typing.Generic[_ParMap__WithDefault__K, _ParMap__WithDefault__V]):
        def __init__(self, underlying: 'ParMap'[_ParMap__WithDefault__K, _ParMap__WithDefault__V], d: scala.Function1[_ParMap__WithDefault__K, _ParMap__WithDefault__V]): ...
        def $minus(self, key: _ParMap__WithDefault__K) -> 'ParMap.WithDefault'[_ParMap__WithDefault__K, _ParMap__WithDefault__V]: ...
        _$plus__U = typing.TypeVar('_$plus__U')  # <U>
        def $plus(self, kv: scala.Tuple2[_ParMap__WithDefault__K, _.plus__U]) -> 'ParMap.WithDefault'[_ParMap__WithDefault__K, _.plus__U]: ...
        def companion(self) -> scala.collection.generic.GenericCompanion[ParIterable]: ...
        def drop(self, n: int) -> scala.collection.parallel.ParIterable: ...
        def dropWhile(self, pred: scala.Function1) -> scala.collection.parallel.ParIterable: ...
        def empty(self) -> 'ParMap.WithDefault'[_ParMap__WithDefault__K, _ParMap__WithDefault__V]: ...
        def filter(self, pred: scala.Function1) -> scala.collection.parallel.ParIterable: ...
        def filterKeys(self, p: scala.Function1[typing.Any, typing.Any]) -> scala.collection.parallel.ParMap[typing.Any, typing.Any]: ...
        def filterNot(self, pred: scala.Function1) -> scala.collection.parallel.ParIterable: ...
        _genericBuilder__B = typing.TypeVar('_genericBuilder__B')  # <B>
        def genericBuilder(self) -> scala.collection.parallel.Combiner[_genericBuilder__B, scala.collection.parallel.ParIterable[_genericBuilder__B]]: ...
        _groupBy__K = typing.TypeVar('_groupBy__K')  # <K>
        def groupBy(self, f: scala.Function1[scala.Tuple2[typing.Any, typing.Any], typing.Any]) -> 'ParMap'[typing.Any, scala.collection.parallel.ParMap[typing.Any, typing.Any]]: ...
        def init(self) -> scala.collection.parallel.ParIterable: ...
        def iterator(self) -> scala.collection.parallel.Splitter[scala.Tuple2[typing.Any, typing.Any]]: ...
        def keySet(self) -> scala.collection.parallel.ParSet[typing.Any]: ...
        def keys(self) -> scala.collection.parallel.ParIterable[typing.Any]: ...
        def keysIterator(self) -> scala.collection.parallel.IterableSplitter[typing.Any]: ...
        def mapCompanion(self) -> scala.collection.generic.GenericParMapCompanion['ParMap']: ...
        _mapValues__S = typing.TypeVar('_mapValues__S')  # <S>
        def mapValues(self, f: scala.Function1[typing.Any, _mapValues__S]) -> scala.collection.parallel.ParMap[typing.Any, _mapValues__S]: ...
        def par(self) -> scala.collection.parallel.ParIterable: ...
        def repr(self) -> scala.collection.parallel.ParIterable: ...
        def seq(self) -> scala.collection.immutable.Map[_ParMap__WithDefault__K, _ParMap__WithDefault__V]: ...
        def slice(self, unc_from: int, unc_until: int) -> scala.collection.parallel.ParIterable: ...
        def stringPrefix(self) -> java.lang.String: ...
        def tail(self) -> scala.collection.parallel.ParIterable: ...
        def take(self, n: int) -> scala.collection.parallel.ParIterable: ...
        def takeWhile(self, pred: scala.Function1) -> scala.collection.parallel.ParIterable: ...
        def toIterable(self) -> ParIterable[scala.Tuple2[_ParMap__WithDefault__K, _ParMap__WithDefault__V]]: ...
        _toMap__P = typing.TypeVar('_toMap__P')  # <P>
        _toMap__Q = typing.TypeVar('_toMap__Q')  # <Q>
        def toMap(self, ev: scala.Predef..less.colon.less[scala.Tuple2[_ParMap__WithDefault__K, _ParMap__WithDefault__V], scala.Tuple2[_toMap__P, _toMap__Q]]) -> 'ParMap'[_toMap__P, _toMap__Q]: ...
        def toSeq(self) -> ParSeq[scala.Tuple2[_ParMap__WithDefault__K, _ParMap__WithDefault__V]]: ...
        _toSet__U = typing.TypeVar('_toSet__U')  # <U>
        def toSet(self) -> ParSet[_toSet__U]: ...
        _updated__U = typing.TypeVar('_updated__U')  # <U>
        def updated(self, key: _ParMap__WithDefault__K, value: _updated__U) -> 'ParMap.WithDefault'[_ParMap__WithDefault__K, _updated__U]: ...
        def values(self) -> scala.collection.parallel.ParIterable[typing.Any]: ...
        def valuesIterator(self) -> scala.collection.parallel.IterableSplitter[typing.Any]: ...
        _withDefault__U = typing.TypeVar('_withDefault__U')  # <U>
        def withDefault(self, d: scala.Function1[_ParMap__WithDefault__K, _withDefault__U]) -> 'ParMap'[_ParMap__WithDefault__K, _withDefault__U]: ...
        _withDefaultValue__U = typing.TypeVar('_withDefaultValue__U')  # <U>
        def withDefaultValue(self, d: _withDefaultValue__U) -> 'ParMap'[_ParMap__WithDefault__K, _withDefaultValue__U]: ...


class __module_protocol__(typing.Protocol):
    # A module protocol which reflects the result of ``jp.JPackage("scala.collection.parallel.immutable")``.

    HashMapCombiner: typing.Type[HashMapCombiner]
    HashSetCombiner: typing.Type[HashSetCombiner]
    LazyParVectorCombiner: typing.Type[LazyParVectorCombiner]
    ParHashMap: typing.Type[ParHashMap]
    ParHashSet: typing.Type[ParHashSet]
    ParIterable: typing.Type[ParIterable]
    ParMap: typing.Type[ParMap]
    ParRange: typing.Type[ParRange]
    ParSeq: typing.Type[ParSeq]
    ParSet: typing.Type[ParSet]
    ParVector: typing.Type[ParVector]
    Repetition: typing.Type[Repetition]
    package: typing.Type[package]
